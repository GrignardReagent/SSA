{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547e9d27",
   "metadata": {},
   "source": [
    "# SVM IY010_simulation_7 analysis: Varying 2 stats, fixing 1 stat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c26d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(Path.cwd().parent.parent.parent / \"src\"))\n",
    "\n",
    "# Import custom modules\n",
    "from classifiers.svm_classifier import svm_classifier, grid_search_svm\n",
    "from models.TF_transformer import TFTransformer, ModelCfg\n",
    "from utils.data_processing import add_binary_labels, add_nearest_neighbour_labels\n",
    "from utils.standardise_time_series import standardise_time_series\n",
    "from utils.shuffle_time_series import shuffle_time_series\n",
    "\n",
    "# Import sklearn modules for SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a70861",
   "metadata": {},
   "source": [
    "data_7_mu: mu is fixed, varying CV and t_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf75f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Standardized dataset:\n",
      "   NaN values: 0\n",
      "Data preparation for SVM:\n",
      "  Feature matrix shape: (2350, 144)\n",
      "  Labels shape: (2350,)\n",
      "  Number of classes: 2\n",
      "  Class distribution: [1150 1200]\n",
      "  Memory usage: 2.58 MB\n",
      "‚úÖ Data ready for SVM classification!\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78       230\n",
      "           1       0.79      0.80      0.80       240\n",
      "\n",
      "    accuracy                           0.79       470\n",
      "   macro avg       0.79      0.79      0.79       470\n",
      "weighted avg       0.79      0.79      0.79       470\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[179  51]\n",
      " [ 48 192]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.18 seconds\n",
      "\n",
      "üîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.77 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       230\n",
      "           1       0.78      0.76      0.77       240\n",
      "\n",
      "    accuracy                           0.77       470\n",
      "   macro avg       0.77      0.77      0.77       470\n",
      "weighted avg       0.77      0.77      0.77       470\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[178  52]\n",
      " [ 58 182]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.20 seconds\n"
     ]
    }
   ],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_mu\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_mu.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "label_column = \"cv_target\" \n",
    "# label_column = 't_ac_target' # we could equally choose t_ac_target here, as it's variable, but it will give different results \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410ea0a",
   "metadata": {},
   "source": [
    "data_7_cv: cv is fixed, varying mu and t_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d0fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Standardized dataset:\n",
      "   NaN values: 0\n",
      "Data preparation for SVM:\n",
      "  Feature matrix shape: (2350, 144)\n",
      "  Labels shape: (2350,)\n",
      "  Number of classes: 2\n",
      "  Class distribution: [1150 1200]\n",
      "  Memory usage: 2.58 MB\n",
      "‚úÖ Data ready for SVM classification!\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       230\n",
      "           1       0.79      0.81      0.80       240\n",
      "\n",
      "    accuracy                           0.79       470\n",
      "   macro avg       0.79      0.79      0.79       470\n",
      "weighted avg       0.79      0.79      0.79       470\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[178  52]\n",
      " [ 45 195]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.14 seconds\n",
      "\n",
      "üîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       230\n",
      "           1       0.80      0.76      0.78       240\n",
      "\n",
      "    accuracy                           0.78       470\n",
      "   macro avg       0.78      0.78      0.78       470\n",
      "weighted avg       0.78      0.78      0.78       470\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[183  47]\n",
      " [ 57 183]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.17 seconds\n"
     ]
    }
   ],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_cv\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_cv.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "label_column = \"mu_target\" \n",
    "# label_column = 't_ac_target' # we could equally choose t_ac_target here, as it's variable, but it will give different results \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc63936",
   "metadata": {},
   "source": [
    "data_7_t_ac: t_ac is fixed, varying mu and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b84f6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Standardized dataset:\n",
      "   NaN values: 0\n",
      "Data preparation for SVM:\n",
      "  Feature matrix shape: (2400, 200)\n",
      "  Labels shape: (2400,)\n",
      "  Number of classes: 2\n",
      "  Class distribution: [1200 1200]\n",
      "  Memory usage: 3.66 MB\n",
      "‚úÖ Data ready for SVM classification!\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.84 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       240\n",
      "           1       0.84      0.85      0.84       240\n",
      "\n",
      "    accuracy                           0.84       480\n",
      "   macro avg       0.84      0.84      0.84       480\n",
      "weighted avg       0.84      0.84      0.84       480\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[200  40]\n",
      " [ 36 204]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.15 seconds\n",
      "\n",
      "üîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.85 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       240\n",
      "           1       0.85      0.85      0.85       240\n",
      "\n",
      "    accuracy                           0.85       480\n",
      "   macro avg       0.85      0.85      0.85       480\n",
      "weighted avg       0.85      0.85      0.85       480\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[205  35]\n",
      " [ 35 205]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 0.18 seconds\n"
     ]
    }
   ],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_t_ac\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_t_ac.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "# label_column = \"cv_target\" \n",
    "label_column = 'mu_target' # we could equally choose mu_target here, as it's variable, but it will give different results \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3e8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
