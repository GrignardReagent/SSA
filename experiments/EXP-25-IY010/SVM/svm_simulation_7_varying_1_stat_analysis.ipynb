{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547e9d27",
   "metadata": {},
   "source": [
    "# SVM IY010_simulation_7 Analysis: Varying 1 stat, fixing 2 stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c26d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(Path.cwd().parent.parent.parent / \"src\"))\n",
    "\n",
    "# Import custom modules\n",
    "from classifiers.svm_classifier import svm_classifier, grid_search_svm\n",
    "from models.TF_transformer import TFTransformer, ModelCfg\n",
    "from utils.data_processing import add_binary_labels, add_nearest_neighbour_labels\n",
    "from utils.standardise_time_series import standardise_time_series\n",
    "from utils.shuffle_time_series import shuffle_time_series\n",
    "\n",
    "# Import sklearn modules for SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd6119",
   "metadata": {},
   "source": [
    "Visualise results when we vary 1 stat target at a time\n",
    "\n",
    "Changing ``t_ac_target``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db582826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Standardized dataset:\n",
      "   NaN values: 0\n",
      "Data preparation for SVM:\n",
      "  Feature matrix shape: (9400, 174)\n",
      "  Labels shape: (9400,)\n",
      "  Number of classes: 2\n",
      "  Class distribution: [4600 4800]\n",
      "  Memory usage: 12.48 MB\n",
      "‚úÖ Data ready for SVM classification!\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.83 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81       920\n",
      "           1       0.78      0.94      0.85       960\n",
      "\n",
      "    accuracy                           0.83      1880\n",
      "   macro avg       0.85      0.83      0.83      1880\n",
      "weighted avg       0.85      0.83      0.83      1880\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[665 255]\n",
      " [ 58 902]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 4.13 seconds\n",
      "\n",
      "üîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67       920\n",
      "           1       0.69      0.77      0.73       960\n",
      "\n",
      "    accuracy                           0.70      1880\n",
      "   macro avg       0.71      0.70      0.70      1880\n",
      "weighted avg       0.71      0.70      0.70      1880\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[579 341]\n",
      " [217 743]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 9.02 seconds\n"
     ]
    }
   ],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_mu_cv_fixed\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_mu_cv_fixed.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "label_column = 't_ac_target' \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0aa01",
   "metadata": {},
   "source": [
    "Changing ``cv_target``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè Standardized dataset:\n",
      "   NaN values: 0\n",
      "Data preparation for SVM:\n",
      "  Feature matrix shape: (9600, 194)\n",
      "  Labels shape: (9600,)\n",
      "  Number of classes: 2\n",
      "  Class distribution: [4800 4800]\n",
      "  Memory usage: 14.21 MB\n",
      "‚úÖ Data ready for SVM classification!\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.92 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       960\n",
      "           1       0.91      0.93      0.92       960\n",
      "\n",
      "    accuracy                           0.92      1920\n",
      "   macro avg       0.92      0.92      0.92      1920\n",
      "weighted avg       0.92      0.92      0.92      1920\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[877  83]\n",
      " [ 72 888]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 2.05 seconds\n",
      "\n",
      "üîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\n",
      "=== SVM (RBF Kernel) Classification Accuracy: 0.91 ===\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       960\n",
      "           1       0.90      0.93      0.91       960\n",
      "\n",
      "    accuracy                           0.91      1920\n",
      "   macro avg       0.91      0.91      0.91      1920\n",
      "weighted avg       0.91      0.91      0.91      1920\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[866  94]\n",
      " [ 72 888]]\n",
      "‚è±Ô∏è  SVM (rbf) training and evaluation time: 2.17 seconds\n"
     ]
    }
   ],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_mu_t_ac_fixed\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_mu_t_ac_fixed.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "label_column = \"cv_target\" \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28088bbf",
   "metadata": {},
   "source": [
    "Changing ``mu_target``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Set up directory paths for data loading ######\n",
    "BASE_DIR = Path.cwd().parent\n",
    "OUT_DIR = BASE_DIR\n",
    "SYNTHETIC_DIR = BASE_DIR / \"data_7_cv_t_ac_fixed\" \n",
    "RESULTS_CSV = \"IY010_simulation_parameters_7_cv_t_ac_fixed.csv\"\n",
    "results_csv_path = BASE_DIR / RESULTS_CSV\n",
    "results = pd.read_csv(results_csv_path)\n",
    "results = results[results[\"success\"]].dropna(\n",
    "    subset=[\"mu_observed\", \"cv_observed\", \"t_ac_observed\"]\n",
    ")\n",
    "\n",
    "label_column = \"mu_target\" \n",
    "labelled_results = add_binary_labels(results, label_column)\n",
    "# labelled_results = add_nearest_neighbour_labels(results, positive_on=label_column)\n",
    "##### Set up directory paths for data loading ######\n",
    "\n",
    "##### Use standardise_time_series utility function ######\n",
    "# Collect all DataFrames and their labels\n",
    "data_frames = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    trajectory_filename = results[\"trajectory_filename\"].values[i]\n",
    "    DATA_CSV = SYNTHETIC_DIR / trajectory_filename\n",
    "    data = pd.read_csv(DATA_CSV)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "    # Get the corresponding label from the results csv\n",
    "    label_value = labelled_results[labelled_results['trajectory_filename'] == trajectory_filename]['label'].iloc[0]\n",
    "    labels.append(label_value)\n",
    "\n",
    "# Use the utility function to standardize\n",
    "labelled_data = standardise_time_series(data_frames, labels=labels, prefix=\"t_\")\n",
    "\n",
    "print(f\"üìè Standardized dataset:\")\n",
    "print(f\"   NaN values: {labelled_data.isnull().sum().sum()}\")\n",
    "##### Use standardise_time_series utility function ######\n",
    "\n",
    "# =========================================================\n",
    "# Prepare Features and Labels for SVM\n",
    "# =========================================================\n",
    "df = labelled_data.copy()\n",
    "# Extract labels\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Extract features (all columns except 'label')\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(f\"Data preparation for SVM:\")\n",
    "print(f\"  Feature matrix shape: {X.shape}\")\n",
    "print(f\"  Labels shape: {y.shape}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"  Class distribution: {np.bincount(y)}\")\n",
    "print(f\"  Memory usage: {X.nbytes / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for any NaN or infinite values\n",
    "if np.any(np.isnan(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: NaN values detected in features\")\n",
    "if np.any(np.isinf(X)):\n",
    "    print(\"‚ö†Ô∏è  Warning: Infinite values detected in features\")\n",
    "    \n",
    "print(\"‚úÖ Data ready for SVM classification!\")\n",
    "\n",
    "# SVM Parameters (using defaults from svm_classifier function)\n",
    "SVM_C = 1.0           # Regularization parameter\n",
    "SVM_GAMMA = 'scale'   # Kernel coefficient \n",
    "SVM_KERNEL = 'rbf'    # Kernel type\n",
    "\n",
    "# Train/test split ratio\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SPLIT, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM using the imported svm_classifier function\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")\n",
    "\n",
    "# =========================================================\n",
    "# Experiment: Does Temporal Order Matter for Classification?\n",
    "# =========================================================\n",
    "print(\"\\nüîÄ Experiment: Shuffling Time Series Data to Test Temporal Order Impact\")\n",
    "# Use the utility function to create shuffled data\n",
    "df_shuffled = shuffle_time_series(\n",
    "    df, \n",
    "    preserve_columns=['label'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Extract features and labels from shuffled data\n",
    "y_shuffled = df_shuffled[\"label\"].values\n",
    "X_shuffled = df_shuffled.drop(columns=[\"label\"]).values\n",
    "\n",
    "# Split the shuffled data\n",
    "X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled = train_test_split(\n",
    "    X_shuffled, \n",
    "    y_shuffled, \n",
    "    test_size=TEST_SPLIT,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train SVM on shuffled data\n",
    "svm_accuracy_shuffled = svm_classifier(\n",
    "    X_train_shuffled, X_test_shuffled, y_train_shuffled, y_test_shuffled,\n",
    "    svm_C=SVM_C,\n",
    "    svm_gamma=SVM_GAMMA, \n",
    "    svm_kernel=SVM_KERNEL,\n",
    "    print_classification_report=True,\n",
    "    print_confusion_matrix=True,\n",
    ")\n",
    "training_time = time.time() - start_time\n",
    "print(f\"‚è±Ô∏è  SVM ({SVM_KERNEL}) training and evaluation time: {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880ec7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
