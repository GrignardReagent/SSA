Finding parameters where all CV ratios are biologically appropriate...

Starting simulations with:
Normal CV: 0.50, Mean: 20.00, Autocorrelation Time: 1.00
Running CV Ratio Simulations:   0%|          | 0/150 [00:00<?, ?it/s]
Testing CV ratio: 0.50, Stress CV: 0.25, Normal CV: 0.50
Corresponding variances - Stress: 25.00, Normal: 100.00
âœ… System is biologically appropriate with Fano factor: 1.25, CV: 0.25
Found valid solution for D=1.0: rho=23.56294874580673, sigma_u=0.07048350451280559, d=1.1380408824532606
Found solution: rho=23.5629, sigma_u=0.0705, d=1.1380
[STRESS] âœ… Found: {'rho': 23.56294874580673, 'sigma_u': 0.07048350451280559, 'd': 1.1380408824532606}
Found valid solution for D=1.0: rho=76.80355551351164, sigma_u=0.2861515182063994, d=2.985789560028585
Found solution: rho=76.8036, sigma_u=0.2862, d=2.9858
[NORMAL] âœ… Found: {'rho': 76.80355551351164, 'sigma_u': 0.2861515182063994, 'd': 2.985789560028585}
Updated Parameter Sets: [{'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}, {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 20.01
    - Variance: 25.03

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 20.02
    - Variance: 98.71
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2702, Train Acc: 0.5430
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.6242, Train Acc: 0.7578
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.4818, Train Acc: 0.7773
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.4274, Train Acc: 0.8164
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.3517, Train Acc: 0.8438
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/100], Loss: 0.2777, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.2721, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.1938, Train Acc: 0.9219
Validation Acc: 0.6250
No improvement (4/10).
Epoch [9/100], Loss: 0.1423, Train Acc: 0.9453
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/100], Loss: 0.1602, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [11/100], Loss: 0.1062, Train Acc: 0.9531
Validation Acc: 0.6562
No improvement (7/10).
Epoch [12/100], Loss: 0.0992, Train Acc: 0.9609
Validation Acc: 0.6875
No improvement (8/10).
Epoch [13/100], Loss: 0.1171, Train Acc: 0.9531
Validation Acc: 0.7188
Epoch [14/100], Loss: 0.1085, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [15/100], Loss: 0.0644, Train Acc: 0.9727
Validation Acc: 0.7188
No improvement (2/10).
Epoch [16/100], Loss: 0.0817, Train Acc: 0.9609
Validation Acc: 0.7188
No improvement (3/10).
Epoch [17/100], Loss: 0.0910, Train Acc: 0.9844
Validation Acc: 0.7031
No improvement (4/10).
Epoch [18/100], Loss: 0.0613, Train Acc: 0.9805
Validation Acc: 0.6875
No improvement (5/10).
Epoch [19/100], Loss: 0.0553, Train Acc: 0.9805
Validation Acc: 0.7031
No improvement (6/10).
Epoch [20/100], Loss: 0.0577, Train Acc: 0.9727
Validation Acc: 0.6875
No improvement (7/10).
Epoch [21/100], Loss: 0.0352, Train Acc: 0.9922
Validation Acc: 0.7031
No improvement (8/10).
Epoch [22/100], Loss: 0.0508, Train Acc: 0.9805
Validation Acc: 0.7031
No improvement (9/10).
Epoch [23/100], Loss: 0.0505, Train Acc: 0.9805
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.75 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6933, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6926, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6918, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6916, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6904, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6888, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6879, Train Acc: 0.4922
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6868, Train Acc: 0.5000
Validation Acc: 0.5156
Epoch [11/50], Loss: 0.6852, Train Acc: 0.5625
Validation Acc: 0.5469
Epoch [12/50], Loss: 0.6838, Train Acc: 0.5469
Validation Acc: 0.5781
Epoch [13/50], Loss: 0.6818, Train Acc: 0.6016
Validation Acc: 0.5938
Epoch [14/50], Loss: 0.6814, Train Acc: 0.5898
Validation Acc: 0.6719
Epoch [15/50], Loss: 0.6787, Train Acc: 0.5703
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.6732, Train Acc: 0.6016
Validation Acc: 0.8281
Epoch [17/50], Loss: 0.6688, Train Acc: 0.6367
Validation Acc: 0.8438
Epoch [18/50], Loss: 0.6669, Train Acc: 0.6328
Validation Acc: 0.8438
No improvement (1/10).
Epoch [19/50], Loss: 0.6637, Train Acc: 0.6680
Validation Acc: 0.8438
No improvement (2/10).
Epoch [20/50], Loss: 0.6527, Train Acc: 0.6992
Validation Acc: 0.8438
No improvement (3/10).
Epoch [21/50], Loss: 0.6444, Train Acc: 0.7461
Validation Acc: 0.9219
Epoch [22/50], Loss: 0.6399, Train Acc: 0.7734
Validation Acc: 0.8750
No improvement (1/10).
Epoch [23/50], Loss: 0.6538, Train Acc: 0.7617
Validation Acc: 0.8594
No improvement (2/10).
Epoch [24/50], Loss: 0.6578, Train Acc: 0.7422
Validation Acc: 0.8594
No improvement (3/10).
Epoch [25/50], Loss: 0.6456, Train Acc: 0.7578
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.6434, Train Acc: 0.7500
Validation Acc: 0.8750
No improvement (5/10).
Epoch [27/50], Loss: 0.6527, Train Acc: 0.7812
Validation Acc: 0.9219
No improvement (6/10).
Epoch [28/50], Loss: 0.6354, Train Acc: 0.8281
Validation Acc: 0.9375
Epoch [29/50], Loss: 0.6417, Train Acc: 0.8281
Validation Acc: 0.9375
No improvement (1/10).
Epoch [30/50], Loss: 0.6263, Train Acc: 0.8438
Validation Acc: 0.9375
No improvement (2/10).
Epoch [31/50], Loss: 0.6343, Train Acc: 0.8359
Validation Acc: 0.9375
No improvement (3/10).
Epoch [32/50], Loss: 0.6273, Train Acc: 0.8281
Validation Acc: 0.9531
Epoch [33/50], Loss: 0.6210, Train Acc: 0.8555
Validation Acc: 0.9375
No improvement (1/10).
Epoch [34/50], Loss: 0.6099, Train Acc: 0.8672
Validation Acc: 0.9375
No improvement (2/10).
Epoch [35/50], Loss: 0.6050, Train Acc: 0.8633
Validation Acc: 0.9375
No improvement (3/10).
Epoch [36/50], Loss: 0.6085, Train Acc: 0.8438
Validation Acc: 0.9375
No improvement (4/10).
Epoch [37/50], Loss: 0.6103, Train Acc: 0.8633
Validation Acc: 0.9375
No improvement (5/10).
Epoch [38/50], Loss: 0.6025, Train Acc: 0.8516
Validation Acc: 0.9375
No improvement (6/10).
Epoch [39/50], Loss: 0.6157, Train Acc: 0.8398
Validation Acc: 0.9375
No improvement (7/10).
Epoch [40/50], Loss: 0.6022, Train Acc: 0.8516
Validation Acc: 0.9375
No improvement (8/10).
Epoch [41/50], Loss: 0.6128, Train Acc: 0.8438
Validation Acc: 0.9375
No improvement (9/10).
Epoch [42/50], Loss: 0.6103, Train Acc: 0.8398
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 73.8936, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/100], Loss: 55.5732, Train Acc: 0.7969
Validation Acc: 0.8125
Epoch [3/100], Loss: 13.0358, Train Acc: 0.6445
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 5.4644, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 3.9997, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/100], Loss: 2.5163, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8826, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.8638, Train Acc: 0.5273
Validation Acc: 0.8906
Epoch [9/100], Loss: 1.9286, Train Acc: 0.4805
Validation Acc: 0.5000
No improvement (1/10).
Epoch [10/100], Loss: 1.9308, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [11/100], Loss: 1.8965, Train Acc: 0.4883
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/100], Loss: 1.8639, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (4/10).
Epoch [13/100], Loss: 1.8231, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (5/10).
Epoch [14/100], Loss: 1.9124, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (6/10)./home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Epoch [15/100], Loss: 1.8486, Train Acc: 0.5742
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/100], Loss: 1.7836, Train Acc: 0.5156
Validation Acc: 0.9688
Epoch [17/100], Loss: 1.8774, Train Acc: 0.5000
Validation Acc: 1.0000
Epoch [18/100], Loss: 1.8280, Train Acc: 0.5117
Validation Acc: 0.9688
No improvement (1/10).
Epoch [19/100], Loss: 1.7356, Train Acc: 0.6172
Validation Acc: 0.6562
No improvement (2/10).
Epoch [20/100], Loss: 1.7929, Train Acc: 0.5938
Validation Acc: 0.5156
No improvement (3/10).
Epoch [21/100], Loss: 1.7976, Train Acc: 0.5938
Validation Acc: 0.5000
No improvement (4/10).
Epoch [22/100], Loss: 1.7302, Train Acc: 0.6523
Validation Acc: 0.5469
No improvement (5/10).
Epoch [23/100], Loss: 1.8538, Train Acc: 0.5820
Validation Acc: 0.7344
No improvement (6/10).
Epoch [24/100], Loss: 1.8407, Train Acc: 0.5859
Validation Acc: 0.8906
No improvement (7/10).
Epoch [25/100], Loss: 1.7413, Train Acc: 0.5352
Validation Acc: 0.8281
No improvement (8/10).
Epoch [26/100], Loss: 1.8170, Train Acc: 0.6289
Validation Acc: 0.7031
No improvement (9/10).
Epoch [27/100], Loss: 1.7448, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8274, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0725, Train Acc: 0.5078
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.8304, Train Acc: 0.5078
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8367, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5729, Train Acc: 0.8828
Validation Acc: 0.9375
Epoch [6/50], Loss: 0.3812, Train Acc: 0.9531
Validation Acc: 0.8281
No improvement (1/10).
Epoch [7/50], Loss: 0.3431, Train Acc: 0.9609
Validation Acc: 0.9375
No improvement (2/10).
Epoch [8/50], Loss: 0.3081, Train Acc: 0.9570
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2899, Train Acc: 0.9688
Validation Acc: 0.9844
No improvement (1/10).
Epoch [10/50], Loss: 0.2782, Train Acc: 0.9766
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2911, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2770, Train Acc: 0.9727
Validation Acc: 1.0000
No improvement (2/10).
Epoch [13/50], Loss: 0.2636, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2480, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2466, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2515, Train Acc: 1.0000
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2541, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2502, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2375, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2367, Train Acc: 1.0000
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.0640, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/50], Loss: 4.0950, Train Acc: 0.5156
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/50], Loss: 3.9902, Train Acc: 0.5117
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/50], Loss: 3.9332, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/50], Loss: 3.3737, Train Acc: 0.5352
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/50], Loss: 3.2091, Train Acc: 0.5312
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/50], Loss: 2.9946, Train Acc: 0.5156
Validation Acc: 0.4688
No improvement (6/10).
Epoch [8/50], Loss: 3.0848, Train Acc: 0.5352
Validation Acc: 0.4062
No improvement (7/10).
Epoch [9/50], Loss: 2.6819, Train Acc: 0.5078
Validation Acc: 0.4531
No improvement (8/10).
Epoch [10/50], Loss: 2.5464, Train Acc: 0.4922
Validation Acc: 0.4531
No improvement (9/10).
Epoch [11/50], Loss: 2.4076, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 109.8736, Train Acc: 0.4883
Validation Acc: 0.5156
Epoch [2/50], Loss: 103.6514, Train Acc: 0.5469
Validation Acc: 0.7656
Epoch [3/50], Loss: 99.1449, Train Acc: 0.5742
Validation Acc: 0.6875
No improvement (1/10).
Epoch [4/50], Loss: 88.3863, Train Acc: 0.5391
Validation Acc: 0.6875
No improvement (2/10).
Epoch [5/50], Loss: 73.3845, Train Acc: 0.5625
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.1727, Train Acc: 0.5078
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 45.9971, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (5/10).
Epoch [8/50], Loss: 35.8162, Train Acc: 0.5391
Validation Acc: 0.6562
No improvement (6/10).
Epoch [9/50], Loss: 24.2596, Train Acc: 0.5820
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 16.6213, Train Acc: 0.5820
Validation Acc: 0.6562
No improvement (8/10).
Epoch [11/50], Loss: 12.4100, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (9/10).
Epoch [12/50], Loss: 8.5030, Train Acc: 0.5625
Validation Acc: 0.7812
Epoch [13/50], Loss: 6.9696, Train Acc: 0.5586
Validation Acc: 0.8594
Epoch [14/50], Loss: 6.6037, Train Acc: 0.5781
Validation Acc: 0.8750
Epoch [15/50], Loss: 6.0700, Train Acc: 0.6289
Validation Acc: 0.8906
Epoch [16/50], Loss: 6.1967, Train Acc: 0.6406
Validation Acc: 0.9062
Epoch [17/50], Loss: 5.2366, Train Acc: 0.6680
Validation Acc: 0.9219
Epoch [18/50], Loss: 5.3666, Train Acc: 0.6953
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 5.1544, Train Acc: 0.6328
Validation Acc: 0.8906
No improvement (2/10).
Epoch [20/50], Loss: 4.6081, Train Acc: 0.7305
Validation Acc: 0.8906
No improvement (3/10).
Epoch [21/50], Loss: 5.3200, Train Acc: 0.7070
Validation Acc: 0.8906
No improvement (4/10).
Epoch [22/50], Loss: 4.5428, Train Acc: 0.7578
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 5.2784, Train Acc: 0.7383
Validation Acc: 0.9062
No improvement (6/10).
Epoch [24/50], Loss: 4.9677, Train Acc: 0.7148
Validation Acc: 0.9062
No improvement (7/10).
Epoch [25/50], Loss: 4.6620, Train Acc: 0.7812
Validation Acc: 0.9375
Epoch [26/50], Loss: 4.2461, Train Acc: 0.7852
Validation Acc: 0.9531
Epoch [27/50], Loss: 4.2271, Train Acc: 0.7656
Validation Acc: 0.9531
No improvement (1/10).
Epoch [28/50], Loss: 4.2130, Train Acc: 0.7930
Validation Acc: 0.9531
No improvement (2/10).
Epoch [29/50], Loss: 4.3524, Train Acc: 0.7656
Validation Acc: 0.9531
No improvement (3/10).
Epoch [30/50], Loss: 4.1205, Train Acc: 0.7969
Validation Acc: 0.9688
Epoch [31/50], Loss: 3.7948, Train Acc: 0.7969
Validation Acc: 0.9688
No improvement (1/10).
Epoch [32/50], Loss: 4.0019, Train Acc: 0.8320
Validation Acc: 0.9688
No improvement (2/10).
Epoch [33/50], Loss: 3.6232, Train Acc: 0.8477
Validation Acc: 0.9688
No improvement (3/10).
Epoch [34/50], Loss: 4.0637, Train Acc: 0.8516
Validation Acc: 0.9688
No improvement (4/10).
Epoch [35/50], Loss: 4.0014, Train Acc: 0.7773
Validation Acc: 0.9688
No improvement (5/10).
Epoch [36/50], Loss: 3.8675, Train Acc: 0.8242
Validation Acc: 0.9688
No improvement (6/10).
Epoch [37/50], Loss: 3.8719, Train Acc: 0.8164
Validation Acc: 0.9688
No improvement (7/10).
Epoch [38/50], Loss: 4.2394, Train Acc: 0.8047
Validation Acc: 0.9688
No improvement (8/10).
Epoch [39/50], Loss: 3.6327, Train Acc: 0.8086
Validation Acc: 0.9688
No improvement (9/10).
Epoch [40/50], Loss: 3.9934, Train Acc: 0.8047
Validation Acc: 0.9688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 1.00 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.81s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:48<00:00, 25.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:48<00:00, 24.11s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.36s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.75s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.70s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 24.00s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.44s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 25.11s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.36s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 25.01s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.20s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.34s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.53s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 25.26s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.40s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.07048350451280559, 'sigma_b': 2.0, 'rho': 23.56294874580673, 'd': 1.1380408824532606, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:45<00:00, 24.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:45<00:00, 22.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.25_0.50/steady_state_trajectories/m_traj_cv_0.25_0.50_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.8 min):
    - Mean mRNA Count: 19.98
    - Variance: 25.38

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1257, Train Acc: 0.5586
Validation Acc: 0.6719
Epoch [2/100], Loss: 0.7789, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.5245, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.4183, Train Acc: 0.8242
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.3815, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (4/10).
Epoch [6/100], Loss: 0.2734, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (5/10).
Epoch [7/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (6/10).
Epoch [8/100], Loss: 0.1727, Train Acc: 0.9258
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.1795, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/100], Loss: 0.1466, Train Acc: 0.9492
Validation Acc: 0.7188
Epoch [11/100], Loss: 0.1188, Train Acc: 0.9453
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/100], Loss: 0.1201, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.1014, Train Acc: 0.9766
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.0876, Train Acc: 0.9648
Validation Acc: 0.7344
Epoch [15/100], Loss: 0.0480, Train Acc: 0.9883
Validation Acc: 0.7500
Epoch [16/100], Loss: 0.0611, Train Acc: 0.9766
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/100], Loss: 0.0646, Train Acc: 0.9883
Validation Acc: 0.7188
No improvement (2/10).
Epoch [18/100], Loss: 0.0762, Train Acc: 0.9648
Validation Acc: 0.7188
No improvement (3/10).
Epoch [19/100], Loss: 0.0852, Train Acc: 0.9688
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/100], Loss: 0.0347, Train Acc: 0.9922
Validation Acc: 0.7656
Epoch [21/100], Loss: 0.0323, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (1/10).
Epoch [22/100], Loss: 0.0732, Train Acc: 0.9766
Validation Acc: 0.7500
No improvement (2/10).
Epoch [23/100], Loss: 0.0490, Train Acc: 0.9883
Validation Acc: 0.7344
No improvement (3/10).
Epoch [24/100], Loss: 0.0299, Train Acc: 0.9961
Validation Acc: 0.7344
No improvement (4/10).
Epoch [25/100], Loss: 0.0540, Train Acc: 0.9844
Validation Acc: 0.7344
No improvement (5/10).
Epoch [26/100], Loss: 0.0242, Train Acc: 0.9844
Validation Acc: 0.7656
No improvement (6/10).
Epoch [27/100], Loss: 0.0244, Train Acc: 0.9961
Validation Acc: 0.7656
No improvement (7/10).
Epoch [28/100], Loss: 0.0323, Train Acc: 0.9883
Validation Acc: 0.7812
Epoch [29/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7656
No improvement (1/10).
Epoch [30/100], Loss: 0.0218, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (2/10).
Epoch [31/100], Loss: 0.0275, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (3/10).
Epoch [32/100], Loss: 0.0215, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (4/10).
Epoch [33/100], Loss: 0.0141, Train Acc: 1.0000
Validation Acc: 0.7500
No improvement (5/10).
Epoch [34/100], Loss: 0.0365, Train Acc: 0.9922
Validation Acc: 0.7500
No improvement (6/10).
Epoch [35/100], Loss: 0.0171, Train Acc: 0.9961
Validation Acc: 0.7500
No improvement (7/10).
Epoch [36/100], Loss: 0.0127, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (8/10).
Epoch [37/100], Loss: 0.0206, Train Acc: 0.9922
Validation Acc: 0.7344
No improvement (9/10).
Epoch [38/100], Loss: 0.0074, Train Acc: 1.0000
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6926, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6934, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6929, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6922, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6924, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6918, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6908, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6914, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6904, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6892, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.1598, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 56.9256, Train Acc: 0.7852
Validation Acc: 0.8281
Epoch [3/100], Loss: 14.2994, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.9044, Train Acc: 0.6367
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5924, Train Acc: 0.8555
Validation Acc: 0.9844
Epoch [6/100], Loss: 2.1729, Train Acc: 0.6406
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8514, Train Acc: 0.4844
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 1.9411, Train Acc: 0.5703
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.7509, Train Acc: 0.4844
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/100], Loss: 1.7839, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8674, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.8948, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7219, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (8/10).
Epoch [14/100], Loss: 1.7009, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (9/10).
Epoch [15/100], Loss: 1.8281, Train Acc: 0.5000
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.8229, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 3.0053, Train Acc: 0.5312
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6157, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.8026, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5506, Train Acc: 0.8828
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.3955, Train Acc: 0.9219
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3326, Train Acc: 0.9805
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.3368, Train Acc: 0.9492
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.3164, Train Acc: 0.9531
Validation Acc: 0.9844
Epoch [10/50], Loss: 0.2858, Train Acc: 0.9805
Validation Acc: 1.0000
Epoch [11/50], Loss: 0.2759, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [12/50], Loss: 0.2745, Train Acc: 0.9844
Validation Acc: 1.0000/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running CV Ratio Simulations:   1%|          | 1/150 [09:28<23:30:36, 568.03s/it]
No improvement (2/10).
Epoch [13/50], Loss: 0.2616, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (3/10).
Epoch [14/50], Loss: 0.2621, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (4/10).
Epoch [15/50], Loss: 0.2610, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (5/10).
Epoch [16/50], Loss: 0.2523, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (6/10).
Epoch [17/50], Loss: 0.2726, Train Acc: 0.9805
Validation Acc: 1.0000
No improvement (7/10).
Epoch [18/50], Loss: 0.2590, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (8/10).
Epoch [19/50], Loss: 0.2383, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (9/10).
Epoch [20/50], Loss: 0.2405, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.4098, Train Acc: 0.4766
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0814, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9286, Train Acc: 0.5156
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/50], Loss: 3.9428, Train Acc: 0.5352
Validation Acc: 0.5938
No improvement (3/10).
Epoch [5/50], Loss: 3.5337, Train Acc: 0.4883
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/50], Loss: 3.2652, Train Acc: 0.5234
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/50], Loss: 3.3655, Train Acc: 0.5312
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/50], Loss: 3.5800, Train Acc: 0.4844
Validation Acc: 0.4844
No improvement (7/10).
Epoch [9/50], Loss: 3.1130, Train Acc: 0.5195
Validation Acc: 0.4375
No improvement (8/10).
Epoch [10/50], Loss: 2.8128, Train Acc: 0.5000
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/50], Loss: 2.5306, Train Acc: 0.5273
Validation Acc: 0.4375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.39 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.1338, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 105.2788, Train Acc: 0.5547
Validation Acc: 0.8125
Epoch [3/50], Loss: 100.5803, Train Acc: 0.5742
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 89.0691, Train Acc: 0.5430
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.3313, Train Acc: 0.5156
Validation Acc: 0.6406
No improvement (3/10).
Epoch [6/50], Loss: 61.0731, Train Acc: 0.4844
Validation Acc: 0.6250
No improvement (4/10).
Epoch [7/50], Loss: 47.2729, Train Acc: 0.5195
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/50], Loss: 35.5563, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [9/50], Loss: 24.8195, Train Acc: 0.5938
Validation Acc: 0.6562
No improvement (7/10).
Epoch [10/50], Loss: 17.5670, Train Acc: 0.5625
Validation Acc: 0.6875
No improvement (8/10).
Epoch [11/50], Loss: 11.5651, Train Acc: 0.5273
Validation Acc: 0.7031
No improvement (9/10).
Epoch [12/50], Loss: 8.7902, Train Acc: 0.5391
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.76 ===
=== Random Classifier Accuracy: 0.45 ===

Testing CV ratio: 0.51, Stress CV: 0.26, Normal CV: 0.50
Corresponding variances - Stress: 26.01, Normal: 100.00
âœ… System is biologically appropriate with Fano factor: 1.30, CV: 0.26
Found valid solution for D=1.0: rho=24.20542087417708, sigma_u=0.0839654019088494, d=1.161507808719168
Found solution: rho=24.2054, sigma_u=0.0840, d=1.1615
[STRESS] âœ… Found: {'rho': 24.20542087417708, 'sigma_u': 0.0839654019088494, 'd': 1.161507808719168}
Found valid solution for D=1.0: rho=76.80355551351164, sigma_u=0.2861515182063994, d=2.985789560028585
Found solution: rho=76.8036, sigma_u=0.2862, d=2.9858
[NORMAL] âœ… Found: {'rho': 76.80355551351164, 'sigma_u': 0.2861515182063994, 'd': 2.985789560028585}
Updated Parameter Sets: [{'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}, {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.55s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.55s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.26_0.50/steady_state_trajectories/m_traj_cv_0.26_0.50_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.6 min):
    - Mean mRNA Count: 19.96
    - Variance: 26.39

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1296, Train Acc: 0.5898
Validation Acc: 0.7344
Epoch [2/100], Loss: 0.8310, Train Acc: 0.6680
Validation Acc: 0.7656
Epoch [3/100], Loss: 0.6391, Train Acc: 0.7422
Validation Acc: 0.7812
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [5/100], Loss: 0.3902, Train Acc: 0.8242
Validation Acc: 0.8125
Epoch [6/100], Loss: 0.3377, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/100], Loss: 0.2660, Train Acc: 0.8945
Validation Acc: 0.7812
No improvement (2/10).
Epoch [8/100], Loss: 0.2214, Train Acc: 0.8828
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/100], Loss: 0.2388, Train Acc: 0.9023
Validation Acc: 0.7656
No improvement (4/10).
Epoch [10/100], Loss: 0.1685, Train Acc: 0.9336
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/100], Loss: 0.1399, Train Acc: 0.9609
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/100], Loss: 0.1689, Train Acc: 0.9141
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/100], Loss: 0.0960, Train Acc: 0.9688
Validation Acc: 0.8281
Epoch [14/100], Loss: 0.1272, Train Acc: 0.9453
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/100], Loss: 0.0979, Train Acc: 0.9570
Validation Acc: 0.7812
No improvement (2/10).
Epoch [16/100], Loss: 0.0967, Train Acc: 0.9727
Validation Acc: 0.7656
No improvement (3/10).
Epoch [17/100], Loss: 0.0837, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (4/10).
Epoch [18/100], Loss: 0.0649, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (5/10).
Epoch [19/100], Loss: 0.0864, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (6/10).
Epoch [20/100], Loss: 0.0544, Train Acc: 0.9805
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/100], Loss: 0.0592, Train Acc: 0.9805
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/100], Loss: 0.0828, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/100], Loss: 0.0563, Train Acc: 0.9805
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6932, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6916, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6912, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6902, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6887, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6889, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6869, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6851, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.2314, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 57.0518, Train Acc: 0.7734
Validation Acc: 0.7969
Epoch [3/100], Loss: 14.2531, Train Acc: 0.6523
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.7022, Train Acc: 0.5859
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5770, Train Acc: 0.8555
Validation Acc: 0.8750
Epoch [6/100], Loss: 2.1200, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8991, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.9059, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.8949, Train Acc: 0.4688
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/100], Loss: 1.9018, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8866, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.9102, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7706, Train Acc: 0.5117
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/100], Loss: 1.7830, Train Acc: 0.5117
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 1.8574, Train Acc: 0.5195
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.74 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.7771, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 2.9730, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6087, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.7000, Train Acc: 0.7617
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5028, Train Acc: 0.8867
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.4259, Train Acc: 0.9297
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3631, Train Acc: 0.9688
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.3300, Train Acc: 0.9688
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2968, Train Acc: 0.9727
Validation Acc: 1.0000
Epoch [10/50], Loss: 0.2675, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [11/50], Loss: 0.2815, Train Acc: 0.9766
Validation Acc: 1.0000
No improvement (2/10).
Epoch [12/50], Loss: 0.2703, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [13/50], Loss: 0.2542, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (4/10).
Epoch [14/50], Loss: 0.2583, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (5/10).
Epoch [15/50], Loss: 0.2580, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (6/10).
Epoch [16/50], Loss: 0.2490, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (7/10).
Epoch [17/50], Loss: 0.2663, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (8/10).
Epoch [18/50], Loss: 0.2428, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (9/10).
Epoch [19/50], Loss: 0.2431, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.3181, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0027, Train Acc: 0.5430
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9033, Train Acc: 0.5195
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/50], Loss: 3.9613, Train Acc: 0.5000
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/50], Loss: 3.5342, Train Acc: 0.5039
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/50], Loss: 3.2631, Train Acc: 0.5508/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/50], Loss: 3.4481, Train Acc: 0.5312
Validation Acc: 0.4219
No improvement (6/10).
Epoch [8/50], Loss: 3.5312, Train Acc: 0.4883
Validation Acc: 0.4688
No improvement (7/10).
Epoch [9/50], Loss: 3.1923, Train Acc: 0.4922
Validation Acc: 0.4688
No improvement (8/10).
Epoch [10/50], Loss: 2.9157, Train Acc: 0.4844
Validation Acc: 0.4688
No improvement (9/10).
Epoch [11/50], Loss: 2.6803, Train Acc: 0.5273
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.46 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.6598, Train Acc: 0.5352
Validation Acc: 0.5156
Epoch [2/50], Loss: 104.5512, Train Acc: 0.5625
Validation Acc: 0.8125
Epoch [3/50], Loss: 101.6188, Train Acc: 0.5859
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 90.6726, Train Acc: 0.5273
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.8675, Train Acc: 0.5430
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.8994, Train Acc: 0.4922
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 47.5925, Train Acc: 0.5078
Validation Acc: 0.6875
No improvement (5/10).
Epoch [8/50], Loss: 35.8999, Train Acc: 0.5195
Validation Acc: 0.6875
No improvement (6/10).
Epoch [9/50], Loss: 24.7700, Train Acc: 0.6016
Validation Acc: 0.7188
No improvement (7/10).
Epoch [10/50], Loss: 17.4738, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (8/10).
Epoch [11/50], Loss: 11.7368, Train Acc: 0.5234
Validation Acc: 0.7656
No improvement (9/10).
Epoch [12/50], Loss: 8.8099, Train Acc: 0.5664
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 25.27s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.48s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.26_0.50/steady_state_trajectories/m_traj_cv_0.26_0.50_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.6 min):
    - Mean mRNA Count: 19.96
    - Variance: 26.39

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1296, Train Acc: 0.5898
Validation Acc: 0.7344
Epoch [2/100], Loss: 0.8310, Train Acc: 0.6680
Validation Acc: 0.7656
Epoch [3/100], Loss: 0.6391, Train Acc: 0.7422
Validation Acc: 0.7812
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [5/100], Loss: 0.3902, Train Acc: 0.8242
Validation Acc: 0.8125
Epoch [6/100], Loss: 0.3377, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/100], Loss: 0.2660, Train Acc: 0.8945
Validation Acc: 0.7812
No improvement (2/10).
Epoch [8/100], Loss: 0.2214, Train Acc: 0.8828
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/100], Loss: 0.2388, Train Acc: 0.9023
Validation Acc: 0.7656
No improvement (4/10).
Epoch [10/100], Loss: 0.1685, Train Acc: 0.9336
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/100], Loss: 0.1399, Train Acc: 0.9609
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/100], Loss: 0.1689, Train Acc: 0.9141
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/100], Loss: 0.0960, Train Acc: 0.9688
Validation Acc: 0.8281
Epoch [14/100], Loss: 0.1272, Train Acc: 0.9453
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/100], Loss: 0.0979, Train Acc: 0.9570
Validation Acc: 0.7812
No improvement (2/10).
Epoch [16/100], Loss: 0.0967, Train Acc: 0.9727
Validation Acc: 0.7656
No improvement (3/10).
Epoch [17/100], Loss: 0.0837, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (4/10).
Epoch [18/100], Loss: 0.0649, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (5/10).
Epoch [19/100], Loss: 0.0864, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (6/10).
Epoch [20/100], Loss: 0.0544, Train Acc: 0.9805
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/100], Loss: 0.0592, Train Acc: 0.9805
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/100], Loss: 0.0828, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/100], Loss: 0.0563, Train Acc: 0.9805
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6932, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6916, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6912, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6902, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6887, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6889, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6869, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6851, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.2314, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 57.0518, Train Acc: 0.7734
Validation Acc: 0.7969
Epoch [3/100], Loss: 14.2531, Train Acc: 0.6523
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.7022, Train Acc: 0.5859
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5770, Train Acc: 0.8555
Validation Acc: 0.8750
Epoch [6/100], Loss: 2.1200, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8991, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.9059, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.8949, Train Acc: 0.4688
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/100], Loss: 1.9018, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8866, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.9102, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7706, Train Acc: 0.5117
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/100], Loss: 1.7830, Train Acc: 0.5117
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 1.8574, Train Acc: 0.5195
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.74 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.7771, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 2.9730, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6087, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.7000, Train Acc: 0.7617
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5028, Train Acc: 0.8867
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.4259, Train Acc: 0.9297
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3631, Train Acc: 0.9688
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.3300, Train Acc: 0.9688
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2968, Train Acc: 0.9727
Validation Acc: 1.0000
Epoch [10/50], Loss: 0.2675, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [11/50], Loss: 0.2815, Train Acc: 0.9766
Validation Acc: 1.0000
No improvement (2/10).
Epoch [12/50], Loss: 0.2703, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [13/50], Loss: 0.2542, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (4/10).
Epoch [14/50], Loss: 0.2583, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (5/10).
Epoch [15/50], Loss: 0.2580, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (6/10).
Epoch [16/50], Loss: 0.2490, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (7/10).
Epoch [17/50], Loss: 0.2663, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (8/10).
Epoch [18/50], Loss: 0.2428, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (9/10).
Epoch [19/50], Loss: 0.2431, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.3181, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0027, Train Acc: 0.5430
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9033, Train Acc: 0.5195
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/50], Loss: 3.9613, Train Acc: 0.5000
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/50], Loss: 3.5342, Train Acc: 0.5039
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/50], Loss: 3.2631, Train Acc: 0.5508/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/50], Loss: 3.4481, Train Acc: 0.5312
Validation Acc: 0.4219
No improvement (6/10).
Epoch [8/50], Loss: 3.5312, Train Acc: 0.4883
Validation Acc: 0.4688
No improvement (7/10).
Epoch [9/50], Loss: 3.1923, Train Acc: 0.4922
Validation Acc: 0.4688
No improvement (8/10).
Epoch [10/50], Loss: 2.9157, Train Acc: 0.4844
Validation Acc: 0.4688
No improvement (9/10).
Epoch [11/50], Loss: 2.6803, Train Acc: 0.5273
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.46 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.6598, Train Acc: 0.5352
Validation Acc: 0.5156
Epoch [2/50], Loss: 104.5512, Train Acc: 0.5625
Validation Acc: 0.8125
Epoch [3/50], Loss: 101.6188, Train Acc: 0.5859
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 90.6726, Train Acc: 0.5273
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.8675, Train Acc: 0.5430
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.8994, Train Acc: 0.4922
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 47.5925, Train Acc: 0.5078
Validation Acc: 0.6875
No improvement (5/10).
Epoch [8/50], Loss: 35.8999, Train Acc: 0.5195
Validation Acc: 0.6875
No improvement (6/10).
Epoch [9/50], Loss: 24.7700, Train Acc: 0.6016
Validation Acc: 0.7188
No improvement (7/10).
Epoch [10/50], Loss: 17.4738, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (8/10).
Epoch [11/50], Loss: 11.7368, Train Acc: 0.5234
Validation Acc: 0.7656
No improvement (9/10).
Epoch [12/50], Loss: 8.8099, Train Acc: 0.5664
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.28s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 25.05s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.28s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.26_0.50/steady_state_trajectories/m_traj_cv_0.26_0.50_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.6 min):
    - Mean mRNA Count: 19.96
    - Variance: 26.39

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1296, Train Acc: 0.5898
Validation Acc: 0.7344
Epoch [2/100], Loss: 0.8310, Train Acc: 0.6680
Validation Acc: 0.7656
Epoch [3/100], Loss: 0.6391, Train Acc: 0.7422
Validation Acc: 0.7812
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [5/100], Loss: 0.3902, Train Acc: 0.8242
Validation Acc: 0.8125
Epoch [6/100], Loss: 0.3377, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/100], Loss: 0.2660, Train Acc: 0.8945
Validation Acc: 0.7812
No improvement (2/10).
Epoch [8/100], Loss: 0.2214, Train Acc: 0.8828
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/100], Loss: 0.2388, Train Acc: 0.9023
Validation Acc: 0.7656
No improvement (4/10).
Epoch [10/100], Loss: 0.1685, Train Acc: 0.9336
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/100], Loss: 0.1399, Train Acc: 0.9609
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/100], Loss: 0.1689, Train Acc: 0.9141
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/100], Loss: 0.0960, Train Acc: 0.9688
Validation Acc: 0.8281
Epoch [14/100], Loss: 0.1272, Train Acc: 0.9453
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/100], Loss: 0.0979, Train Acc: 0.9570
Validation Acc: 0.7812
No improvement (2/10).
Epoch [16/100], Loss: 0.0967, Train Acc: 0.9727
Validation Acc: 0.7656
No improvement (3/10).
Epoch [17/100], Loss: 0.0837, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (4/10).
Epoch [18/100], Loss: 0.0649, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (5/10).
Epoch [19/100], Loss: 0.0864, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (6/10).
Epoch [20/100], Loss: 0.0544, Train Acc: 0.9805
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/100], Loss: 0.0592, Train Acc: 0.9805
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/100], Loss: 0.0828, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/100], Loss: 0.0563, Train Acc: 0.9805
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6932, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6916, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6912, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6902, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6887, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6889, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6869, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6851, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.2314, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 57.0518, Train Acc: 0.7734
Validation Acc: 0.7969
Epoch [3/100], Loss: 14.2531, Train Acc: 0.6523
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.7022, Train Acc: 0.5859
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5770, Train Acc: 0.8555
Validation Acc: 0.8750
Epoch [6/100], Loss: 2.1200, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8991, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.9059, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.8949, Train Acc: 0.4688
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/100], Loss: 1.9018, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8866, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.9102, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7706, Train Acc: 0.5117
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/100], Loss: 1.7830, Train Acc: 0.5117
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 1.8574, Train Acc: 0.5195
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.74 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.7771, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 2.9730, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6087, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.7000, Train Acc: 0.7617
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5028, Train Acc: 0.8867
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.4259, Train Acc: 0.9297
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3631, Train Acc: 0.9688
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.3300, Train Acc: 0.9688
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2968, Train Acc: 0.9727
Validation Acc: 1.0000
Epoch [10/50], Loss: 0.2675, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [11/50], Loss: 0.2815, Train Acc: 0.9766
Validation Acc: 1.0000
No improvement (2/10).
Epoch [12/50], Loss: 0.2703, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [13/50], Loss: 0.2542, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (4/10).
Epoch [14/50], Loss: 0.2583, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (5/10).
Epoch [15/50], Loss: 0.2580, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (6/10).
Epoch [16/50], Loss: 0.2490, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (7/10).
Epoch [17/50], Loss: 0.2663, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (8/10).
Epoch [18/50], Loss: 0.2428, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (9/10).
Epoch [19/50], Loss: 0.2431, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.3181, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0027, Train Acc: 0.5430
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9033, Train Acc: 0.5195
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/50], Loss: 3.9613, Train Acc: 0.5000
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/50], Loss: 3.5342, Train Acc: 0.5039
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/50], Loss: 3.2631, Train Acc: 0.5508/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/50], Loss: 3.4481, Train Acc: 0.5312
Validation Acc: 0.4219
No improvement (6/10).
Epoch [8/50], Loss: 3.5312, Train Acc: 0.4883
Validation Acc: 0.4688
No improvement (7/10).
Epoch [9/50], Loss: 3.1923, Train Acc: 0.4922
Validation Acc: 0.4688
No improvement (8/10).
Epoch [10/50], Loss: 2.9157, Train Acc: 0.4844
Validation Acc: 0.4688
No improvement (9/10).
Epoch [11/50], Loss: 2.6803, Train Acc: 0.5273
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.46 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.6598, Train Acc: 0.5352
Validation Acc: 0.5156
Epoch [2/50], Loss: 104.5512, Train Acc: 0.5625
Validation Acc: 0.8125
Epoch [3/50], Loss: 101.6188, Train Acc: 0.5859
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 90.6726, Train Acc: 0.5273
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.8675, Train Acc: 0.5430
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.8994, Train Acc: 0.4922
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 47.5925, Train Acc: 0.5078
Validation Acc: 0.6875
No improvement (5/10).
Epoch [8/50], Loss: 35.8999, Train Acc: 0.5195
Validation Acc: 0.6875
No improvement (6/10).
Epoch [9/50], Loss: 24.7700, Train Acc: 0.6016
Validation Acc: 0.7188
No improvement (7/10).
Epoch [10/50], Loss: 17.4738, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (8/10).
Epoch [11/50], Loss: 11.7368, Train Acc: 0.5234
Validation Acc: 0.7656
No improvement (9/10).
Epoch [12/50], Loss: 8.8099, Train Acc: 0.5664
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.43s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 24.96s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:46<00:00, 23.23s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.26_0.50/steady_state_trajectories/m_traj_cv_0.26_0.50_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.6 min):
    - Mean mRNA Count: 19.96
    - Variance: 26.39

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1296, Train Acc: 0.5898
Validation Acc: 0.7344
Epoch [2/100], Loss: 0.8310, Train Acc: 0.6680
Validation Acc: 0.7656
Epoch [3/100], Loss: 0.6391, Train Acc: 0.7422
Validation Acc: 0.7812
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [5/100], Loss: 0.3902, Train Acc: 0.8242
Validation Acc: 0.8125
Epoch [6/100], Loss: 0.3377, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/100], Loss: 0.2660, Train Acc: 0.8945
Validation Acc: 0.7812
No improvement (2/10).
Epoch [8/100], Loss: 0.2214, Train Acc: 0.8828
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/100], Loss: 0.2388, Train Acc: 0.9023
Validation Acc: 0.7656
No improvement (4/10).
Epoch [10/100], Loss: 0.1685, Train Acc: 0.9336
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/100], Loss: 0.1399, Train Acc: 0.9609
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/100], Loss: 0.1689, Train Acc: 0.9141
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/100], Loss: 0.0960, Train Acc: 0.9688
Validation Acc: 0.8281
Epoch [14/100], Loss: 0.1272, Train Acc: 0.9453
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/100], Loss: 0.0979, Train Acc: 0.9570
Validation Acc: 0.7812
No improvement (2/10).
Epoch [16/100], Loss: 0.0967, Train Acc: 0.9727
Validation Acc: 0.7656
No improvement (3/10).
Epoch [17/100], Loss: 0.0837, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (4/10).
Epoch [18/100], Loss: 0.0649, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (5/10).
Epoch [19/100], Loss: 0.0864, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (6/10).
Epoch [20/100], Loss: 0.0544, Train Acc: 0.9805
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/100], Loss: 0.0592, Train Acc: 0.9805
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/100], Loss: 0.0828, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/100], Loss: 0.0563, Train Acc: 0.9805
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6932, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6916, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6912, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6902, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6887, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6889, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6869, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6851, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.2314, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 57.0518, Train Acc: 0.7734
Validation Acc: 0.7969
Epoch [3/100], Loss: 14.2531, Train Acc: 0.6523
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.7022, Train Acc: 0.5859
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5770, Train Acc: 0.8555
Validation Acc: 0.8750
Epoch [6/100], Loss: 2.1200, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8991, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.9059, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.8949, Train Acc: 0.4688
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/100], Loss: 1.9018, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8866, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.9102, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7706, Train Acc: 0.5117
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/100], Loss: 1.7830, Train Acc: 0.5117
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 1.8574, Train Acc: 0.5195
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.74 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.7771, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 2.9730, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6087, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.7000, Train Acc: 0.7617
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5028, Train Acc: 0.8867
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.4259, Train Acc: 0.9297
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3631, Train Acc: 0.9688
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.3300, Train Acc: 0.9688
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2968, Train Acc: 0.9727
Validation Acc: 1.0000
Epoch [10/50], Loss: 0.2675, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [11/50], Loss: 0.2815, Train Acc: 0.9766
Validation Acc: 1.0000
No improvement (2/10).
Epoch [12/50], Loss: 0.2703, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [13/50], Loss: 0.2542, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (4/10).
Epoch [14/50], Loss: 0.2583, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (5/10).
Epoch [15/50], Loss: 0.2580, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (6/10).
Epoch [16/50], Loss: 0.2490, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (7/10).
Epoch [17/50], Loss: 0.2663, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (8/10).
Epoch [18/50], Loss: 0.2428, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (9/10).
Epoch [19/50], Loss: 0.2431, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.3181, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0027, Train Acc: 0.5430
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9033, Train Acc: 0.5195
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/50], Loss: 3.9613, Train Acc: 0.5000
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/50], Loss: 3.5342, Train Acc: 0.5039
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/50], Loss: 3.2631, Train Acc: 0.5508/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/50], Loss: 3.4481, Train Acc: 0.5312
Validation Acc: 0.4219
No improvement (6/10).
Epoch [8/50], Loss: 3.5312, Train Acc: 0.4883
Validation Acc: 0.4688
No improvement (7/10).
Epoch [9/50], Loss: 3.1923, Train Acc: 0.4922
Validation Acc: 0.4688
No improvement (8/10).
Epoch [10/50], Loss: 2.9157, Train Acc: 0.4844
Validation Acc: 0.4688
No improvement (9/10).
Epoch [11/50], Loss: 2.6803, Train Acc: 0.5273
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.46 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.6598, Train Acc: 0.5352
Validation Acc: 0.5156
Epoch [2/50], Loss: 104.5512, Train Acc: 0.5625
Validation Acc: 0.8125
Epoch [3/50], Loss: 101.6188, Train Acc: 0.5859
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 90.6726, Train Acc: 0.5273
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.8675, Train Acc: 0.5430
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.8994, Train Acc: 0.4922
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 47.5925, Train Acc: 0.5078
Validation Acc: 0.6875
No improvement (5/10).
Epoch [8/50], Loss: 35.8999, Train Acc: 0.5195
Validation Acc: 0.6875
No improvement (6/10).
Epoch [9/50], Loss: 24.7700, Train Acc: 0.6016
Validation Acc: 0.7188
No improvement (7/10).
Epoch [10/50], Loss: 17.4738, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (8/10).
Epoch [11/50], Loss: 11.7368, Train Acc: 0.5234
Validation Acc: 0.7656
No improvement (9/10).
Epoch [12/50], Loss: 8.8099, Train Acc: 0.5664
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 25.32s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:47<00:00, 23.52s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 0.2861515182063994, 'sigma_b': 1.0, 'rho': 76.80355551351164, 'd': 2.985789560028585, 'label': 1}
Steady state series saved to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY007/data/mRNA_trajectories_cv_0.26_0.50/steady_state_trajectories/m_traj_cv_0.26_0.50_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 8.6 min):
    - Mean mRNA Count: 19.96
    - Variance: 26.39

  Normal Condition (after 3.3 min):
    - Mean mRNA Count: 19.95
    - Variance: 100.62
=== SVM (RBF Kernel) Classification Accuracy: 1.00 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 1.00 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1296, Train Acc: 0.5898
Validation Acc: 0.7344
Epoch [2/100], Loss: 0.8310, Train Acc: 0.6680
Validation Acc: 0.7656
Epoch [3/100], Loss: 0.6391, Train Acc: 0.7422
Validation Acc: 0.7812
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [5/100], Loss: 0.3902, Train Acc: 0.8242
Validation Acc: 0.8125
Epoch [6/100], Loss: 0.3377, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/100], Loss: 0.2660, Train Acc: 0.8945
Validation Acc: 0.7812
No improvement (2/10).
Epoch [8/100], Loss: 0.2214, Train Acc: 0.8828
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/100], Loss: 0.2388, Train Acc: 0.9023
Validation Acc: 0.7656
No improvement (4/10).
Epoch [10/100], Loss: 0.1685, Train Acc: 0.9336
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/100], Loss: 0.1399, Train Acc: 0.9609
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/100], Loss: 0.1689, Train Acc: 0.9141
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/100], Loss: 0.0960, Train Acc: 0.9688
Validation Acc: 0.8281
Epoch [14/100], Loss: 0.1272, Train Acc: 0.9453
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/100], Loss: 0.0979, Train Acc: 0.9570
Validation Acc: 0.7812
No improvement (2/10).
Epoch [16/100], Loss: 0.0967, Train Acc: 0.9727
Validation Acc: 0.7656
No improvement (3/10).
Epoch [17/100], Loss: 0.0837, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (4/10).
Epoch [18/100], Loss: 0.0649, Train Acc: 0.9766
Validation Acc: 0.8125
No improvement (5/10).
Epoch [19/100], Loss: 0.0864, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (6/10).
Epoch [20/100], Loss: 0.0544, Train Acc: 0.9805
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/100], Loss: 0.0592, Train Acc: 0.9805
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/100], Loss: 0.0828, Train Acc: 0.9648
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/100], Loss: 0.0563, Train Acc: 0.9805
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6925, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6932, Train Acc: 0.5273
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/50], Loss: 0.6916, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/50], Loss: 0.6912, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/50], Loss: 0.6902, Train Acc: 0.5742
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/50], Loss: 0.6887, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/50], Loss: 0.6889, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (8/10).
Epoch [10/50], Loss: 0.6869, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/50], Loss: 0.6851, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Long-Short Term Memory (LSTM) Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 75.2314, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/100], Loss: 57.0518, Train Acc: 0.7734
Validation Acc: 0.7969
Epoch [3/100], Loss: 14.2531, Train Acc: 0.6523
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 4.7022, Train Acc: 0.5859
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 4.5770, Train Acc: 0.8555
Validation Acc: 0.8750
Epoch [6/100], Loss: 2.1200, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/100], Loss: 1.8991, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/100], Loss: 1.9059, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/100], Loss: 1.8949, Train Acc: 0.4688
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/100], Loss: 1.9018, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/100], Loss: 1.8866, Train Acc: 0.4727
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/100], Loss: 1.9102, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (7/10).
Epoch [13/100], Loss: 1.7706, Train Acc: 0.5117
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/100], Loss: 1.7830, Train Acc: 0.5117
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 1.8574, Train Acc: 0.5195
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.74 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 3.7771, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 2.9730, Train Acc: 0.5156
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 1.6087, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.7000, Train Acc: 0.7617
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5028, Train Acc: 0.8867
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.4259, Train Acc: 0.9297
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.3631, Train Acc: 0.9688
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.3300, Train Acc: 0.9688
Validation Acc: 0.9844
Epoch [9/50], Loss: 0.2968, Train Acc: 0.9727
Validation Acc: 1.0000
Epoch [10/50], Loss: 0.2675, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (1/10).
Epoch [11/50], Loss: 0.2815, Train Acc: 0.9766
Validation Acc: 1.0000
No improvement (2/10).
Epoch [12/50], Loss: 0.2703, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (3/10).
Epoch [13/50], Loss: 0.2542, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (4/10).
Epoch [14/50], Loss: 0.2583, Train Acc: 0.9844
Validation Acc: 1.0000
No improvement (5/10).
Epoch [15/50], Loss: 0.2580, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (6/10).
Epoch [16/50], Loss: 0.2490, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (7/10).
Epoch [17/50], Loss: 0.2663, Train Acc: 0.9922
Validation Acc: 1.0000
No improvement (8/10).
Epoch [18/50], Loss: 0.2428, Train Acc: 0.9961
Validation Acc: 1.0000
No improvement (9/10).
Epoch [19/50], Loss: 0.2431, Train Acc: 0.9883
Validation Acc: 1.0000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D Preprocessing Accuracy: 1.00 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 4.3181, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/50], Loss: 4.0027, Train Acc: 0.5430
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/50], Loss: 3.9033, Train Acc: 0.5195
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/50], Loss: 3.9613, Train Acc: 0.5000
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/50], Loss: 3.5342, Train Acc: 0.5039
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/50], Loss: 3.2631, Train Acc: 0.5508/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(

Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/50], Loss: 3.4481, Train Acc: 0.5312
Validation Acc: 0.4219
No improvement (6/10).
Epoch [8/50], Loss: 3.5312, Train Acc: 0.4883
Validation Acc: 0.4688
No improvement (7/10).
Epoch [9/50], Loss: 3.1923, Train Acc: 0.4922
Validation Acc: 0.4688
No improvement (8/10).
Epoch [10/50], Loss: 2.9157, Train Acc: 0.4844
Validation Acc: 0.4688
No improvement (9/10).
Epoch [11/50], Loss: 2.6803, Train Acc: 0.5273
Validation Acc: 0.4531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Vanilla Transformer Accuracy: 0.46 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 110.6598, Train Acc: 0.5352
Validation Acc: 0.5156
Epoch [2/50], Loss: 104.5512, Train Acc: 0.5625
Validation Acc: 0.8125
Epoch [3/50], Loss: 101.6188, Train Acc: 0.5859
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 90.6726, Train Acc: 0.5273
Validation Acc: 0.6406
No improvement (2/10).
Epoch [5/50], Loss: 76.8675, Train Acc: 0.5430
Validation Acc: 0.6562
No improvement (3/10).
Epoch [6/50], Loss: 60.8994, Train Acc: 0.4922
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/50], Loss: 47.5925, Train Acc: 0.5078
Validation Acc: 0.6875
No improvement (5/10).
Epoch [8/50], Loss: 35.8999, Train Acc: 0.5195
Validation Acc: 0.6875
No improvement (6/10).
Epoch [9/50], Loss: 24.7700, Train Acc: 0.6016
Validation Acc: 0.7188
No improvement (7/10).
Epoch [10/50], Loss: 17.4738, Train Acc: 0.5430
Validation Acc: 0.7188
No improvement (8/10).
Epoch [11/50], Loss: 11.7368, Train Acc: 0.5234
Validation Acc: 0.7656
No improvement (9/10).
Epoch [12/50], Loss: 8.8099, Train Acc: 0.5664
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Transformer with Conv1D and Auxiliary Task Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:13<00:13, 13.61s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 0.0839654019088494, 'sigma_b': 2.0, 'rho': 24.20542087417708, 'd': 1.161507808719168, 'label': 0}
