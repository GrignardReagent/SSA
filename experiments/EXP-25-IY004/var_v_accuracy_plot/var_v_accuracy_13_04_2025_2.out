Running Variance Ratio Simulations:   0%|          | 0/35 [00:00<?, ?it/s]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
<lambdifygenerated-53>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-53>:2: RuntimeWarning: invalid value encountered in scalar add
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
[STRESS] âœ… Found: {'rho': 5953.275830160401, 'sigma_b': 0.02223949128203162, 'd': 0.7346358147580936}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138059896, 'sigma_b': 0.06014543999849558, 'd': 0.7827636158617439}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.45s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.52s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.76
    - Variance: 3371.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.71
    - Variance: 1159.02
=== SVM (RBF Kernel) Classification Accuracy: 0.59 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.64 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3432, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8181, Train Acc: 0.6797
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.6705, Train Acc: 0.6953
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.5822, Train Acc: 0.7617
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.4909, Train Acc: 0.7617
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4879, Train Acc: 0.7852
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.4896, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.3350, Train Acc: 0.8398
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.2985, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (1/10).
Epoch [10/100], Loss: 0.3458, Train Acc: 0.8359
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.3194, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (1/10).
Epoch [12/100], Loss: 0.2718, Train Acc: 0.8984
Validation Acc: 0.5938
No improvement (2/10).
Epoch [13/100], Loss: 0.2888, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (3/10).
Epoch [14/100], Loss: 0.2740, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (4/10).
Epoch [15/100], Loss: 0.2715, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (5/10).
Epoch [16/100], Loss: 0.2390, Train Acc: 0.8906
Validation Acc: 0.6094
No improvement (6/10).
Epoch [17/100], Loss: 0.2780, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (7/10).
Epoch [18/100], Loss: 0.1736, Train Acc: 0.9297
Validation Acc: 0.6406
No improvement (8/10).
Epoch [19/100], Loss: 0.2100, Train Acc: 0.9297
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1712, Train Acc: 0.9180
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.72 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8203
Validation Acc: 0.5938
Epoch [4/50], Loss: 0.6177, Train Acc: 0.8359
Validation Acc: 0.6875
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8594
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5755, Train Acc: 0.8242
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.5902, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (2/10).
Epoch [8/50], Loss: 0.5611, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (3/10).
Epoch [9/50], Loss: 0.5619, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (5/10).
Epoch [11/50], Loss: 0.5760, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5608, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/50], Loss: 0.5663, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (9/10).
Epoch [15/50], Loss: 0.5636, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5473, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (2/10).
Epoch [18/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5392, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [20/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5428, Train Acc: 0.8242
Validation Acc: 0.7812
No improvement (2/10).
Epoch [22/50], Loss: 0.5517, Train Acc: 0.8320
Validation Acc: 0.7656
No improvement (3/10).
Epoch [23/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5600, Train Acc: 0.7930
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (6/10).
Epoch [26/50], Loss: 0.5465, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (7/10).
Epoch [27/50], Loss: 0.5455, Train Acc: 0.8359
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6894, Train Acc: 0.6328
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6777, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6655, Train Acc: 0.6445
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6580, Train Acc: 0.6445
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6396, Train Acc: 0.6953
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.6215, Train Acc: 0.7109
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/50], Loss: 0.6673, Train Acc: 0.6211
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.6871, Train Acc: 0.5664
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.6417, Train Acc: 0.6680
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/50], Loss: 0.6297, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (6/10).
Epoch [12/50], Loss: 0.6334, Train Acc: 0.6836
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6226, Train Acc: 0.7031
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6130, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (9/10).
Epoch [15/50], Loss: 0.6094, Train Acc: 0.7344
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.91s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.98s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02223949128203162, 'rho': 5953.275830160401, 'd': 0.7346358147580936, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   3%|â–Ž         | 1/35 [14:22<8:08:36, 862.24s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849558, 'rho': 1179.1338138059896, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3179_1200/steady_state_trajectories/m_traj_3179.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3202.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4133, Train Acc: 0.4805
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.9099, Train Acc: 0.5977
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7841, Train Acc: 0.6914
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7681, Train Acc: 0.6680
Validation Acc: 0.5469
Epoch [5/100], Loss: 0.6345, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5597, Train Acc: 0.7305
Validation Acc: 0.5938
Epoch [7/100], Loss: 0.5358, Train Acc: 0.7617
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4179, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4522, Train Acc: 0.8008
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.4140, Train Acc: 0.7969
Validation Acc: 0.6406
Epoch [11/100], Loss: 0.4466, Train Acc: 0.7812
Validation Acc: 0.6562
Epoch [12/100], Loss: 0.3983, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3497, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (2/10).
Epoch [14/100], Loss: 0.3375, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.3118, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [16/100], Loss: 0.2883, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [17/100], Loss: 0.2887, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [18/100], Loss: 0.3036, Train Acc: 0.8750
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.3317, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (1/10).
Epoch [20/100], Loss: 0.2061, Train Acc: 0.9102
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2177, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (1/10).
Epoch [22/100], Loss: 0.2226, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (2/10).
Epoch [23/100], Loss: 0.1961, Train Acc: 0.9219
Validation Acc: 0.6406
No improvement (3/10).
Epoch [24/100], Loss: 0.2378, Train Acc: 0.9062
Validation Acc: 0.6562
No improvement (4/10).
Epoch [25/100], Loss: 0.1768, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (5/10).
Epoch [26/100], Loss: 0.2055, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (6/10).
Epoch [27/100], Loss: 0.2128, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (7/10).
Epoch [28/100], Loss: 0.2018, Train Acc: 0.9023
Validation Acc: 0.7031
Epoch [29/100], Loss: 0.1969, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (1/10).
Epoch [30/100], Loss: 0.1332, Train Acc: 0.9570
Validation Acc: 0.6562
No improvement (2/10).
Epoch [31/100], Loss: 0.1392, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (3/10).
Epoch [32/100], Loss: 0.1350, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (4/10).
Epoch [33/100], Loss: 0.1499, Train Acc: 0.9336
Validation Acc: 0.6406
No improvement (5/10).
Epoch [34/100], Loss: 0.1210, Train Acc: 0.9609
Validation Acc: 0.6719
No improvement (6/10).
Epoch [35/100], Loss: 0.1486, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (7/10).
Epoch [36/100], Loss: 0.1114, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (8/10).
Epoch [37/100], Loss: 0.1204, Train Acc: 0.9648
Validation Acc: 0.6562
No improvement (9/10).
Epoch [38/100], Loss: 0.1293, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8203
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6184, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5845, Train Acc: 0.8750
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5774, Train Acc: 0.7891
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5838, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.5614, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/50], Loss: 0.5629, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/50], Loss: 0.5556, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (4/10).
Epoch [11/50], Loss: 0.5663, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (5/10).
Epoch [12/50], Loss: 0.5477, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [13/50], Loss: 0.5614, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (1/10).
Epoch [14/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (2/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (3/10).
Epoch [16/50], Loss: 0.5414, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5536, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (5/10).
Epoch [18/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (6/10).
Epoch [19/50], Loss: 0.5453, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (7/10).
Epoch [20/50], Loss: 0.5328, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (8/10).
Epoch [21/50], Loss: 0.5492, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (9/10).
Epoch [22/50], Loss: 0.5467, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6706, Train Acc: 0.6484
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6523
Validation Acc: 0.6406
Epoch [5/50], Loss: 0.6486, Train Acc: 0.6797
Validation Acc: 0.6875
Epoch [6/50], Loss: 0.6289, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [7/50], Loss: 0.6002, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5991, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6122, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [11/50], Loss: 0.6001, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5961, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.6041, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (6/10).
Epoch [14/50], Loss: 0.5883, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5878, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5582, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (9/10).
Epoch [17/50], Loss: 0.5569, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.81 ===
Attempt 1/10
[STRESS] âœ… Found: {'rho': 5975.7576175588665, 'sigma_b': 0.02215574122838347, 'd': 0.7346365351446036}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813796912, 'sigma_b': 0.06014543999834102, 'd': 0.7827636158616957}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.38s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.47
    - Variance: 3361.87

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.61
    - Variance: 1067.43
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.47 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3472, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9186, Train Acc: 0.6367
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.8371, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6777, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5104, Train Acc: 0.7773
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4743, Train Acc: 0.7812
Validation Acc: 0.5625
No improvement (3/10).
Epoch [7/100], Loss: 0.4196, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (4/10).
Epoch [8/100], Loss: 0.3798, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3478, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (6/10).
Epoch [10/100], Loss: 0.3792, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.2983, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (8/10).
Epoch [12/100], Loss: 0.3142, Train Acc: 0.8633
Validation Acc: 0.5312
No improvement (9/10).
Epoch [13/100], Loss: 0.2575, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6662, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [4/50], Loss: 0.6175, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5948, Train Acc: 0.8438
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5835, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5640, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5679, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5613, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (5/10).
Epoch [11/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/50], Loss: 0.5525, Train Acc: 0.8203
Validation Acc: 0.7500
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.9062
Epoch [15/50], Loss: 0.5562, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5472, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (2/10).
Epoch [17/50], Loss: 0.5438, Train Acc: 0.8438
Validation Acc: 0.9062
No improvement (3/10).
Epoch [18/50], Loss: 0.5559, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (4/10).
Epoch [19/50], Loss: 0.5558, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (5/10).
Epoch [20/50], Loss: 0.5391, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (6/10).
Epoch [21/50], Loss: 0.5452, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (7/10).
Epoch [22/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [23/50], Loss: 0.5537, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (9/10).
Epoch [24/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5430
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6484
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6747, Train Acc: 0.6719
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6551, Train Acc: 0.6719
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6440, Train Acc: 0.6992
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.6086, Train Acc: 0.7461
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.6041, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.5929, Train Acc: 0.7695
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/50], Loss: 0.6094, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (4/10).
Epoch [10/50], Loss: 0.5929, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5806, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (6/10).
Epoch [12/50], Loss: 0.5822, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (7/10).
Epoch [13/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.7344
No improvement (8/10).
Epoch [14/50], Loss: 0.5968, Train Acc: 0.7500
Validation Acc: 0.7656
No improvement (9/10).
Epoch [15/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5761, Train Acc: 0.7734
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5767, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (2/10).
Epoch [18/50], Loss: 0.5670, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [19/50], Loss: 0.5728, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (4/10).
Epoch [20/50], Loss: 0.5646, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (5/10).
Epoch [21/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (6/10).
Epoch [22/50], Loss: 0.5689, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5640, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (8/10).
Epoch [24/50], Loss: 0.5605, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (9/10).
Epoch [25/50], Loss: 0.5607, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.02s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.91s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.86s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.94s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.80s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02215574122838347, 'rho': 5975.7576175588665, 'd': 0.7346365351446036, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   6%|â–Œ         | 2/35 [20:11<5:08:16, 560.51s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-42204>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-42204>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999834102, 'rho': 1179.133813796912, 'd': 0.7827636158616957, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3191_1200/steady_state_trajectories/m_traj_3191.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3127.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.44 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4816, Train Acc: 0.5195
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8953, Train Acc: 0.6484
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6867, Train Acc: 0.6914
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.7177, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/100], Loss: 0.6371, Train Acc: 0.7383
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4516, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.4726, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/100], Loss: 0.3922, Train Acc: 0.8164
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/100], Loss: 0.3898, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/100], Loss: 0.4427, Train Acc: 0.8320
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/100], Loss: 0.3018, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3304, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2731, Train Acc: 0.8711
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/100], Loss: 0.2767, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/100], Loss: 0.2770, Train Acc: 0.8906
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6914
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6199, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5949, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5790, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5894, Train Acc: 0.7734
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (2/10).
Epoch [9/50], Loss: 0.5788, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [10/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (4/10).
Epoch [11/50], Loss: 0.5758, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (5/10).
Epoch [12/50], Loss: 0.5671, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5472, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5594, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5329, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5417, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6755, Train Acc: 0.6719
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6528, Train Acc: 0.6914
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6363, Train Acc: 0.7109
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6196, Train Acc: 0.7188
Validation Acc: 0.7812
Epoch [7/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (2/10).
Epoch [9/50], Loss: 0.6173, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (3/10).
Epoch [10/50], Loss: 0.6186, Train Acc: 0.7070
Validation Acc: 0.7500
No improvement (4/10).
Epoch [11/50], Loss: 0.6016, Train Acc: 0.7305
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5962, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (2/10).
Epoch [14/50], Loss: 0.5990, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (3/10).
Epoch [15/50], Loss: 0.5943, Train Acc: 0.7305
Validation Acc: 0.7969
No improvement (4/10).
Epoch [16/50], Loss: 0.5901, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (5/10).
Epoch [17/50], Loss: 0.5793, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (6/10).
Epoch [18/50], Loss: 0.5769, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (7/10).
Epoch [19/50], Loss: 0.5785, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [21/50], Loss: 0.5770, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (2/10).
Epoch [22/50], Loss: 0.5717, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [23/50], Loss: 0.5755, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (4/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (5/10).
Epoch [25/50], Loss: 0.5663, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (6/10).
Epoch [26/50], Loss: 0.5650, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [27/50], Loss: 0.5632, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [28/50], Loss: 0.5690, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (9/10).
Epoch [29/50], Loss: 0.5673, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 5998.23950488924, 'sigma_b': 0.02207261957500077, 'd': 0.7346372501426729}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3150.43

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1185, Train Acc: 0.5625
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9958, Train Acc: 0.6055
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7974, Train Acc: 0.6797
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5829, Train Acc: 0.7266
Validation Acc: 0.6094
No improvement (3/10).
Epoch [5/100], Loss: 0.5501, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (4/10).
Epoch [6/100], Loss: 0.4874, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4695, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (6/10).
Epoch [8/100], Loss: 0.4054, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (7/10).
Epoch [9/100], Loss: 0.3765, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.3706, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (9/10).
Epoch [11/100], Loss: 0.2935, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [12/100], Loss: 0.2991, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (1/10).
Epoch [13/100], Loss: 0.3410, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (2/10).
Epoch [14/100], Loss: 0.2916, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (3/10).
Epoch [15/100], Loss: 0.2822, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [16/100], Loss: 0.2904, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (5/10).
Epoch [17/100], Loss: 0.2916, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (6/10).
Epoch [18/100], Loss: 0.2279, Train Acc: 0.8945
Validation Acc: 0.5625
No improvement (7/10).
Epoch [19/100], Loss: 0.2441, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (8/10).
Epoch [20/100], Loss: 0.2126, Train Acc: 0.9102
Validation Acc: 0.5625
No improvement (9/10).
Epoch [21/100], Loss: 0.2324, Train Acc: 0.8984
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6646, Train Acc: 0.8086
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6227, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5912, Train Acc: 0.8555
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (1/10).
Epoch [7/50], Loss: 0.5926, Train Acc: 0.7891
Validation Acc: 0.8438
Epoch [8/50], Loss: 0.5713, Train Acc: 0.8281
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.5794, Train Acc: 0.7852
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5628, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [11/50], Loss: 0.5927, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5491, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [13/50], Loss: 0.5642, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (3/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.8438
No improvement (4/10).
Epoch [15/50], Loss: 0.5425, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (5/10).
Epoch [16/50], Loss: 0.5359, Train Acc: 0.8633
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5307, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5455, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (2/10).
Epoch [19/50], Loss: 0.5359, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (3/10).
Epoch [20/50], Loss: 0.5217, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5297, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [22/50], Loss: 0.5231, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (6/10).
Epoch [23/50], Loss: 0.5227, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5348, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (8/10).
Epoch [25/50], Loss: 0.5208, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (9/10).
Epoch [26/50], Loss: 0.5396, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5547
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.6680
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6469, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6237, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (1/10).
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6024, Train Acc: 0.7539
Validation Acc: 0.7656
Epoch [8/50], Loss: 0.6000, Train Acc: 0.7461
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.6005, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.6061, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.6333, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (4/10).
Epoch [13/50], Loss: 0.7057, Train Acc: 0.5547
Validation Acc: 0.5000
No improvement (5/10).
Epoch [14/50], Loss: 0.6784, Train Acc: 0.5859
Validation Acc: 0.7656
No improvement (6/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (7/10).
Epoch [16/50], Loss: 0.5912, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (8/10).
Epoch [17/50], Loss: 0.5811, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (9/10).
Epoch [18/50], Loss: 0.5818, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.09s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.13s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.01s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.98s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02207261957500077, 'rho': 5998.23950488924, 'd': 0.7346372501426729, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   9%|â–Š         | 3/35 [43:17<8:19:54, 937.34s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-46910>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-46910>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3203_1200/steady_state_trajectories/m_traj_3203.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3428.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3999, Train Acc: 0.5625
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8288, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7198, Train Acc: 0.6641
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.5199, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.5551, Train Acc: 0.7578
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.4477, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3807, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3843, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3570, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3367, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2783, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2828, Train Acc: 0.8945
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6663, Train Acc: 0.8242
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6153, Train Acc: 0.8477
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5866, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5906, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5595, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (1/10).
Epoch [9/50], Loss: 0.5949, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5734, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.5943, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.5930, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (5/10).
Epoch [13/50], Loss: 0.5660, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (6/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (7/10).
Epoch [15/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [16/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [18/50], Loss: 0.5429, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (3/10).
Epoch [19/50], Loss: 0.5445, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (4/10).
Epoch [20/50], Loss: 0.5439, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (5/10).
Epoch [21/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (6/10).
Epoch [22/50], Loss: 0.5525, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (7/10).
Epoch [23/50], Loss: 0.5281, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [24/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (9/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6367
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6758, Train Acc: 0.6797
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6588, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6423, Train Acc: 0.7148
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6584, Train Acc: 0.6445
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6168, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6064, Train Acc: 0.7539
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5901, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/50], Loss: 0.6034, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.5734, Train Acc: 0.7812
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.5690, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.5682, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5539, Train Acc: 0.7930
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.5482, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.80 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6020.721341758363, 'sigma_b': 0.02199011929202661, 'd': 0.7346379598087545}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.80s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.17
    - Variance: 2802.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2292, Train Acc: 0.5430
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9731, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7679, Train Acc: 0.7227
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.5475, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5784, Train Acc: 0.7695
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.4322, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/100], Loss: 0.4510, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (2/10).
Epoch [8/100], Loss: 0.3730, Train Acc: 0.8359
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/100], Loss: 0.3455, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3616, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (5/10).
Epoch [11/100], Loss: 0.3174, Train Acc: 0.8594
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.2465, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.2695, Train Acc: 0.8672
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.2721, Train Acc: 0.8828
Validation Acc: 0.6562
Epoch [15/100], Loss: 0.2488, Train Acc: 0.8984
Validation Acc: 0.6562
No improvement (1/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8906
Validation Acc: 0.6562
No improvement (2/10).
Epoch [17/100], Loss: 0.1857, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (3/10).
Epoch [18/100], Loss: 0.2609, Train Acc: 0.9062
Validation Acc: 0.6719
Epoch [19/100], Loss: 0.1973, Train Acc: 0.9336
Validation Acc: 0.6562
No improvement (1/10).
Epoch [20/100], Loss: 0.1961, Train Acc: 0.9180
Validation Acc: 0.6562
No improvement (2/10).
Epoch [21/100], Loss: 0.1652, Train Acc: 0.9258
Validation Acc: 0.6719
No improvement (3/10).
Epoch [22/100], Loss: 0.1524, Train Acc: 0.9414
Validation Acc: 0.6875
Epoch [23/100], Loss: 0.1776, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (1/10).
Epoch [24/100], Loss: 0.1462, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (2/10).
Epoch [25/100], Loss: 0.1644, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (3/10).
Epoch [26/100], Loss: 0.1234, Train Acc: 0.9414
Validation Acc: 0.6406
No improvement (4/10).
Epoch [27/100], Loss: 0.1259, Train Acc: 0.9609
Validation Acc: 0.6094
No improvement (5/10).
Epoch [28/100], Loss: 0.1533, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (6/10).
Epoch [29/100], Loss: 0.1138, Train Acc: 0.9531
Validation Acc: 0.6406
No improvement (7/10).
Epoch [30/100], Loss: 0.1051, Train Acc: 0.9805
Validation Acc: 0.5938
No improvement (8/10).
Epoch [31/100], Loss: 0.0822, Train Acc: 0.9844
Validation Acc: 0.6094
No improvement (9/10).
Epoch [32/100], Loss: 0.1058, Train Acc: 0.9688
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8164
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6221, Train Acc: 0.8281
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.5927, Train Acc: 0.8594
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5766, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5843, Train Acc: 0.7773
Validation Acc: 0.8438
No improvement (1/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.7812
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.8438
No improvement (1/10).
Epoch [10/50], Loss: 0.5642, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (2/10).
Epoch [11/50], Loss: 0.5659, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (3/10).
Epoch [12/50], Loss: 0.5522, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5718, Train Acc: 0.7383
Validation Acc: 0.8594
No improvement (5/10).
Epoch [14/50], Loss: 0.5571, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5598, Train Acc: 0.7812
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5516, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5411, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5413, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [20/50], Loss: 0.5271, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (1/10).
Epoch [21/50], Loss: 0.5384, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (2/10).
Epoch [22/50], Loss: 0.5378, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (3/10).
Epoch [23/50], Loss: 0.5263, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (4/10).
Epoch [24/50], Loss: 0.5440, Train Acc: 0.7891
Validation Acc: 0.8594
No improvement (5/10).
Epoch [25/50], Loss: 0.5265, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (6/10).
Epoch [26/50], Loss: 0.5335, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (7/10).
Epoch [27/50], Loss: 0.5402, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (8/10).
Epoch [28/50], Loss: 0.5251, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [29/50], Loss: 0.5268, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5391
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6289
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6793, Train Acc: 0.6328
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6680, Train Acc: 0.6367
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6552, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (2/10).
Epoch [6/50], Loss: 0.6417, Train Acc: 0.6875
Validation Acc: 0.6562
Epoch [7/50], Loss: 0.6396, Train Acc: 0.6875
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.6236, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.6487, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [10/50], Loss: 0.7232, Train Acc: 0.5195
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.7082, Train Acc: 0.5039
Validation Acc: 0.5156
No improvement (3/10).
Epoch [12/50], Loss: 0.6687, Train Acc: 0.5312
Validation Acc: 0.6094
No improvement (4/10).
Epoch [13/50], Loss: 0.6518, Train Acc: 0.6602
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.6713, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (6/10).
Epoch [15/50], Loss: 0.6736, Train Acc: 0.6172
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/50], Loss: 0.6747, Train Acc: 0.6055
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/50], Loss: 0.6856, Train Acc: 0.5781
Validation Acc: 0.5312
No improvement (9/10).
Epoch [18/50], Loss: 0.6859, Train Acc: 0.5703
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.60 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.80s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.76s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.69s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.69s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.53s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.75s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.67s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02199011929202661, 'rho': 6020.721341758363, 'd': 0.7346379598087545, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  11%|â–ˆâ–        | 4/35 [1:06:32<9:37:43, 1118.18s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3215_1200/steady_state_trajectories/m_traj_3215.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.27
    - Variance: 2785.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.76 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3661, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8598, Train Acc: 0.6719
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7552, Train Acc: 0.6797
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6608, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5184, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/100], Loss: 0.4823, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.4584, Train Acc: 0.8047
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/100], Loss: 0.3711, Train Acc: 0.8281
Validation Acc: 0.6719
Epoch [9/100], Loss: 0.3757, Train Acc: 0.8438
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3475, Train Acc: 0.8438
Validation Acc: 0.7031
Epoch [11/100], Loss: 0.3190, Train Acc: 0.8750
Validation Acc: 0.6719
No improvement (1/10).
Epoch [12/100], Loss: 0.2849, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (2/10).
Epoch [13/100], Loss: 0.2907, Train Acc: 0.8711
Validation Acc: 0.6562
No improvement (3/10).
Epoch [14/100], Loss: 0.3286, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (4/10).
Epoch [15/100], Loss: 0.3487, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (5/10).
Epoch [16/100], Loss: 0.2908, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (6/10).
Epoch [17/100], Loss: 0.1993, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (7/10).
Epoch [18/100], Loss: 0.1950, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (8/10).
Epoch [19/100], Loss: 0.2377, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (9/10).
Epoch [20/100], Loss: 0.1559, Train Acc: 0.9414
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8398
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6081, Train Acc: 0.8672
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.5835, Train Acc: 0.8789
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5726, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5700, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [8/50], Loss: 0.5512, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [9/50], Loss: 0.5551, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (1/10).
Epoch [10/50], Loss: 0.5524, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (2/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (3/10).
Epoch [12/50], Loss: 0.5378, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5441, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (5/10).
Epoch [14/50], Loss: 0.5494, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (6/10).
Epoch [15/50], Loss: 0.5464, Train Acc: 0.8281
Validation Acc: 0.8281
No improvement (7/10).
Epoch [16/50], Loss: 0.5325, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5264, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5404, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6172
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6543, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6282, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5983, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [8/50], Loss: 0.6432, Train Acc: 0.6719
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (6/10).
Epoch [10/50], Loss: 0.5801, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (7/10).
Epoch [11/50], Loss: 0.5876, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (8/10).
Epoch [12/50], Loss: 0.5783, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (9/10).
Epoch [13/50], Loss: 0.5902, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6043.2031783022085, 'sigma_b': 0.02190823343247106, 'd': 0.7346386642035208}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.74s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.50s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.53s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.01
    - Variance: 3197.26

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.64 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3000, Train Acc: 0.5430
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8759, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8730, Train Acc: 0.6758
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6307, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.4839, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [6/100], Loss: 0.4445, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4344, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3516, Train Acc: 0.8594
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3471, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (8/10).
Epoch [10/100], Loss: 0.3292, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.2641, Train Acc: 0.8750
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6859, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6636, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6177, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8789
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5701, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (1/10).
Epoch [7/50], Loss: 0.5795, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (2/10).
Epoch [8/50], Loss: 0.5610, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (3/10).
Epoch [9/50], Loss: 0.5609, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (4/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5681, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5545, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5774, Train Acc: 0.7734
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5703, Train Acc: 0.7734
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5552, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6895, Train Acc: 0.6445
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6765, Train Acc: 0.6641
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6596, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6412, Train Acc: 0.7109
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.6324, Train Acc: 0.7070
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6271, Train Acc: 0.7031
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/50], Loss: 0.6199, Train Acc: 0.7188
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.6143, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6243, Train Acc: 0.7109
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5967, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (5/10).
Epoch [12/50], Loss: 0.6077, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (6/10).
Epoch [13/50], Loss: 0.6339, Train Acc: 0.6914
Validation Acc: 0.6719
No improvement (7/10).
Epoch [14/50], Loss: 0.6434, Train Acc: 0.6758
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/50], Loss: 0.6434, Train Acc: 0.6758
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/50], Loss: 0.6308, Train Acc: 0.6836
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.06s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.01s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.06s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.06s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02190823343247106, 'rho': 6043.2031783022085, 'd': 0.7346386642035208, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  14%|â–ˆâ–        | 5/35 [1:29:32<10:06:16, 1212.53s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
<lambdifygenerated-104443>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-104443>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3227_1200/steady_state_trajectories/m_traj_3227.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.45
    - Variance: 3182.70

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.66 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2242, Train Acc: 0.5117
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8683, Train Acc: 0.6680
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.7830, Train Acc: 0.6680
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.7295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.5254, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5681, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5196, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (5/10).
Epoch [8/100], Loss: 0.3425, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4332, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4192, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.3506, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (9/10).
Epoch [12/100], Loss: 0.3000, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6652, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6125, Train Acc: 0.8516
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5885, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5687, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (2/10).
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8203
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5553, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5543, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5620, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5584, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8359
Validation Acc: 0.9062
No improvement (2/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8789
Validation Acc: 0.9375
Epoch [18/50], Loss: 0.5388, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (1/10).
Epoch [19/50], Loss: 0.5491, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (2/10).
Epoch [20/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (3/10).
Epoch [21/50], Loss: 0.5284, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (4/10).
Epoch [22/50], Loss: 0.5354, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (5/10).
Epoch [23/50], Loss: 0.5379, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [24/50], Loss: 0.5418, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (7/10).
Epoch [25/50], Loss: 0.5270, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [26/50], Loss: 0.5328, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [27/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6903, Train Acc: 0.6094
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6785, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6513, Train Acc: 0.7305
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6265, Train Acc: 0.7852
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6111, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6342, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/50], Loss: 0.6701, Train Acc: 0.6133
Validation Acc: 0.5938
No improvement (4/10).
Epoch [10/50], Loss: 0.6598, Train Acc: 0.6211
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.6491, Train Acc: 0.6484
Validation Acc: 0.6250
No improvement (6/10).
Epoch [12/50], Loss: 0.6416, Train Acc: 0.6562
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/50], Loss: 0.6261, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6084, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6067, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6065.685014523766, 'sigma_b': 0.021826955157876898, 'd': 0.7346393633854864}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.56s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.61
    - Variance: 3351.44

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2617, Train Acc: 0.5312
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9435, Train Acc: 0.6406
Validation Acc: 0.5938
No improvement (1/10).
Epoch [3/100], Loss: 0.7175, Train Acc: 0.7109
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6287, Train Acc: 0.7305
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.5123, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/100], Loss: 0.5407, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/100], Loss: 0.4590, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/100], Loss: 0.3715, Train Acc: 0.8398
Validation Acc: 0.6875
No improvement (4/10).
Epoch [9/100], Loss: 0.3433, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (5/10).
Epoch [10/100], Loss: 0.3435, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/100], Loss: 0.3602, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (7/10).
Epoch [12/100], Loss: 0.3039, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (8/10).
Epoch [13/100], Loss: 0.3598, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/100], Loss: 0.3018, Train Acc: 0.8633
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6675, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [4/50], Loss: 0.6230, Train Acc: 0.8125
Validation Acc: 0.9375
No improvement (1/10).
Epoch [5/50], Loss: 0.5941, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (2/10).
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [7/50], Loss: 0.5941, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [8/50], Loss: 0.5767, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (5/10).
Epoch [9/50], Loss: 0.5704, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.5624, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (7/10).
Epoch [11/50], Loss: 0.5699, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (8/10).
Epoch [12/50], Loss: 0.5522, Train Acc: 0.8477
Validation Acc: 0.9375
No improvement (9/10).
Epoch [13/50], Loss: 0.5615, Train Acc: 0.8281
Validation Acc: 0.9375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6901, Train Acc: 0.6328
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [4/50], Loss: 0.6681, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6582, Train Acc: 0.6602
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6330, Train Acc: 0.7070
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6268, Train Acc: 0.7070
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6158, Train Acc: 0.7266
Validation Acc: 0.8281
Epoch [9/50], Loss: 0.6033, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (1/10).
Epoch [10/50], Loss: 0.6320, Train Acc: 0.6914
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.6332, Train Acc: 0.6992
Validation Acc: 0.7656
No improvement (3/10).
Epoch [12/50], Loss: 0.6092, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (4/10).
Epoch [13/50], Loss: 0.6069, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (5/10).
Epoch [14/50], Loss: 0.6362, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/50], Loss: 0.6542, Train Acc: 0.6406
Validation Acc: 0.6875
No improvement (7/10).
Epoch [16/50], Loss: 0.6497, Train Acc: 0.6328
Validation Acc: 0.6875
No improvement (8/10).
Epoch [17/50], Loss: 0.6336, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (9/10).
Epoch [18/50], Loss: 0.6308, Train Acc: 0.6602
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.13s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.21s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021826955157876898, 'rho': 6065.685014523766, 'd': 0.7346393633854864, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  17%|â–ˆâ–‹        | 6/35 [1:52:35<10:14:00, 1270.35s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3239_1200/steady_state_trajectories/m_traj_3239.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.62
    - Variance: 3278.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4132, Train Acc: 0.5039
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9983, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.6691, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (2/10).
Epoch [5/100], Loss: 0.6028, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/100], Loss: 0.4643, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (4/10).
Epoch [7/100], Loss: 0.5158, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3404, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.3758, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3542, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (8/10).
Epoch [11/100], Loss: 0.3183, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3389, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6672, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6141, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5894, Train Acc: 0.8516
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5719, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5748, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5565, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5610, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.5605, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (6/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5545, Train Acc: 0.8008
Validation Acc: 0.9062
Epoch [14/50], Loss: 0.5588, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (1/10).
Epoch [15/50], Loss: 0.5754, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (2/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (3/10).
Epoch [17/50], Loss: 0.5402, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (4/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (5/10).
Epoch [19/50], Loss: 0.5537, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5313, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5462, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5474, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5977
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6822, Train Acc: 0.6445
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6617, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6314, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6248, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6190, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6298, Train Acc: 0.7031
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.6832, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6151, Train Acc: 0.7266
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5850, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (7/10).
Epoch [13/50], Loss: 0.5920, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5885, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5985, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6088.166850431201, 'sigma_b': 0.021746277730896425, 'd': 0.7346400574123043}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.93s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3217.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.65 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.41 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2818, Train Acc: 0.5586
Validation Acc: 0.4062
Epoch [2/100], Loss: 1.0112, Train Acc: 0.6211
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7549, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6173, Train Acc: 0.7148
Validation Acc: 0.4531
No improvement (2/10).
Epoch [5/100], Loss: 0.5733, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4531, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (4/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (5/10).
Epoch [8/100], Loss: 0.3743, Train Acc: 0.8516
Validation Acc: 0.4375
No improvement (6/10).
Epoch [9/100], Loss: 0.3472, Train Acc: 0.8633
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.3438, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2955, Train Acc: 0.8672
Validation Acc: 0.5312
Epoch [12/100], Loss: 0.3726, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (1/10).
Epoch [13/100], Loss: 0.3410, Train Acc: 0.8789
Validation Acc: 0.5156
No improvement (2/10).
Epoch [14/100], Loss: 0.2499, Train Acc: 0.8789
Validation Acc: 0.5625
Epoch [15/100], Loss: 0.2476, Train Acc: 0.8984
Validation Acc: 0.5781
Epoch [16/100], Loss: 0.2126, Train Acc: 0.9102
Validation Acc: 0.5625
No improvement (1/10).
Epoch [17/100], Loss: 0.2275, Train Acc: 0.9023
Validation Acc: 0.5156
No improvement (2/10).
Epoch [18/100], Loss: 0.2264, Train Acc: 0.9023
Validation Acc: 0.5312
No improvement (3/10).
Epoch [19/100], Loss: 0.2104, Train Acc: 0.9141
Validation Acc: 0.5469
No improvement (4/10).
Epoch [20/100], Loss: 0.1960, Train Acc: 0.9297
Validation Acc: 0.5625
No improvement (5/10).
Epoch [21/100], Loss: 0.1620, Train Acc: 0.9297
Validation Acc: 0.5625
No improvement (6/10).
Epoch [22/100], Loss: 0.1719, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (7/10).
Epoch [23/100], Loss: 0.1907, Train Acc: 0.9297
Validation Acc: 0.5938
Epoch [24/100], Loss: 0.2322, Train Acc: 0.9219
Validation Acc: 0.5781
No improvement (1/10).
Epoch [25/100], Loss: 0.1338, Train Acc: 0.9531
Validation Acc: 0.5781
No improvement (2/10).
Epoch [26/100], Loss: 0.1645, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (3/10).
Epoch [27/100], Loss: 0.1423, Train Acc: 0.9609
Validation Acc: 0.5781
No improvement (4/10).
Epoch [28/100], Loss: 0.0969, Train Acc: 0.9688
Validation Acc: 0.5938
No improvement (5/10).
Epoch [29/100], Loss: 0.1183, Train Acc: 0.9531
Validation Acc: 0.5938
No improvement (6/10).
Epoch [30/100], Loss: 0.1110, Train Acc: 0.9570
Validation Acc: 0.5938
No improvement (7/10).
Epoch [31/100], Loss: 0.1332, Train Acc: 0.9453
Validation Acc: 0.6094
Epoch [32/100], Loss: 0.1035, Train Acc: 0.9648
Validation Acc: 0.5938
No improvement (1/10).
Epoch [33/100], Loss: 0.1058, Train Acc: 0.9609
Validation Acc: 0.5625
No improvement (2/10).
Epoch [34/100], Loss: 0.1041, Train Acc: 0.9727
Validation Acc: 0.5781
No improvement (3/10).
Epoch [35/100], Loss: 0.0977, Train Acc: 0.9648
Validation Acc: 0.5938
No improvement (4/10).
Epoch [36/100], Loss: 0.0805, Train Acc: 0.9727
Validation Acc: 0.5938
No improvement (5/10).
Epoch [37/100], Loss: 0.1097, Train Acc: 0.9648
Validation Acc: 0.5938
No improvement (6/10).
Epoch [38/100], Loss: 0.0902, Train Acc: 0.9727
Validation Acc: 0.5625
No improvement (7/10).
Epoch [39/100], Loss: 0.0701, Train Acc: 0.9766
Validation Acc: 0.5625
No improvement (8/10).
Epoch [40/100], Loss: 0.0660, Train Acc: 0.9805
Validation Acc: 0.5781
No improvement (9/10).
Epoch [41/100], Loss: 0.1074, Train Acc: 0.9766
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.50 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6859, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8359
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5846, Train Acc: 0.8594
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5753, Train Acc: 0.8320
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.5969, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (2/10).
Epoch [8/50], Loss: 0.5684, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (3/10).
Epoch [9/50], Loss: 0.5669, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5615, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/50], Loss: 0.5656, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (6/10).
Epoch [12/50], Loss: 0.5463, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (7/10).
Epoch [13/50], Loss: 0.5607, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.5573, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5571, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5586
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6289
Validation Acc: 0.5000
Epoch [3/50], Loss: 0.6777, Train Acc: 0.6289
Validation Acc: 0.5781
Epoch [4/50], Loss: 0.6632, Train Acc: 0.6406
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6369, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (2/10).
Epoch [7/50], Loss: 0.6979, Train Acc: 0.5664
Validation Acc: 0.5781
No improvement (3/10).
Epoch [8/50], Loss: 0.6601, Train Acc: 0.6328
Validation Acc: 0.6250
No improvement (4/10).
Epoch [9/50], Loss: 0.6639, Train Acc: 0.6133
Validation Acc: 0.6562
No improvement (5/10).
Epoch [10/50], Loss: 0.6568, Train Acc: 0.6133
Validation Acc: 0.6562
No improvement (6/10).
Epoch [11/50], Loss: 0.6213, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (7/10).
Epoch [12/50], Loss: 0.5847, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (8/10).
Epoch [13/50], Loss: 0.5717, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (9/10).
Epoch [14/50], Loss: 0.5704, Train Acc: 0.7812
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.91s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021746277730896425, 'rho': 6088.166850431201, 'd': 0.7346400574123043, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  20%|â–ˆâ–ˆ        | 7/35 [2:15:16<10:06:45, 1300.21s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-147999>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-147999>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3251_1200/steady_state_trajectories/m_traj_3251.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.00
    - Variance: 3118.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3449, Train Acc: 0.5195
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8534, Train Acc: 0.6484
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.7135, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6159, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5701, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4300, Train Acc: 0.8086
Validation Acc: 0.5312
Epoch [7/100], Loss: 0.5116, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.3429, Train Acc: 0.8359
Validation Acc: 0.5469
Epoch [9/100], Loss: 0.3703, Train Acc: 0.8359
Validation Acc: 0.5781
Epoch [10/100], Loss: 0.3564, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [11/100], Loss: 0.3372, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [12/100], Loss: 0.3072, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (2/10).
Epoch [13/100], Loss: 0.2772, Train Acc: 0.8711
Validation Acc: 0.5156
No improvement (3/10).
Epoch [14/100], Loss: 0.2764, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [15/100], Loss: 0.3135, Train Acc: 0.8438
Validation Acc: 0.5156
No improvement (5/10).
Epoch [16/100], Loss: 0.2310, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (6/10).
Epoch [17/100], Loss: 0.2141, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (7/10).
Epoch [18/100], Loss: 0.2048, Train Acc: 0.8984
Validation Acc: 0.5625
No improvement (8/10).
Epoch [19/100], Loss: 0.2867, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [20/100], Loss: 0.1883, Train Acc: 0.9297
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6122, Train Acc: 0.8594
Validation Acc: 0.7344
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8867
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.5780, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5583, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5765, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5514, Train Acc: 0.8516
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [12/50], Loss: 0.5386, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (1/10).
Epoch [13/50], Loss: 0.5570, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5450, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8125
No improvement (1/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5236, Train Acc: 0.8555
Validation Acc: 0.7812
No improvement (3/10).
Epoch [18/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.5345, Train Acc: 0.8477
Validation Acc: 0.7969
No improvement (5/10).
Epoch [20/50], Loss: 0.5278, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (6/10).
Epoch [21/50], Loss: 0.5342, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (7/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5256, Train Acc: 0.8594
Validation Acc: 0.8125
No improvement (1/10).
Epoch [24/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [25/50], Loss: 0.5313, Train Acc: 0.8438
Validation Acc: 0.7656
No improvement (3/10).
Epoch [26/50], Loss: 0.5326, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (4/10).
Epoch [27/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (5/10).
Epoch [28/50], Loss: 0.5288, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (6/10).
Epoch [29/50], Loss: 0.5200, Train Acc: 0.8555
Validation Acc: 0.7969
No improvement (7/10).
Epoch [30/50], Loss: 0.5153, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (8/10).
Epoch [31/50], Loss: 0.5161, Train Acc: 0.8477
Validation Acc: 0.8125
No improvement (9/10).
Epoch [32/50], Loss: 0.5098, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6914
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6376, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/50], Loss: 0.6032, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (3/10).
Epoch [7/50], Loss: 0.5811, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.5719, Train Acc: 0.8008
Validation Acc: 0.7344
Epoch [9/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6157, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [11/50], Loss: 0.5948, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5880, Train Acc: 0.7617
Validation Acc: 0.7500
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.7812
Epoch [15/50], Loss: 0.5906, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5705, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (2/10).
Epoch [17/50], Loss: 0.5677, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [18/50], Loss: 0.5662, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (4/10).
Epoch [19/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (5/10).
Epoch [20/50], Loss: 0.5543, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (6/10).
Epoch [21/50], Loss: 0.5645, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (7/10).
Epoch [22/50], Loss: 0.5541, Train Acc: 0.8125
Validation Acc: 0.7344
No improvement (8/10).
Epoch [23/50], Loss: 0.5560, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (9/10).
Epoch [24/50], Loss: 0.5592, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6110.648686020953, 'sigma_b': 0.021666194513420396, 'd': 0.7346407463407776}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.39s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.51
    - Variance: 2950.12

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.64 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1414, Train Acc: 0.5781
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9433, Train Acc: 0.6289
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.7881, Train Acc: 0.6797
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5882, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [5/100], Loss: 0.5270, Train Acc: 0.7891
Validation Acc: 0.6719
Epoch [6/100], Loss: 0.5137, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/100], Loss: 0.4280, Train Acc: 0.7930
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/100], Loss: 0.3950, Train Acc: 0.8281
Validation Acc: 0.6875
Epoch [9/100], Loss: 0.3658, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/100], Loss: 0.3426, Train Acc: 0.8281
Validation Acc: 0.6562
No improvement (2/10).
Epoch [11/100], Loss: 0.2702, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (3/10).
Epoch [12/100], Loss: 0.3145, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.2981, Train Acc: 0.8750
Validation Acc: 0.6562
No improvement (5/10).
Epoch [14/100], Loss: 0.2658, Train Acc: 0.8750
Validation Acc: 0.6562
No improvement (6/10).
Epoch [15/100], Loss: 0.2396, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/100], Loss: 0.1988, Train Acc: 0.9023
Validation Acc: 0.6562
No improvement (8/10).
Epoch [17/100], Loss: 0.2426, Train Acc: 0.8828
Validation Acc: 0.6562
No improvement (9/10).
Epoch [18/100], Loss: 0.2144, Train Acc: 0.8789
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8164
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6233, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (2/10).
Epoch [7/50], Loss: 0.5876, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [8/50], Loss: 0.5742, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.5716, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (5/10).
Epoch [10/50], Loss: 0.5652, Train Acc: 0.8438
Validation Acc: 0.9375
Epoch [11/50], Loss: 0.5729, Train Acc: 0.8008
Validation Acc: 0.9219
No improvement (1/10).
Epoch [12/50], Loss: 0.5551, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (2/10).
Epoch [13/50], Loss: 0.5709, Train Acc: 0.7773
Validation Acc: 0.9062
No improvement (3/10).
Epoch [14/50], Loss: 0.5535, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (4/10).
Epoch [15/50], Loss: 0.5591, Train Acc: 0.7891
Validation Acc: 0.9375
No improvement (5/10).
Epoch [16/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (6/10).
Epoch [17/50], Loss: 0.5419, Train Acc: 0.8516
Validation Acc: 0.9219
No improvement (7/10).
Epoch [18/50], Loss: 0.5539, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (8/10).
Epoch [19/50], Loss: 0.5463, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (9/10).
Epoch [20/50], Loss: 0.5333, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5430
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6367
Validation Acc: 0.5000
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6602
Validation Acc: 0.5781
Epoch [4/50], Loss: 0.6603, Train Acc: 0.6602
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/50], Loss: 0.6443, Train Acc: 0.6914
Validation Acc: 0.6094
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7070
Validation Acc: 0.6250
Epoch [7/50], Loss: 0.6265, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.6243, Train Acc: 0.7070
Validation Acc: 0.6406
Epoch [9/50], Loss: 0.6224, Train Acc: 0.6953
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6120, Train Acc: 0.7266
Validation Acc: 0.6406
No improvement (1/10).
Epoch [11/50], Loss: 0.6089, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/50], Loss: 0.6146, Train Acc: 0.7148
Validation Acc: 0.6406
No improvement (3/10).
Epoch [13/50], Loss: 0.6082, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/50], Loss: 0.6022, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [15/50], Loss: 0.6097, Train Acc: 0.7188
Validation Acc: 0.6562
No improvement (1/10).
Epoch [16/50], Loss: 0.6054, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (2/10).
Epoch [17/50], Loss: 0.6002, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (3/10).
Epoch [18/50], Loss: 0.5989, Train Acc: 0.7266
Validation Acc: 0.6094
No improvement (4/10).
Epoch [19/50], Loss: 0.6014, Train Acc: 0.7188
Validation Acc: 0.6094
No improvement (5/10).
Epoch [20/50], Loss: 0.5955, Train Acc: 0.7344
Validation Acc: 0.6250
No improvement (6/10).
Epoch [21/50], Loss: 0.6002, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (7/10).
Epoch [22/50], Loss: 0.5963, Train Acc: 0.7344
Validation Acc: 0.6250
No improvement (8/10).
Epoch [23/50], Loss: 0.5925, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (9/10).
Epoch [24/50], Loss: 0.5961, Train Acc: 0.7305
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.87s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.90s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.93s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.83s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).
Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021666194513420396, 'rho': 6110.648686020953, 'd': 0.7346407463407776, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3263_1200/steady_state_trajectories/m_traj_3263.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.19
    - Variance: 2740.56

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4559, Train Acc: 0.5195
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8384, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.6947, Train Acc: 0.6914
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6364, Train Acc: 0.7266
Validation Acc: 0.5469
No improvement (2/10).
Epoch [5/100], Loss: 0.4873, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.5450, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4113, Train Acc: 0.8320
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3605, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (1/10).
Epoch [9/100], Loss: 0.3837, Train Acc: 0.8438
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3687, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.4108, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.3626, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/100], Loss: 0.2843, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (6/10).
Epoch [14/100], Loss: 0.2975, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (7/10).
Epoch [15/100], Loss: 0.2545, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.2470, Train Acc: 0.8867
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2158, Train Acc: 0.9023
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/50], Loss: 0.5749, Train Acc: 0.9023
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.5759, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/50], Loss: 0.5793, Train Acc: 0.7852
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5905, Train Acc: 0.7383
Validation Acc: 0.8906
No improvement (1/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6045, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [11/50], Loss: 0.5807, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [13/50], Loss: 0.5563, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (6/10).
Epoch [14/50], Loss: 0.5638, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (7/10).
Epoch [15/50], Loss: 0.5515, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5397, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5310, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6680
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6697, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6469, Train Acc: 0.7266
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6366, Train Acc: 0.7461
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6350, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6259, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6172, Train Acc: 0.7227
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6014, Train Acc: 0.7422
Validation Acc: 0.7656
No improvement (1/10).
Epoch [10/50], Loss: 0.5918, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5918, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.5909, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (4/10).
Epoch [13/50], Loss: 0.5875, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.5937, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [15/50], Loss: 0.5761, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [16/50], Loss: 0.5845, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [17/50], Loss: 0.5768, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (1/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5714, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (3/10).
Epoch [20/50], Loss: 0.5726, Train Acc: 0.7734
Validation Acc: 0.8125
Epoch [21/50], Loss: 0.5796, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (1/10).
Epoch [22/50], Loss: 0.5696, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (2/10).
Epoch [23/50], Loss: 0.5630, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (3/10).
Epoch [24/50], Loss: 0.5673, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (4/10).
Epoch [25/50], Loss: 0.5736, Train Acc: 0.7695
Validation Acc: 0.8125
No improvement (5/10).
Epoch [26/50], Loss: 0.5752, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (6/10).
Epoch [27/50], Loss: 0.5713, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (7/10).
Epoch [28/50], Loss: 0.5694, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [29/50], Loss: 0.5651, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [30/50], Loss: 0.5564, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (2/10).
Epoch [31/50], Loss: 0.5596, Train Acc: 0.7812
Validation Acc: 0.7969
No improvement (3/10).
Epoch [32/50], Loss: 0.5590, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (4/10).
Epoch [33/50], Loss: 0.5684, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (5/10).
Epoch [34/50], Loss: 0.5608, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [35/50], Loss: 0.5666, Train Acc: 0.7695
Validation Acc: 0.8281
No improvement (7/10).
Epoch [36/50], Loss: 0.5542, Train Acc: 0.7969
Validation Acc: 0.8438
Epoch [37/50], Loss: 0.5561, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [38/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (1/10).
Epoch [39/50], Loss: 0.5512, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (2/10).
Epoch [40/50], Loss: 0.5401, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (3/10).
Epoch [41/50], Loss: 0.5530, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (4/10).
Epoch [42/50], Loss: 0.5463, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (5/10).
Epoch [43/50], Loss: 0.5526, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (6/10).
Epoch [44/50], Loss: 0.5479, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [45/50], Loss: 0.5360, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (8/10).Running Variance Ratio Simulations:  23%|â–ˆâ–ˆâ–Ž       | 8/35 [2:38:05<9:54:51, 1321.91s/it] /home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-179576>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-179576>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])

Epoch [46/50], Loss: 0.5323, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (9/10).
Epoch [47/50], Loss: 0.5356, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6133.130521301562, 'sigma_b': 0.021586698964770733, 'd': 0.7346414302268811}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.76
    - Variance: 2994.32

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.60 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2747, Train Acc: 0.5547
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.9739, Train Acc: 0.6602
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.8698, Train Acc: 0.6445
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6487, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5828, Train Acc: 0.7656
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.4838, Train Acc: 0.7461
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.5072, Train Acc: 0.7578
Validation Acc: 0.5469
No improvement (4/10).
Epoch [8/100], Loss: 0.3920, Train Acc: 0.8203
Validation Acc: 0.5469
No improvement (5/10).
Epoch [9/100], Loss: 0.3891, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [10/100], Loss: 0.3751, Train Acc: 0.8359
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3470, Train Acc: 0.8555
Validation Acc: 0.5938
No improvement (8/10).
Epoch [12/100], Loss: 0.3508, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (9/10).
Epoch [13/100], Loss: 0.3569, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6857, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6613, Train Acc: 0.8516
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5899, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8633
Validation Acc: 0.7969
No improvement (1/10).
Epoch [7/50], Loss: 0.5878, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [8/50], Loss: 0.5575, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5541, Train Acc: 0.8164
Validation Acc: 0.7188
No improvement (4/10).
Epoch [10/50], Loss: 0.5534, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/50], Loss: 0.5686, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5688, Train Acc: 0.7422
Validation Acc: 0.8281
No improvement (8/10).
Epoch [14/50], Loss: 0.5506, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (9/10).
Epoch [15/50], Loss: 0.5578, Train Acc: 0.7695
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5430
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6611, Train Acc: 0.6523
Validation Acc: 0.5469
Epoch [5/50], Loss: 0.6521, Train Acc: 0.6641
Validation Acc: 0.5781
Epoch [6/50], Loss: 0.6422, Train Acc: 0.6875
Validation Acc: 0.6094
Epoch [7/50], Loss: 0.6418, Train Acc: 0.6758
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.6413, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [9/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/50], Loss: 0.6274, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [11/50], Loss: 0.6294, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (3/10).
Epoch [12/50], Loss: 0.6295, Train Acc: 0.6875
Validation Acc: 0.5781
No improvement (4/10).
Epoch [13/50], Loss: 0.6209, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/50], Loss: 0.6181, Train Acc: 0.7031
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/50], Loss: 0.6192, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.6169, Train Acc: 0.6836
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/50], Loss: 0.6023, Train Acc: 0.6914
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/50], Loss: 0.6058, Train Acc: 0.6758
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.16s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.02s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.19s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.09s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.18s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021586698964770733, 'rho': 6133.130521301562, 'd': 0.7346414302268811, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  26%|â–ˆâ–ˆâ–Œ       | 9/35 [3:00:41<9:37:28, 1332.64s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3275_1200/steady_state_trajectories/m_traj_3275.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3122.24

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3732, Train Acc: 0.5000
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8341, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.6997, Train Acc: 0.7148
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.5789, Train Acc: 0.7500
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.5224, Train Acc: 0.7461
Validation Acc: 0.6250
No improvement (4/10).
Epoch [6/100], Loss: 0.4559, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.4814, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (6/10).
Epoch [8/100], Loss: 0.3646, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (7/10).
Epoch [9/100], Loss: 0.3308, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (8/10).
Epoch [10/100], Loss: 0.2806, Train Acc: 0.8867
Validation Acc: 0.5781
No improvement (9/10).
Epoch [11/100], Loss: 0.3032, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6797
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6654, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5785, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.5810, Train Acc: 0.7656
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5601, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (4/10).
Epoch [9/50], Loss: 0.5676, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5569, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [11/50], Loss: 0.5707, Train Acc: 0.7617
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5518, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5649, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [14/50], Loss: 0.5737, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [15/50], Loss: 0.5531, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5390, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (1/10).
Epoch [18/50], Loss: 0.5412, Train Acc: 0.8398
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5504, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5346, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [21/50], Loss: 0.5399, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5276, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5314, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5247, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5297, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.96 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6328
Validation Acc: 0.7031
Epoch [3/50], Loss: 0.6725, Train Acc: 0.6602
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6564, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6407, Train Acc: 0.7227
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6022, Train Acc: 0.7812
Validation Acc: 0.7656
Epoch [7/50], Loss: 0.5875, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (2/10).
Epoch [9/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6588, Train Acc: 0.6562
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/50], Loss: 0.6732, Train Acc: 0.6328
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6389, Train Acc: 0.6836
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5804, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (7/10).
Epoch [14/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.5812, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (9/10).
Epoch [16/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6155.612356272901, 'sigma_b': 0.02150778463990794, 'd': 0.7346421091257699}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.94s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.21
    - Variance: 2891.59

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.0819, Train Acc: 0.5703
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8932, Train Acc: 0.6602
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7610, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6277, Train Acc: 0.7617
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4836, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [6/100], Loss: 0.4626, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/100], Loss: 0.4126, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/100], Loss: 0.3559, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (3/10).
Epoch [9/100], Loss: 0.3079, Train Acc: 0.8672
Validation Acc: 0.6250
Epoch [10/100], Loss: 0.3122, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (1/10).
Epoch [11/100], Loss: 0.2911, Train Acc: 0.8711
Validation Acc: 0.6250
No improvement (2/10).
Epoch [12/100], Loss: 0.2948, Train Acc: 0.8789
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.2632, Train Acc: 0.8672
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.2390, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (5/10).
Epoch [15/100], Loss: 0.2457, Train Acc: 0.8984
Validation Acc: 0.6406
Epoch [16/100], Loss: 0.2146, Train Acc: 0.8984
Validation Acc: 0.6250
No improvement (1/10).
Epoch [17/100], Loss: 0.2349, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (2/10).
Epoch [18/100], Loss: 0.1982, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (3/10).
Epoch [19/100], Loss: 0.1899, Train Acc: 0.9062
Validation Acc: 0.6250
No improvement (4/10).
Epoch [20/100], Loss: 0.1677, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (5/10).
Epoch [21/100], Loss: 0.1847, Train Acc: 0.9258
Validation Acc: 0.6406
No improvement (6/10).
Epoch [22/100], Loss: 0.1425, Train Acc: 0.9492
Validation Acc: 0.6250
No improvement (7/10).
Epoch [23/100], Loss: 0.1195, Train Acc: 0.9648
Validation Acc: 0.6250
No improvement (8/10).
Epoch [24/100], Loss: 0.1379, Train Acc: 0.9688
Validation Acc: 0.6250
No improvement (9/10).
Epoch [25/100], Loss: 0.1384, Train Acc: 0.9531
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6856, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6631, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6172, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5848, Train Acc: 0.8672
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5829, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5861, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5632, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5760, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5535, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [13/50], Loss: 0.5702, Train Acc: 0.7852
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5574, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (3/10).
Epoch [15/50], Loss: 0.5583, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.9062
No improvement (1/10).
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (2/10).
Epoch [18/50], Loss: 0.5416, Train Acc: 0.7930
Validation Acc: 0.9062
No improvement (3/10).
Epoch [19/50], Loss: 0.5266, Train Acc: 0.8438
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5282, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (1/10).
Epoch [21/50], Loss: 0.5349, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (2/10).
Epoch [22/50], Loss: 0.5234, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (3/10).
Epoch [23/50], Loss: 0.5283, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (4/10).
Epoch [24/50], Loss: 0.5384, Train Acc: 0.7969
Validation Acc: 0.8906
No improvement (5/10).
Epoch [25/50], Loss: 0.5185, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (6/10).
Epoch [26/50], Loss: 0.5298, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [27/50], Loss: 0.5212, Train Acc: 0.8438
Validation Acc: 0.9219
No improvement (8/10).
Epoch [28/50], Loss: 0.5215, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (9/10).
Epoch [29/50], Loss: 0.5277, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5508
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6889, Train Acc: 0.6094
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6751, Train Acc: 0.6406
Validation Acc: 0.5625
Epoch [4/50], Loss: 0.6597, Train Acc: 0.6719
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6433, Train Acc: 0.7070
Validation Acc: 0.7656
No improvement (1/10).
Epoch [6/50], Loss: 0.6306, Train Acc: 0.7227
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.6322, Train Acc: 0.6992
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.6108, Train Acc: 0.7383
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.6179, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [10/50], Loss: 0.6209, Train Acc: 0.7188
Validation Acc: 0.7656
No improvement (4/10).
Epoch [11/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7969
No improvement (5/10).
Epoch [12/50], Loss: 0.6042, Train Acc: 0.7383
Validation Acc: 0.8281
No improvement (6/10).
Epoch [13/50], Loss: 0.5991, Train Acc: 0.7461
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.6013, Train Acc: 0.7422
Validation Acc: 0.8750
No improvement (8/10).
Epoch [15/50], Loss: 0.5926, Train Acc: 0.7500
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.6025, Train Acc: 0.7344
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.92s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.04s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02150778463990794, 'rho': 6155.612356272901, 'd': 0.7346421091257699, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.07s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  29%|â–ˆâ–ˆâ–Š       | 10/35 [3:23:58<9:23:34, 1352.60s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-230807>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-230807>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3287_1200/steady_state_trajectories/m_traj_3287.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.90
    - Variance: 3154.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.84 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2959, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7206, Train Acc: 0.6953
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7343, Train Acc: 0.6914
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6775, Train Acc: 0.7422
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.5896, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4728, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/100], Loss: 0.5048, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4812, Train Acc: 0.7812
Validation Acc: 0.5781
No improvement (1/10).
Epoch [9/100], Loss: 0.3636, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/100], Loss: 0.3436, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/100], Loss: 0.3142, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/100], Loss: 0.2911, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [13/100], Loss: 0.2995, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2921, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/100], Loss: 0.2842, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (8/10).
Epoch [16/100], Loss: 0.3036, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/100], Loss: 0.2098, Train Acc: 0.9102
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8320
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6157, Train Acc: 0.8438
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5885, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5836, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6013, Train Acc: 0.7852
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5610, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.5661, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5557, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [11/50], Loss: 0.5612, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5343, Train Acc: 0.8711
Validation Acc: 0.9219
No improvement (5/10).
Epoch [13/50], Loss: 0.5613, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (6/10).
Epoch [14/50], Loss: 0.5511, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (7/10).
Epoch [15/50], Loss: 0.5367, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [16/50], Loss: 0.5327, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (9/10).
Epoch [17/50], Loss: 0.5247, Train Acc: 0.8672
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6898, Train Acc: 0.6055
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6804, Train Acc: 0.6641
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6875
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6340, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6105, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6301, Train Acc: 0.6953
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.5653, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (1/10).
Epoch [10/50], Loss: 0.6152, Train Acc: 0.7188
Validation Acc: 0.7500
No improvement (2/10).
Epoch [11/50], Loss: 0.5856, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5939, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [13/50], Loss: 0.5915, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5911, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [15/50], Loss: 0.6007, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (4/10).
Epoch [17/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (5/10).
Epoch [18/50], Loss: 0.5830, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5727, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [20/50], Loss: 0.5773, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5647, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/50], Loss: 0.5523, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6178.094190942474, 'sigma_b': 0.02142944518769857, 'd': 0.7346427830918018}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.10s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.11s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.02
    - Variance: 3261.92

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1357, Train Acc: 0.5391
Validation Acc: 0.5000
Epoch [2/100], Loss: 1.0573, Train Acc: 0.5781
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.8373, Train Acc: 0.6836
Validation Acc: 0.5312
Epoch [4/100], Loss: 0.6036, Train Acc: 0.7227
Validation Acc: 0.5781
Epoch [5/100], Loss: 0.4791, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4510, Train Acc: 0.7969
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4189, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.4140, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (2/10).
Epoch [9/100], Loss: 0.3614, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.3646, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.3325, Train Acc: 0.8594
Validation Acc: 0.5781
No improvement (5/10).
Epoch [12/100], Loss: 0.2863, Train Acc: 0.8633
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8789
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2881, Train Acc: 0.8711
Validation Acc: 0.6250
No improvement (8/10).
Epoch [15/100], Loss: 0.2720, Train Acc: 0.8867
Validation Acc: 0.6406
Epoch [16/100], Loss: 0.2067, Train Acc: 0.9023
Validation Acc: 0.6562
Epoch [17/100], Loss: 0.2244, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (1/10).
Epoch [18/100], Loss: 0.2454, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (2/10).
Epoch [19/100], Loss: 0.2622, Train Acc: 0.8867
Validation Acc: 0.6562
No improvement (3/10).
Epoch [20/100], Loss: 0.2101, Train Acc: 0.9258
Validation Acc: 0.6406
No improvement (4/10).
Epoch [21/100], Loss: 0.1650, Train Acc: 0.9336
Validation Acc: 0.5938
No improvement (5/10).
Epoch [22/100], Loss: 0.1923, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (6/10).
Epoch [23/100], Loss: 0.1791, Train Acc: 0.9258
Validation Acc: 0.6250
No improvement (7/10).
Epoch [24/100], Loss: 0.2074, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (8/10).
Epoch [25/100], Loss: 0.1960, Train Acc: 0.9023
Validation Acc: 0.6250
No improvement (9/10).
Epoch [26/100], Loss: 0.1808, Train Acc: 0.9258
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.49 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6662, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6220, Train Acc: 0.8281
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.6000, Train Acc: 0.8594
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5758, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.5917, Train Acc: 0.8008
Validation Acc: 0.5469
No improvement (2/10).
Epoch [8/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (3/10).
Epoch [9/50], Loss: 0.5619, Train Acc: 0.7930
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5660, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (5/10).
Epoch [11/50], Loss: 0.5708, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5615, Train Acc: 0.7734
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5783, Train Acc: 0.7422
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5571, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5588, Train Acc: 0.7773
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6016
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6807, Train Acc: 0.6133
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
Epoch [5/50], Loss: 0.6570, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [6/50], Loss: 0.6457, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6320, Train Acc: 0.6992
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6289, Train Acc: 0.6914
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.6194, Train Acc: 0.7148
Validation Acc: 0.7500
Epoch [10/50], Loss: 0.6911, Train Acc: 0.5820
Validation Acc: 0.5000
No improvement (1/10).
Epoch [11/50], Loss: 0.7349, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (2/10).
Epoch [12/50], Loss: 0.7298, Train Acc: 0.5078
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7273, Train Acc: 0.5000
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7219, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7228, Train Acc: 0.4922
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7188, Train Acc: 0.5000
Validation Acc: 0.5000
No improvement (7/10).
Epoch [17/50], Loss: 0.7177, Train Acc: 0.4961
Validation Acc: 0.5000
No improvement (8/10).
Epoch [18/50], Loss: 0.7180, Train Acc: 0.4883
Validation Acc: 0.5000
No improvement (9/10).
Epoch [19/50], Loss: 0.7138, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.50 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.02s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02142944518769857, 'rho': 6178.094190942474, 'd': 0.7346427830918018, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [3:46:46<9:02:54, 1357.26s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3299_1200/steady_state_trajectories/m_traj_3299.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 2979.22

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2570, Train Acc: 0.5234
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8789, Train Acc: 0.6133
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.8002, Train Acc: 0.6641
Validation Acc: 0.6250
No improvement (2/10).
Epoch [4/100], Loss: 0.7413, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6164, Train Acc: 0.7344
Validation Acc: 0.6406
Epoch [6/100], Loss: 0.5518, Train Acc: 0.7734
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.5076, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4411, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/100], Loss: 0.4070, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (4/10).
Epoch [10/100], Loss: 0.3927, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3787, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/100], Loss: 0.3796, Train Acc: 0.8086
Validation Acc: 0.6406
No improvement (7/10).
Epoch [13/100], Loss: 0.3237, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (8/10).
Epoch [14/100], Loss: 0.3387, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (9/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6650, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6136, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5936, Train Acc: 0.8477
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8398
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5794, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5633, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5542, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5561, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (5/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (6/10).
Epoch [12/50], Loss: 0.5442, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (7/10).
Epoch [13/50], Loss: 0.5589, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (9/10).
Epoch [15/50], Loss: 0.5499, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.79 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6094
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6821, Train Acc: 0.6562
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6571, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (1/10).
Epoch [5/50], Loss: 0.6241, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [6/50], Loss: 0.6199, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6562
No improvement (2/10).
Epoch [8/50], Loss: 0.6176, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.5987, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (1/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (2/10).
Epoch [11/50], Loss: 0.5799, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [12/50], Loss: 0.5792, Train Acc: 0.7812
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7344
Validation Acc: 0.5312
No improvement (5/10).
Epoch [14/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (6/10).
Epoch [15/50], Loss: 0.5991, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (7/10).
Epoch [16/50], Loss: 0.5813, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.5866, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (9/10).
Epoch [18/50], Loss: 0.5760, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6200.57602530553, 'sigma_b': 0.02135167434920005, 'd': 0.7346434521785425}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.21s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.11
    - Variance: 3108.25

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.62 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1407, Train Acc: 0.5742
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8741, Train Acc: 0.6484
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7929, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6168, Train Acc: 0.7461
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4796, Train Acc: 0.7500
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/100], Loss: 0.4539, Train Acc: 0.7617
Validation Acc: 0.5781
Epoch [7/100], Loss: 0.4716, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/100], Loss: 0.4048, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.3922, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4063, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (5/10).
Epoch [12/100], Loss: 0.3197, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (6/10).
Epoch [13/100], Loss: 0.3341, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [14/100], Loss: 0.3110, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.2872, Train Acc: 0.8516
Validation Acc: 0.6250
No improvement (1/10).
Epoch [16/100], Loss: 0.2476, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.2348, Train Acc: 0.8945
Validation Acc: 0.5625
No improvement (3/10).
Epoch [18/100], Loss: 0.1971, Train Acc: 0.9180
Validation Acc: 0.5469
No improvement (4/10).
Epoch [19/100], Loss: 0.1987, Train Acc: 0.9219
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.2729, Train Acc: 0.8750
Validation Acc: 0.5156
No improvement (6/10).
Epoch [21/100], Loss: 0.1836, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (7/10).
Epoch [22/100], Loss: 0.1737, Train Acc: 0.9297
Validation Acc: 0.5781
No improvement (8/10).
Epoch [23/100], Loss: 0.1972, Train Acc: 0.9062
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1839, Train Acc: 0.9141
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6684, Train Acc: 0.8086
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6238, Train Acc: 0.8438
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.6018, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5911, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (1/10).
Epoch [7/50], Loss: 0.6048, Train Acc: 0.7617
Validation Acc: 0.8438
No improvement (2/10).
Epoch [8/50], Loss: 0.5820, Train Acc: 0.7930
Validation Acc: 0.9375
Epoch [9/50], Loss: 0.5792, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5666, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (2/10).
Epoch [11/50], Loss: 0.5743, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (3/10).
Epoch [12/50], Loss: 0.5511, Train Acc: 0.8594
Validation Acc: 0.9375
No improvement (4/10).
Epoch [13/50], Loss: 0.5667, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (5/10).
Epoch [14/50], Loss: 0.5626, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (6/10).
Epoch [15/50], Loss: 0.5631, Train Acc: 0.8203
Validation Acc: 0.9375
No improvement (7/10).
Epoch [16/50], Loss: 0.5511, Train Acc: 0.8359
Validation Acc: 0.9375
No improvement (8/10).
Epoch [17/50], Loss: 0.5427, Train Acc: 0.8555
Validation Acc: 0.9219
No improvement (9/10).
Epoch [18/50], Loss: 0.5476, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5391
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6895, Train Acc: 0.6172
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6796, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [4/50], Loss: 0.6660, Train Acc: 0.6445
Validation Acc: 0.5938
Epoch [5/50], Loss: 0.6489, Train Acc: 0.6719
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6337, Train Acc: 0.7188
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.6290, Train Acc: 0.7109
Validation Acc: 0.7969
No improvement (2/10).
Epoch [8/50], Loss: 0.6668, Train Acc: 0.6328
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.7029, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (4/10).
Epoch [10/50], Loss: 0.6988, Train Acc: 0.5547
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.6911, Train Acc: 0.5781
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.6364, Train Acc: 0.6719
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.6090, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6077, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.6108, Train Acc: 0.7383
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.45s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.18s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.24s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.99s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.26s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.96s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.19s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02135167434920005, 'rho': 6200.57602530553, 'd': 0.7346434521785425, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.99s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [4:09:34<8:41:33, 1360.58s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3311_1200/steady_state_trajectories/m_traj_3311.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.20
    - Variance: 3234.53

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2707, Train Acc: 0.5508
Validation Acc: 0.6875
Epoch [2/100], Loss: 0.7531, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7840, Train Acc: 0.6680
Validation Acc: 0.7031
Epoch [4/100], Loss: 0.6752, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (1/10).
Epoch [5/100], Loss: 0.6537, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.4613, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (3/10).
Epoch [7/100], Loss: 0.4813, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.3949, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (5/10).
Epoch [9/100], Loss: 0.4336, Train Acc: 0.8125
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/100], Loss: 0.3506, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3409, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (8/10).
Epoch [12/100], Loss: 0.3381, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.3232, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8477
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6130, Train Acc: 0.8750
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5895, Train Acc: 0.8594
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5760, Train Acc: 0.8047
Validation Acc: 0.5469
No improvement (1/10).
Epoch [7/50], Loss: 0.5825, Train Acc: 0.7773
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8086
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5668, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/50], Loss: 0.5526, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (5/10).
Epoch [11/50], Loss: 0.5675, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.5521, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5535, Train Acc: 0.8125
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5664, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [15/50], Loss: 0.5510, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (2/10).
Epoch [16/50], Loss: 0.5432, Train Acc: 0.8398
Validation Acc: 0.7812
No improvement (3/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [18/50], Loss: 0.5462, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5452, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (6/10).
Epoch [20/50], Loss: 0.5329, Train Acc: 0.8398
Validation Acc: 0.7969
No improvement (7/10).
Epoch [21/50], Loss: 0.5453, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (8/10).
Epoch [22/50], Loss: 0.5436, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (9/10).
Epoch [23/50], Loss: 0.5456, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5117
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6896, Train Acc: 0.6211
Validation Acc: 0.6875
Epoch [3/50], Loss: 0.6811, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6654, Train Acc: 0.6680
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6386, Train Acc: 0.7422
Validation Acc: 0.5000
No improvement (1/10).
Epoch [6/50], Loss: 0.6309, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6506, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (3/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6875
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/50], Loss: 0.6283, Train Acc: 0.6953
Validation Acc: 0.6250
No improvement (5/10).
Epoch [10/50], Loss: 0.6332, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (6/10).
Epoch [11/50], Loss: 0.6133, Train Acc: 0.7188
Validation Acc: 0.5938
No improvement (7/10).
Epoch [12/50], Loss: 0.5913, Train Acc: 0.7617
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5786, Train Acc: 0.7852
Validation Acc: 0.6094
No improvement (9/10).
Epoch [14/50], Loss: 0.5786, Train Acc: 0.7812
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6223.057859376579, 'sigma_b': 0.02127446595601114, 'd': 0.7346441164387905}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.87s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3186.98

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.65 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.47 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2541, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8946, Train Acc: 0.6680
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.8024, Train Acc: 0.7109
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.5976, Train Acc: 0.7227
Validation Acc: 0.6406
Epoch [5/100], Loss: 0.5083, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [6/100], Loss: 0.4253, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/100], Loss: 0.4287, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (3/10).
Epoch [8/100], Loss: 0.3951, Train Acc: 0.8281
Validation Acc: 0.6406
No improvement (4/10).
Epoch [9/100], Loss: 0.3053, Train Acc: 0.8594
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.3032, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (1/10).
Epoch [11/100], Loss: 0.3006, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (2/10).
Epoch [12/100], Loss: 0.2899, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [13/100], Loss: 0.2578, Train Acc: 0.9023
Validation Acc: 0.6875
No improvement (1/10).
Epoch [14/100], Loss: 0.2516, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (2/10).
Epoch [15/100], Loss: 0.2464, Train Acc: 0.8789
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/100], Loss: 0.2040, Train Acc: 0.9297
Validation Acc: 0.7188
Epoch [17/100], Loss: 0.2128, Train Acc: 0.9180
Validation Acc: 0.7188
No improvement (1/10).
Epoch [18/100], Loss: 0.1991, Train Acc: 0.9258
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.1756, Train Acc: 0.9258
Validation Acc: 0.7188
No improvement (3/10).
Epoch [20/100], Loss: 0.2258, Train Acc: 0.8945
Validation Acc: 0.6875
No improvement (4/10).
Epoch [21/100], Loss: 0.1779, Train Acc: 0.9297
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/100], Loss: 0.2116, Train Acc: 0.9141
Validation Acc: 0.7344
Epoch [23/100], Loss: 0.1476, Train Acc: 0.9297
Validation Acc: 0.7500
Epoch [24/100], Loss: 0.1505, Train Acc: 0.9375
Validation Acc: 0.7500
No improvement (1/10).
Epoch [25/100], Loss: 0.1602, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (2/10).
Epoch [26/100], Loss: 0.1075, Train Acc: 0.9570
Validation Acc: 0.7188
No improvement (3/10).
Epoch [27/100], Loss: 0.1066, Train Acc: 0.9609
Validation Acc: 0.7188
No improvement (4/10).
Epoch [28/100], Loss: 0.1172, Train Acc: 0.9531
Validation Acc: 0.7188
No improvement (5/10).
Epoch [29/100], Loss: 0.1048, Train Acc: 0.9688
Validation Acc: 0.7188
No improvement (6/10).
Epoch [30/100], Loss: 0.0858, Train Acc: 0.9688
Validation Acc: 0.7188
No improvement (7/10).
Epoch [31/100], Loss: 0.1172, Train Acc: 0.9688
Validation Acc: 0.7188
No improvement (8/10).
Epoch [32/100], Loss: 0.0870, Train Acc: 0.9688
Validation Acc: 0.7031
No improvement (9/10).
Epoch [33/100], Loss: 0.0811, Train Acc: 0.9805
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8359
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6221, Train Acc: 0.8359
Validation Acc: 0.8281
No improvement (1/10).
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8594
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5777, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5956, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (2/10).
Epoch [8/50], Loss: 0.5729, Train Acc: 0.7891
Validation Acc: 0.9062
Epoch [9/50], Loss: 0.5660, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (1/10).
Epoch [10/50], Loss: 0.5679, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (2/10).
Epoch [11/50], Loss: 0.5645, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5534, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (4/10).
Epoch [13/50], Loss: 0.5641, Train Acc: 0.7773
Validation Acc: 0.9062
No improvement (5/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8164
Validation Acc: 0.9219
Epoch [15/50], Loss: 0.5517, Train Acc: 0.7891
Validation Acc: 0.9375
Epoch [16/50], Loss: 0.5486, Train Acc: 0.8008
Validation Acc: 0.9375
No improvement (1/10).
Epoch [17/50], Loss: 0.5330, Train Acc: 0.8477
Validation Acc: 0.9219
No improvement (2/10).
Epoch [18/50], Loss: 0.5283, Train Acc: 0.8125
Validation Acc: 0.9219
No improvement (3/10).
Epoch [19/50], Loss: 0.5416, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (4/10).
Epoch [20/50], Loss: 0.5299, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (5/10).
Epoch [21/50], Loss: 0.5447, Train Acc: 0.7930
Validation Acc: 0.9062
No improvement (6/10).
Epoch [22/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [23/50], Loss: 0.5381, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (8/10).
Epoch [24/50], Loss: 0.5475, Train Acc: 0.7812
Validation Acc: 0.9219
No improvement (9/10).
Epoch [25/50], Loss: 0.5343, Train Acc: 0.8125
Validation Acc: 0.9375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6925, Train Acc: 0.5703
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6714, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [4/50], Loss: 0.6581, Train Acc: 0.6758
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/50], Loss: 0.6511, Train Acc: 0.6680
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.6405, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [7/50], Loss: 0.6296, Train Acc: 0.7070
Validation Acc: 0.6562
Epoch [8/50], Loss: 0.6302, Train Acc: 0.7031
Validation Acc: 0.7188
Epoch [9/50], Loss: 0.6285, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6259, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.6188, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (3/10).
Epoch [12/50], Loss: 0.6185, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6066, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/50], Loss: 0.6049, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [15/50], Loss: 0.6114, Train Acc: 0.7266
Validation Acc: 0.6719
No improvement (7/10).
Epoch [16/50], Loss: 0.6035, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [17/50], Loss: 0.5976, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (1/10).
Epoch [18/50], Loss: 0.5951, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [19/50], Loss: 0.6011, Train Acc: 0.7383
Validation Acc: 0.7031
No improvement (3/10).
Epoch [20/50], Loss: 0.5985, Train Acc: 0.7383
Validation Acc: 0.7344
No improvement (4/10).
Epoch [21/50], Loss: 0.5833, Train Acc: 0.7773
Validation Acc: 0.7969
Epoch [22/50], Loss: 0.5721, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (1/10).
Epoch [23/50], Loss: 0.5777, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (2/10).
Epoch [24/50], Loss: 0.5996, Train Acc: 0.7461
Validation Acc: 0.7656
No improvement (3/10).
Epoch [25/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (4/10).
Epoch [26/50], Loss: 0.5990, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (5/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (6/10).
Epoch [28/50], Loss: 0.5859, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (7/10).
Epoch [29/50], Loss: 0.5928, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (8/10).
Epoch [30/50], Loss: 0.5982, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (9/10).
Epoch [31/50], Loss: 0.5887, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.01s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.96s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02127446595601114, 'rho': 6223.057859376579, 'd': 0.7346441164387905, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [4:32:23<8:19:49, 1363.16s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3323_1200/steady_state_trajectories/m_traj_3323.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.37
    - Variance: 3375.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4401, Train Acc: 0.4648
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9168, Train Acc: 0.6367
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8102, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.7738, Train Acc: 0.6797
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5852, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (2/10).
Epoch [6/100], Loss: 0.5294, Train Acc: 0.7656
Validation Acc: 0.6406
Epoch [7/100], Loss: 0.5037, Train Acc: 0.7969
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/100], Loss: 0.4267, Train Acc: 0.7773
Validation Acc: 0.7031
Epoch [9/100], Loss: 0.4237, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (1/10).
Epoch [10/100], Loss: 0.3728, Train Acc: 0.8203
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/100], Loss: 0.4105, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (3/10).
Epoch [12/100], Loss: 0.3598, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (4/10).
Epoch [13/100], Loss: 0.2647, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (5/10).
Epoch [14/100], Loss: 0.3162, Train Acc: 0.8672
Validation Acc: 0.6875
No improvement (6/10).
Epoch [15/100], Loss: 0.3139, Train Acc: 0.8555
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/100], Loss: 0.2505, Train Acc: 0.8945
Validation Acc: 0.7344
Epoch [17/100], Loss: 0.2835, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (1/10).
Epoch [18/100], Loss: 0.2985, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (2/10).
Epoch [19/100], Loss: 0.2765, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (3/10).
Epoch [20/100], Loss: 0.2143, Train Acc: 0.9141
Validation Acc: 0.6719
No improvement (4/10).
Epoch [21/100], Loss: 0.2301, Train Acc: 0.8984
Validation Acc: 0.6406
No improvement (5/10).
Epoch [22/100], Loss: 0.2219, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (6/10).
Epoch [23/100], Loss: 0.2199, Train Acc: 0.9141
Validation Acc: 0.7031
No improvement (7/10).
Epoch [24/100], Loss: 0.2156, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (8/10).
Epoch [25/100], Loss: 0.2072, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (9/10).
Epoch [26/100], Loss: 0.2369, Train Acc: 0.8945
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8594
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8672
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5715, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/50], Loss: 0.5787, Train Acc: 0.7930
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/50], Loss: 0.5585, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5667, Train Acc: 0.7891
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5567, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (5/10).
Epoch [11/50], Loss: 0.5592, Train Acc: 0.8203
Validation Acc: 0.9375
Epoch [12/50], Loss: 0.5506, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5584, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (2/10).
Epoch [14/50], Loss: 0.5561, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5490, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5421, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5378, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5513, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (8/10).
Epoch [20/50], Loss: 0.5410, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [21/50], Loss: 0.5420, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6678, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6549, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6412, Train Acc: 0.6914
Validation Acc: 0.6875
No improvement (1/10).
Epoch [6/50], Loss: 0.6226, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [7/50], Loss: 0.6155, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6099, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (4/10).
Epoch [9/50], Loss: 0.5830, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5745, Train Acc: 0.8008
Validation Acc: 0.7344
No improvement (7/10).
Epoch [12/50], Loss: 0.5841, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5763, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5672, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5765, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5621, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (2/10).
Epoch [17/50], Loss: 0.5690, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [18/50], Loss: 0.6227, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [19/50], Loss: 0.6149, Train Acc: 0.7148
Validation Acc: 0.8281
Epoch [20/50], Loss: 0.6130, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (1/10).
Epoch [21/50], Loss: 0.6107, Train Acc: 0.7188
Validation Acc: 0.8125
No improvement (2/10).
Epoch [22/50], Loss: 0.6012, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (3/10).
Epoch [23/50], Loss: 0.5981, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (4/10).
Epoch [24/50], Loss: 0.6133, Train Acc: 0.7148
Validation Acc: 0.8125
No improvement (5/10).
Epoch [25/50], Loss: 0.6063, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (6/10).
Epoch [26/50], Loss: 0.6064, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [27/50], Loss: 0.5935, Train Acc: 0.7461
Validation Acc: 0.8125
No improvement (8/10).
Epoch [28/50], Loss: 0.6044, Train Acc: 0.7305
Validation Acc: 0.8125
No improvement (9/10).
Epoch [29/50], Loss: 0.5988, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6245.539693144841, 'sigma_b': 0.021197813928616187, 'd': 0.734644775924578}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.68
    - Variance: 2997.58

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1668, Train Acc: 0.5781
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9932, Train Acc: 0.6172
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.7961, Train Acc: 0.7109
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6397, Train Acc: 0.7227
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5545, Train Acc: 0.7578
Validation Acc: 0.5938
Epoch [6/100], Loss: 0.4650, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4418, Train Acc: 0.7695
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.3850, Train Acc: 0.8281
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4019, Train Acc: 0.8008
Validation Acc: 0.6562
Epoch [10/100], Loss: 0.3383, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (1/10).
Epoch [11/100], Loss: 0.3360, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (2/10).
Epoch [12/100], Loss: 0.2854, Train Acc: 0.8789
Validation Acc: 0.6406
No improvement (3/10).
Epoch [13/100], Loss: 0.2854, Train Acc: 0.8750
Validation Acc: 0.6094
No improvement (4/10).
Epoch [14/100], Loss: 0.2723, Train Acc: 0.8789
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.2720, Train Acc: 0.8594
Validation Acc: 0.6094
No improvement (6/10).
Epoch [16/100], Loss: 0.2955, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (7/10).
Epoch [17/100], Loss: 0.2237, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (8/10).
Epoch [18/100], Loss: 0.2121, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (9/10).
Epoch [19/100], Loss: 0.1869, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6857, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6636, Train Acc: 0.8242
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8672
Validation Acc: 0.9219
Epoch [5/50], Loss: 0.5867, Train Acc: 0.8555
Validation Acc: 0.9375
Epoch [6/50], Loss: 0.5708, Train Acc: 0.8516
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.5885, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (2/10).
Epoch [8/50], Loss: 0.5597, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (3/10).
Epoch [9/50], Loss: 0.5521, Train Acc: 0.8594
Validation Acc: 0.9375
No improvement (4/10).
Epoch [10/50], Loss: 0.5610, Train Acc: 0.8594
Validation Acc: 0.9375
No improvement (5/10).
Epoch [11/50], Loss: 0.5614, Train Acc: 0.8477
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5488, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (7/10).
Epoch [13/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.9219
No improvement (8/10).
Epoch [14/50], Loss: 0.5496, Train Acc: 0.8477
Validation Acc: 0.9219
No improvement (9/10).
Epoch [15/50], Loss: 0.5532, Train Acc: 0.8477
Validation Acc: 0.9375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5391
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6719, Train Acc: 0.6719
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/50], Loss: 0.6561, Train Acc: 0.6992
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6343, Train Acc: 0.7188
Validation Acc: 0.7188
Epoch [6/50], Loss: 0.6195, Train Acc: 0.7227
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6033, Train Acc: 0.7539
Validation Acc: 0.8438
Epoch [8/50], Loss: 0.5771, Train Acc: 0.7930
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5791, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.6274, Train Acc: 0.6836
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5801, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5822, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (5/10).
Epoch [14/50], Loss: 0.5795, Train Acc: 0.7266
Validation Acc: 0.7812
No improvement (6/10).
Epoch [15/50], Loss: 0.5820, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (7/10).
Epoch [16/50], Loss: 0.5755, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (8/10).
Epoch [17/50], Loss: 0.5834, Train Acc: 0.7344
Validation Acc: 0.7812
No improvement (9/10).
Epoch [18/50], Loss: 0.5899, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.43s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.40s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.94s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.27s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.41s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.38s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.09s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.39s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021197813928616187, 'rho': 6245.539693144841, 'd': 0.734644775924578, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.10s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [4:55:28<7:59:19, 1369.51s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-332790>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-332790>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3335_1200/steady_state_trajectories/m_traj_3335.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.55
    - Variance: 3396.51

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4097, Train Acc: 0.5078
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8797, Train Acc: 0.6211
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7066, Train Acc: 0.6875
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6919, Train Acc: 0.7539
Validation Acc: 0.5312
No improvement (3/10).
Epoch [5/100], Loss: 0.5033, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4319, Train Acc: 0.8008
Validation Acc: 0.5156
No improvement (5/10).
Epoch [7/100], Loss: 0.4098, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3598, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3459, Train Acc: 0.8555
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.3433, Train Acc: 0.8516
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.2948, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6121, Train Acc: 0.8633
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8867
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5711, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (1/10).
Epoch [7/50], Loss: 0.5755, Train Acc: 0.7734
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5537, Train Acc: 0.8047
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5553, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.7812
No improvement (2/10).
Epoch [11/50], Loss: 0.5754, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (3/10).
Epoch [12/50], Loss: 0.5536, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (4/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5509, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (6/10).
Epoch [15/50], Loss: 0.5498, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (7/10).
Epoch [16/50], Loss: 0.5363, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (8/10).
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (9/10).
Epoch [18/50], Loss: 0.5341, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.5938
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6865, Train Acc: 0.6211
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6741, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [5/50], Loss: 0.6576, Train Acc: 0.6836
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6823, Train Acc: 0.5859
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7188
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6056, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6282, Train Acc: 0.6953
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6352, Train Acc: 0.6602
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6446, Train Acc: 0.6602
Validation Acc: 0.6719
No improvement (4/10).
Epoch [12/50], Loss: 0.6553, Train Acc: 0.6484
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6672, Train Acc: 0.6445
Validation Acc: 0.6719
No improvement (6/10).
Epoch [14/50], Loss: 0.6723, Train Acc: 0.6367
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/50], Loss: 0.6686, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (8/10).
Epoch [16/50], Loss: 0.6354, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (9/10).
Epoch [17/50], Loss: 0.6152, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6268.0215266287505, 'sigma_b': 0.021121712274820542, 'd': 0.7346454306872016}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.41s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.88
    - Variance: 3562.19

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3245, Train Acc: 0.5078
Validation Acc: 0.5156
Epoch [2/100], Loss: 1.0441, Train Acc: 0.6289
Validation Acc: 0.4688
No improvement (1/10).
Epoch [3/100], Loss: 0.8728, Train Acc: 0.6562
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6503, Train Acc: 0.7031
Validation Acc: 0.4375
No improvement (3/10).
Epoch [5/100], Loss: 0.5213, Train Acc: 0.7578
Validation Acc: 0.4531
No improvement (4/10).
Epoch [6/100], Loss: 0.4849, Train Acc: 0.7891
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4577, Train Acc: 0.7656
Validation Acc: 0.4531
No improvement (6/10).
Epoch [8/100], Loss: 0.4233, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (7/10).
Epoch [9/100], Loss: 0.3254, Train Acc: 0.8477
Validation Acc: 0.4844
No improvement (8/10).
Epoch [10/100], Loss: 0.3340, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [11/100], Loss: 0.3191, Train Acc: 0.8633
Validation Acc: 0.5469
Epoch [12/100], Loss: 0.3527, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (1/10).
Epoch [13/100], Loss: 0.3253, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [14/100], Loss: 0.2326, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (3/10).
Epoch [15/100], Loss: 0.3522, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [16/100], Loss: 0.2329, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (1/10).
Epoch [17/100], Loss: 0.2270, Train Acc: 0.8906
Validation Acc: 0.5938
Epoch [18/100], Loss: 0.2085, Train Acc: 0.9219
Validation Acc: 0.5625
No improvement (1/10).
Epoch [19/100], Loss: 0.2189, Train Acc: 0.9023
Validation Acc: 0.5312
No improvement (2/10).
Epoch [20/100], Loss: 0.1815, Train Acc: 0.9258
Validation Acc: 0.5312
No improvement (3/10).
Epoch [21/100], Loss: 0.1550, Train Acc: 0.9258
Validation Acc: 0.5312
No improvement (4/10).
Epoch [22/100], Loss: 0.1760, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (5/10).
Epoch [23/100], Loss: 0.2505, Train Acc: 0.8750
Validation Acc: 0.5469
No improvement (6/10).
Epoch [24/100], Loss: 0.1923, Train Acc: 0.9258
Validation Acc: 0.5625
No improvement (7/10).
Epoch [25/100], Loss: 0.1926, Train Acc: 0.9180
Validation Acc: 0.5781
No improvement (8/10).
Epoch [26/100], Loss: 0.1581, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (9/10).
Epoch [27/100], Loss: 0.1273, Train Acc: 0.9531
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7266
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6670, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6237, Train Acc: 0.8281
Validation Acc: 0.7656
No improvement (1/10).
Epoch [5/50], Loss: 0.5853, Train Acc: 0.8633
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5661, Train Acc: 0.8633
Validation Acc: 0.9062
Epoch [7/50], Loss: 0.5928, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (1/10).
Epoch [8/50], Loss: 0.5681, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5641, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (3/10).
Epoch [10/50], Loss: 0.5573, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (4/10).
Epoch [11/50], Loss: 0.5653, Train Acc: 0.7891
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (1/10).
Epoch [13/50], Loss: 0.5597, Train Acc: 0.7617
Validation Acc: 0.9062
No improvement (2/10).
Epoch [14/50], Loss: 0.5445, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (3/10).
Epoch [15/50], Loss: 0.5449, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (4/10).
Epoch [16/50], Loss: 0.5394, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (5/10).
Epoch [17/50], Loss: 0.5337, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5274, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (7/10).
Epoch [19/50], Loss: 0.5303, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5326, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5421, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6882, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6736, Train Acc: 0.6484
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6557, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/50], Loss: 0.6394, Train Acc: 0.7227
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7461
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.6080, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (2/10).
Epoch [8/50], Loss: 0.6020, Train Acc: 0.7461
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5783, Train Acc: 0.7812
Validation Acc: 0.9062
Epoch [10/50], Loss: 0.5916, Train Acc: 0.7461
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.6110, Train Acc: 0.7148
Validation Acc: 0.7344
No improvement (2/10).
Epoch [12/50], Loss: 0.6463, Train Acc: 0.6484
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.6754, Train Acc: 0.5938
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/50], Loss: 0.6900, Train Acc: 0.5664
Validation Acc: 0.6250
No improvement (5/10).
Epoch [15/50], Loss: 0.6910, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (6/10).
Epoch [16/50], Loss: 0.6801, Train Acc: 0.5703
Validation Acc: 0.6250
No improvement (7/10).
Epoch [17/50], Loss: 0.6797, Train Acc: 0.5586
Validation Acc: 0.6250
No improvement (8/10).
Epoch [18/50], Loss: 0.6792, Train Acc: 0.5547
Validation Acc: 0.6250
No improvement (9/10).
Epoch [19/50], Loss: 0.6791, Train Acc: 0.5586
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.021121712274820542, 'rho': 6268.0215266287505, 'd': 0.7346454306872016, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [5:18:17<7:36:28, 1369.42s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
<lambdifygenerated-358368>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-358368>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running Variance Ratio Simulations:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [6:01:34<9:10:41, 1739.05s/it]<lambdifygenerated-410261>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-410261>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3347_1200/steady_state_trajectories/m_traj_3347.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.86
    - Variance: 3047.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3994, Train Acc: 0.4805
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9349, Train Acc: 0.6367
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.7136, Train Acc: 0.6875
Validation Acc: 0.4688
No improvement (2/10).
Epoch [4/100], Loss: 0.6501, Train Acc: 0.7227
Validation Acc: 0.4688
No improvement (3/10).
Epoch [5/100], Loss: 0.5663, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4721, Train Acc: 0.8008
Validation Acc: 0.4844
No improvement (5/10).
Epoch [7/100], Loss: 0.4809, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (6/10).
Epoch [8/100], Loss: 0.4053, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.3967, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (8/10).
Epoch [10/100], Loss: 0.4113, Train Acc: 0.8125
Validation Acc: 0.4375
No improvement (9/10).
Epoch [11/100], Loss: 0.3511, Train Acc: 0.8516
Validation Acc: 0.4844
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6664, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6168, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8594
Validation Acc: 0.8906
No improvement (1/10).
Epoch [6/50], Loss: 0.5796, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5593, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5657, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (6/10).
Epoch [11/50], Loss: 0.5649, Train Acc: 0.8047
Validation Acc: 0.7969
No improvement (7/10).
Epoch [12/50], Loss: 0.5480, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5477, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (1/10).
Epoch [14/50], Loss: 0.5673, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (2/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (3/10).
Epoch [16/50], Loss: 0.5349, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (4/10).
Epoch [17/50], Loss: 0.5348, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (5/10).
Epoch [18/50], Loss: 0.5369, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (6/10).
Epoch [19/50], Loss: 0.5243, Train Acc: 0.8789
Validation Acc: 0.9219
Epoch [20/50], Loss: 0.5388, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5429, Train Acc: 0.8125
Validation Acc: 0.9375
Epoch [22/50], Loss: 0.5404, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (1/10).
Epoch [23/50], Loss: 0.5384, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (2/10).
Epoch [24/50], Loss: 0.5424, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [25/50], Loss: 0.5351, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (4/10).
Epoch [26/50], Loss: 0.5367, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (5/10).
Epoch [27/50], Loss: 0.5275, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [28/50], Loss: 0.5350, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (7/10).
Epoch [29/50], Loss: 0.5309, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (8/10).
Epoch [30/50], Loss: 0.5232, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (9/10).
Epoch [31/50], Loss: 0.5300, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6250
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6774, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6607, Train Acc: 0.6641
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6430, Train Acc: 0.7227
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6505, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6310, Train Acc: 0.7031
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7344
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/50], Loss: 0.5957, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [10/50], Loss: 0.6136, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (3/10).
Epoch [11/50], Loss: 0.6186, Train Acc: 0.6797
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5929, Train Acc: 0.7383
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.5861, Train Acc: 0.7852
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5764, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5496, Train Acc: 0.8281
Validation Acc: 0.8281
Epoch [16/50], Loss: 0.5788, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [17/50], Loss: 0.5918, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (2/10).
Epoch [18/50], Loss: 0.5957, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (3/10).
Epoch [19/50], Loss: 0.6003, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (4/10).
Epoch [20/50], Loss: 0.5982, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (5/10).
Epoch [21/50], Loss: 0.6145, Train Acc: 0.6953
Validation Acc: 0.8125
No improvement (6/10).
Epoch [22/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (7/10).
Epoch [23/50], Loss: 0.5743, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [24/50], Loss: 0.5625, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5584, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] âŒ No suitable solution found.
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138044316, 'sigma_b': 0.060145439998485865, 'd': 0.7827636158617431}
âš ï¸ Skipping simulation for ratio 2.8000 due to stress failure.

Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
[STRESS] âœ… Found: {'rho': 6312.985192732142, 'sigma_b': 0.020971136546384224, 'd': 0.7346467262444651}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138059095, 'sigma_b': 0.06014543999849508, 'd': 0.7827636158617438}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.85
    - Variance: 3166.80

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.51
    - Variance: 1053.47
=== SVM (RBF Kernel) Classification Accuracy: 0.82 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.68 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3128, Train Acc: 0.5664
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.7769, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.8753, Train Acc: 0.6719
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6456, Train Acc: 0.7148
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.4892, Train Acc: 0.7852
Validation Acc: 0.5938
Epoch [6/100], Loss: 0.5016, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4004, Train Acc: 0.8086
Validation Acc: 0.6250
Epoch [8/100], Loss: 0.4241, Train Acc: 0.8164
Validation Acc: 0.6562
Epoch [9/100], Loss: 0.3147, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (1/10).
Epoch [10/100], Loss: 0.3240, Train Acc: 0.8438
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3299, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (3/10).
Epoch [12/100], Loss: 0.3194, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2786, Train Acc: 0.8672
Validation Acc: 0.6562
No improvement (5/10).
Epoch [14/100], Loss: 0.2593, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [15/100], Loss: 0.2730, Train Acc: 0.8867
Validation Acc: 0.6406
No improvement (1/10).
Epoch [16/100], Loss: 0.1952, Train Acc: 0.9258
Validation Acc: 0.6562
No improvement (2/10).
Epoch [17/100], Loss: 0.2508, Train Acc: 0.9023
Validation Acc: 0.6406
No improvement (3/10).
Epoch [18/100], Loss: 0.2797, Train Acc: 0.8867
Validation Acc: 0.6719
No improvement (4/10).
Epoch [19/100], Loss: 0.2314, Train Acc: 0.8984
Validation Acc: 0.6562
No improvement (5/10).
Epoch [20/100], Loss: 0.1882, Train Acc: 0.9180
Validation Acc: 0.7031
Epoch [21/100], Loss: 0.2128, Train Acc: 0.8984
Validation Acc: 0.6719
No improvement (1/10).
Epoch [22/100], Loss: 0.1799, Train Acc: 0.9219
Validation Acc: 0.6875
No improvement (2/10).
Epoch [23/100], Loss: 0.1450, Train Acc: 0.9492
Validation Acc: 0.6875
No improvement (3/10).
Epoch [24/100], Loss: 0.1900, Train Acc: 0.9414
Validation Acc: 0.7031
No improvement (4/10).
Epoch [25/100], Loss: 0.1325, Train Acc: 0.9492
Validation Acc: 0.7031
No improvement (5/10).
Epoch [26/100], Loss: 0.1426, Train Acc: 0.9453
Validation Acc: 0.7031
No improvement (6/10).
Epoch [27/100], Loss: 0.1601, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (7/10).
Epoch [28/100], Loss: 0.1451, Train Acc: 0.9609
Validation Acc: 0.6875
No improvement (8/10).
Epoch [29/100], Loss: 0.1724, Train Acc: 0.9297
Validation Acc: 0.6875
No improvement (9/10).
Epoch [30/100], Loss: 0.1604, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.66 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6858, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8633
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6127, Train Acc: 0.8672
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8672
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.5647, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [7/50], Loss: 0.5804, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5629, Train Acc: 0.8125
Validation Acc: 0.7656
No improvement (2/10).
Epoch [9/50], Loss: 0.5516, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (4/10).
Epoch [11/50], Loss: 0.5493, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [12/50], Loss: 0.5397, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5581, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (7/10).
Epoch [14/50], Loss: 0.5490, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5500, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (9/10).
Epoch [16/50], Loss: 0.5361, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6905, Train Acc: 0.5977
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6839, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [4/50], Loss: 0.6685, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6221, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6331, Train Acc: 0.7344
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.6428, Train Acc: 0.6680
Validation Acc: 0.6719
No improvement (2/10).
Epoch [8/50], Loss: 0.6143, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.5866, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5902, Train Acc: 0.7344
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.5928, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (6/10).
Epoch [12/50], Loss: 0.5789, Train Acc: 0.7539
Validation Acc: 0.6875
No improvement (7/10).
Epoch [13/50], Loss: 0.5772, Train Acc: 0.7656
Validation Acc: 0.7188
No improvement (8/10).
Epoch [14/50], Loss: 0.5742, Train Acc: 0.7656
Validation Acc: 0.7031
No improvement (9/10).
Epoch [15/50], Loss: 0.5715, Train Acc: 0.7695
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.16s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  6.00s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.28s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020971136546384224, 'rho': 6312.985192732142, 'd': 0.7346467262444651, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [6:16:53<7:27:42, 1492.34s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849508, 'rho': 1179.1338138059095, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3371_1200/steady_state_trajectories/m_traj_3371.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.96
    - Variance: 3241.35

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2008, Train Acc: 0.5508
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8104, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7458, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.7002, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5463, Train Acc: 0.7422
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5025, Train Acc: 0.7734
Validation Acc: 0.6875
Epoch [7/100], Loss: 0.4723, Train Acc: 0.8086
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3888, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/100], Loss: 0.3913, Train Acc: 0.8203
Validation Acc: 0.6562
No improvement (3/10).
Epoch [10/100], Loss: 0.3509, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.3019, Train Acc: 0.8711
Validation Acc: 0.5938
No improvement (5/10).
Epoch [12/100], Loss: 0.3311, Train Acc: 0.8398
Validation Acc: 0.6250
No improvement (6/10).
Epoch [13/100], Loss: 0.3100, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (7/10).
Epoch [14/100], Loss: 0.2796, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (8/10).
Epoch [15/100], Loss: 0.2753, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (9/10).
Epoch [16/100], Loss: 0.2074, Train Acc: 0.9141
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6862, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8398
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6090, Train Acc: 0.8711
Validation Acc: 0.9531
Epoch [5/50], Loss: 0.5838, Train Acc: 0.8750
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5714, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/50], Loss: 0.5738, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5567, Train Acc: 0.8281
Validation Acc: 0.5156
No improvement (5/10).
Epoch [10/50], Loss: 0.5532, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5576, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [12/50], Loss: 0.5485, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (8/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6775, Train Acc: 0.6562
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6445
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6561, Train Acc: 0.6523
Validation Acc: 0.5625
No improvement (1/10).
Epoch [6/50], Loss: 0.6139, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5851, Train Acc: 0.7852
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.7050, Train Acc: 0.5625
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/50], Loss: 0.7103, Train Acc: 0.5469
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7112, Train Acc: 0.5352
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.7024, Train Acc: 0.5391
Validation Acc: 0.5000
No improvement (4/10).
Epoch [12/50], Loss: 0.6989, Train Acc: 0.5469
Validation Acc: 0.5000
No improvement (5/10).
Epoch [13/50], Loss: 0.6915, Train Acc: 0.5586
Validation Acc: 0.5000
No improvement (6/10).
Epoch [14/50], Loss: 0.6938, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/50], Loss: 0.6930, Train Acc: 0.5469
Validation Acc: 0.5312
No improvement (8/10).
Epoch [16/50], Loss: 0.6889, Train Acc: 0.5586
Validation Acc: 0.5312
No improvement (9/10).
Epoch [17/50], Loss: 0.6882, Train Acc: 0.5625
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.55 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
[STRESS] âœ… Found: {'rho': 6335.467025368994, 'sigma_b': 0.020896650909975157, 'd': 0.7346473671380898}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138181327, 'sigma_b': 0.060145439998482354, 'd': 0.7827636158612069}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.98s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.29
    - Variance: 2891.41

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.73
    - Variance: 1124.11
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3847, Train Acc: 0.5195
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8336, Train Acc: 0.6562
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7320, Train Acc: 0.6680
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6944, Train Acc: 0.7109
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5497, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/100], Loss: 0.4607, Train Acc: 0.7930
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4214, Train Acc: 0.8164
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/100], Loss: 0.4047, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4079, Train Acc: 0.8203
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.3422, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (4/10).
Epoch [11/100], Loss: 0.2737, Train Acc: 0.8594
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3835, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [13/100], Loss: 0.3522, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [14/100], Loss: 0.3030, Train Acc: 0.8594
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.2745, Train Acc: 0.8789
Validation Acc: 0.6406
No improvement (1/10).
Epoch [16/100], Loss: 0.3084, Train Acc: 0.8672
Validation Acc: 0.6250
No improvement (2/10).
Epoch [17/100], Loss: 0.2421, Train Acc: 0.8828
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.2800, Train Acc: 0.8633
Validation Acc: 0.5469
No improvement (4/10).
Epoch [19/100], Loss: 0.2405, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (5/10).
Epoch [20/100], Loss: 0.2723, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (6/10).
Epoch [21/100], Loss: 0.1772, Train Acc: 0.9258
Validation Acc: 0.5625
No improvement (7/10).
Epoch [22/100], Loss: 0.2128, Train Acc: 0.9258
Validation Acc: 0.5938
No improvement (8/10).
Epoch [23/100], Loss: 0.2048, Train Acc: 0.9102
Validation Acc: 0.6094
No improvement (9/10).
Epoch [24/100], Loss: 0.2220, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6673, Train Acc: 0.8047
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6206, Train Acc: 0.8086
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (1/10).
Epoch [6/50], Loss: 0.5704, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (2/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.5765, Train Acc: 0.7891
Validation Acc: 0.9375
Epoch [9/50], Loss: 0.5745, Train Acc: 0.8125
Validation Acc: 0.9375
No improvement (1/10).
Epoch [10/50], Loss: 0.5691, Train Acc: 0.7852
Validation Acc: 0.9531
Epoch [11/50], Loss: 0.5630, Train Acc: 0.7969
Validation Acc: 0.9375
No improvement (1/10).
Epoch [12/50], Loss: 0.5599, Train Acc: 0.7852
Validation Acc: 0.9375
No improvement (2/10).
Epoch [13/50], Loss: 0.5631, Train Acc: 0.7812
Validation Acc: 0.9219
No improvement (3/10).
Epoch [14/50], Loss: 0.5665, Train Acc: 0.7617
Validation Acc: 0.9844
Epoch [15/50], Loss: 0.5646, Train Acc: 0.7734
Validation Acc: 0.9375
No improvement (1/10).
Epoch [16/50], Loss: 0.5468, Train Acc: 0.7930
Validation Acc: 0.9688
No improvement (2/10).
Epoch [17/50], Loss: 0.5201, Train Acc: 0.8516
Validation Acc: 0.9844
No improvement (3/10).
Epoch [18/50], Loss: 0.5325, Train Acc: 0.8086
Validation Acc: 0.9844
No improvement (4/10).
Epoch [19/50], Loss: 0.5533, Train Acc: 0.7773
Validation Acc: 0.9688
No improvement (5/10).
Epoch [20/50], Loss: 0.5204, Train Acc: 0.8242
Validation Acc: 0.9375
No improvement (6/10).
Epoch [21/50], Loss: 0.5277, Train Acc: 0.7969
Validation Acc: 0.9375
No improvement (7/10).
Epoch [22/50], Loss: 0.5344, Train Acc: 0.8242
Validation Acc: 0.9688
No improvement (8/10).
Epoch [23/50], Loss: 0.5375, Train Acc: 0.8047
Validation Acc: 0.9688
No improvement (9/10).
Epoch [24/50], Loss: 0.5500, Train Acc: 0.7734
Validation Acc: 0.9688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6900, Train Acc: 0.6328
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6799, Train Acc: 0.6484
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6592, Train Acc: 0.7031
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6638, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.6216, Train Acc: 0.7539
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5925, Train Acc: 0.7852
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.6029, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.6622, Train Acc: 0.6211
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6781, Train Acc: 0.5898
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6652, Train Acc: 0.6016
Validation Acc: 0.5938
No improvement (4/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.5938
Validation Acc: 0.5781
No improvement (5/10).
Epoch [13/50], Loss: 0.6620, Train Acc: 0.5938
Validation Acc: 0.5781
No improvement (6/10).
Epoch [14/50], Loss: 0.6645, Train Acc: 0.5859
Validation Acc: 0.5781
No improvement (7/10).
Epoch [15/50], Loss: 0.6638, Train Acc: 0.5820
Validation Acc: 0.5781
No improvement (8/10).
Epoch [16/50], Loss: 0.6583, Train Acc: 0.5938
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/50], Loss: 0.6535, Train Acc: 0.6016
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.60 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.16s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.26s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.28s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.07s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020896650909975157, 'rho': 6335.467025368994, 'd': 0.7346473671380898, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [6:29:24<5:59:44, 1269.69s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998482354, 'rho': 1179.1338138181327, 'd': 0.7827636158612069, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3383_1200/steady_state_trajectories/m_traj_3383.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.25
    - Variance: 2842.84

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.86 ===
=== Logistic Regression Accuracy: 0.65 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4954, Train Acc: 0.4922
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9106, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.7602, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6747, Train Acc: 0.7266
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.5634, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (2/10).
Epoch [6/100], Loss: 0.5260, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4880, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3638, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (5/10).
Epoch [9/100], Loss: 0.3859, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/100], Loss: 0.3881, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (7/10).
Epoch [11/100], Loss: 0.3378, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (8/10).
Epoch [12/100], Loss: 0.3204, Train Acc: 0.8594
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3328, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6668, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6156, Train Acc: 0.8320
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5884, Train Acc: 0.8750
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5816, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (2/10).
Epoch [7/50], Loss: 0.5844, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5659, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5506, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [11/50], Loss: 0.5610, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (7/10).
Epoch [12/50], Loss: 0.5483, Train Acc: 0.8516
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.5578, Train Acc: 0.7969
Validation Acc: 0.8594
Epoch [15/50], Loss: 0.5440, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (1/10).
Epoch [16/50], Loss: 0.5452, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5226, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [18/50], Loss: 0.5407, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [19/50], Loss: 0.5301, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [20/50], Loss: 0.5367, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5364, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (4/10).
Epoch [22/50], Loss: 0.5429, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (5/10).
Epoch [23/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (6/10).
Epoch [24/50], Loss: 0.5466, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [25/50], Loss: 0.5281, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (8/10).
Epoch [26/50], Loss: 0.5391, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (9/10).
Epoch [27/50], Loss: 0.5289, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5469
Validation Acc: 0.4375
Epoch [2/50], Loss: 0.6841, Train Acc: 0.6523
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6650, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6474, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6301, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7266
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6110, Train Acc: 0.7227
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5978, Train Acc: 0.7578
Validation Acc: 0.7500
Epoch [9/50], Loss: 0.5918, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/50], Loss: 0.5812, Train Acc: 0.7695
Validation Acc: 0.5156
No improvement (2/10).
Epoch [11/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5768, Train Acc: 0.7695
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.6058, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.6240, Train Acc: 0.6758
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7305
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.6048, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5787, Train Acc: 0.7656
Validation Acc: 0.8594
Epoch [18/50], Loss: 0.5615, Train Acc: 0.7969
Validation Acc: 0.8750
Epoch [19/50], Loss: 0.5610, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (1/10).
Epoch [20/50], Loss: 0.5656, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (2/10).
Epoch [21/50], Loss: 0.5678, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [22/50], Loss: 0.5341, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (4/10).
Epoch [23/50], Loss: 0.5243, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (5/10).
Epoch [24/50], Loss: 0.4972, Train Acc: 0.8672
Validation Acc: 0.8438
No improvement (6/10).
Epoch [25/50], Loss: 0.4937, Train Acc: 0.8633
Validation Acc: 0.8281
No improvement (7/10).
Epoch [26/50], Loss: 0.5090, Train Acc: 0.8477
Validation Acc: 0.7031
No improvement (8/10).
Epoch [27/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.7188
No improvement (9/10).
Epoch [28/50], Loss: 0.4977, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.90 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6357.948857973735, 'sigma_b': 0.020822692520704882, 'd': 0.7346480035065075}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.42s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.46
    - Variance: 3438.79

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1827, Train Acc: 0.5195
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9080, Train Acc: 0.6289
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8412, Train Acc: 0.6719
Validation Acc: 0.5312
No improvement (2/10).
Epoch [4/100], Loss: 0.6246, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (3/10).
Epoch [5/100], Loss: 0.4939, Train Acc: 0.7500
Validation Acc: 0.6094
Epoch [6/100], Loss: 0.5061, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.4974, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.4425, Train Acc: 0.8086
Validation Acc: 0.5938
No improvement (3/10).
Epoch [9/100], Loss: 0.4317, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (4/10).
Epoch [10/100], Loss: 0.3359, Train Acc: 0.8359
Validation Acc: 0.5938
No improvement (5/10).
Epoch [11/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/100], Loss: 0.2844, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (7/10).
Epoch [13/100], Loss: 0.3832, Train Acc: 0.8359
Validation Acc: 0.6406
Epoch [14/100], Loss: 0.2582, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2773, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (2/10).
Epoch [16/100], Loss: 0.2800, Train Acc: 0.9023
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2356, Train Acc: 0.9062
Validation Acc: 0.6250
No improvement (4/10).
Epoch [18/100], Loss: 0.2336, Train Acc: 0.9102
Validation Acc: 0.6406
No improvement (5/10).
Epoch [19/100], Loss: 0.2368, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (6/10).
Epoch [20/100], Loss: 0.1823, Train Acc: 0.9180
Validation Acc: 0.6250
No improvement (7/10).
Epoch [21/100], Loss: 0.1864, Train Acc: 0.9414
Validation Acc: 0.6094
No improvement (8/10).
Epoch [22/100], Loss: 0.1665, Train Acc: 0.9297
Validation Acc: 0.5781
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7266
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6658, Train Acc: 0.8242
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6205, Train Acc: 0.8320
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5910, Train Acc: 0.8555
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5689, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (1/10).
Epoch [7/50], Loss: 0.5988, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [8/50], Loss: 0.5718, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.5766, Train Acc: 0.7852
Validation Acc: 0.5000
No improvement (2/10).
Epoch [10/50], Loss: 0.5879, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.5776, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (4/10).
Epoch [12/50], Loss: 0.5468, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [13/50], Loss: 0.5599, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (6/10).
Epoch [14/50], Loss: 0.5558, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (7/10).
Epoch [15/50], Loss: 0.5575, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (8/10).
Epoch [16/50], Loss: 0.5433, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5347, Train Acc: 0.8516
Validation Acc: 0.9062
No improvement (1/10).
Epoch [18/50], Loss: 0.5512, Train Acc: 0.8047
Validation Acc: 0.9219
Epoch [19/50], Loss: 0.5538, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (1/10).
Epoch [20/50], Loss: 0.5284, Train Acc: 0.8555
Validation Acc: 0.9219
No improvement (2/10).
Epoch [21/50], Loss: 0.5440, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [22/50], Loss: 0.5455, Train Acc: 0.8594
Validation Acc: 0.9219
No improvement (4/10).
Epoch [23/50], Loss: 0.5491, Train Acc: 0.8320
Validation Acc: 0.9219
No improvement (5/10).
Epoch [24/50], Loss: 0.5573, Train Acc: 0.8086
Validation Acc: 0.9219
No improvement (6/10).
Epoch [25/50], Loss: 0.5399, Train Acc: 0.8203
Validation Acc: 0.9219
No improvement (7/10).
Epoch [26/50], Loss: 0.5512, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [27/50], Loss: 0.5406, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (9/10).
Epoch [28/50], Loss: 0.5557, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5586
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6882, Train Acc: 0.6289
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6770, Train Acc: 0.6289
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/50], Loss: 0.6626, Train Acc: 0.6484
Validation Acc: 0.5781
Epoch [5/50], Loss: 0.6570, Train Acc: 0.6445
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6509, Train Acc: 0.6484
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.6359, Train Acc: 0.6914
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.6094, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (1/10).
Epoch [9/50], Loss: 0.6082, Train Acc: 0.7266
Validation Acc: 0.7344
No improvement (2/10).
Epoch [10/50], Loss: 0.5771, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (3/10).
Epoch [11/50], Loss: 0.5519, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (4/10).
Epoch [12/50], Loss: 0.5548, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (5/10).
Epoch [13/50], Loss: 0.5451, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (6/10).
Epoch [14/50], Loss: 0.5486, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5703, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (8/10).
Epoch [16/50], Loss: 0.5426, Train Acc: 0.8242
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5494, Train Acc: 0.8203
Validation Acc: 0.8281
Epoch [18/50], Loss: 0.5406, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (1/10).
Epoch [19/50], Loss: 0.5403, Train Acc: 0.8203
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5359, Train Acc: 0.8359
Validation Acc: 0.8281
No improvement (3/10).
Epoch [21/50], Loss: 0.5493, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (4/10).
Epoch [22/50], Loss: 0.5267, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (5/10).
Epoch [23/50], Loss: 0.5304, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (6/10).
Epoch [24/50], Loss: 0.5240, Train Acc: 0.8359
Validation Acc: 0.8125
No improvement (7/10).
Epoch [25/50], Loss: 0.5304, Train Acc: 0.8359
Validation Acc: 0.7969
No improvement (8/10).
Epoch [26/50], Loss: 0.5460, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (9/10).
Epoch [27/50], Loss: 0.5450, Train Acc: 0.8008
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.50s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.46s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.69s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.17s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.25s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.38s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.07s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.50s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.00s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.47s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.10s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.47s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.09s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.37s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.53s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020822692520704882, 'rho': 6357.948857973735, 'd': 0.7346480035065075, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.09s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.16s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [6:52:17<5:46:50, 1300.63s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3395_1200/steady_state_trajectories/m_traj_3395.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3201.36

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.53 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3108, Train Acc: 0.5078
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8136, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [3/100], Loss: 0.8564, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/100], Loss: 0.6433, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (2/10).
Epoch [5/100], Loss: 0.5629, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (3/10).
Epoch [6/100], Loss: 0.4901, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5450, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (5/10).
Epoch [8/100], Loss: 0.3447, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4040, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.4356, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (8/10).
Epoch [11/100], Loss: 0.3495, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3635, Train Acc: 0.8320
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8242
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5904, Train Acc: 0.8711
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5727, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8047
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (6/10).
Epoch [12/50], Loss: 0.5592, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (8/10).
Epoch [14/50], Loss: 0.5590, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6676, Train Acc: 0.6797
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6541, Train Acc: 0.6953
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6342, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.6208, Train Acc: 0.7227
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6100, Train Acc: 0.7344
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6015, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (1/10).
Epoch [9/50], Loss: 0.6372, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.6566, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (3/10).
Epoch [11/50], Loss: 0.6414, Train Acc: 0.6719
Validation Acc: 0.6562
No improvement (4/10).
Epoch [12/50], Loss: 0.6541, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [13/50], Loss: 0.6426, Train Acc: 0.6602
Validation Acc: 0.6562
No improvement (6/10).
Epoch [14/50], Loss: 0.6398, Train Acc: 0.6641
Validation Acc: 0.6562
No improvement (7/10).
Epoch [15/50], Loss: 0.6495, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6596, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (9/10).
Epoch [17/50], Loss: 0.6544, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.64 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6380.43068978461, 'sigma_b': 0.02074925579994778, 'd': 0.7346486353974884}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.97s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 3158.49

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.0755, Train Acc: 0.5508
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.9226, Train Acc: 0.6367
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7202, Train Acc: 0.7305
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.5406, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.4651, Train Acc: 0.7969
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4221, Train Acc: 0.8203
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.3745, Train Acc: 0.8242
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3680, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (7/10).
Epoch [9/100], Loss: 0.2662, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [10/100], Loss: 0.2951, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (9/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8828
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6859, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6648, Train Acc: 0.8164
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6188, Train Acc: 0.8438
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5878, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (1/10).
Epoch [6/50], Loss: 0.5778, Train Acc: 0.8359
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5920, Train Acc: 0.8047
Validation Acc: 0.5156
No improvement (1/10).
Epoch [8/50], Loss: 0.5770, Train Acc: 0.7734
Validation Acc: 0.5156
No improvement (2/10).
Epoch [9/50], Loss: 0.5527, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (3/10).
Epoch [10/50], Loss: 0.5597, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (4/10).
Epoch [11/50], Loss: 0.5753, Train Acc: 0.7578
Validation Acc: 0.8750
No improvement (5/10).
Epoch [12/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5727, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (8/10).
Epoch [15/50], Loss: 0.5556, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5431, Train Acc: 0.8125
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5447, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (1/10).
Epoch [18/50], Loss: 0.5488, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (2/10).
Epoch [19/50], Loss: 0.5454, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (3/10).
Epoch [20/50], Loss: 0.5334, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (4/10).
Epoch [21/50], Loss: 0.5405, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5499, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (7/10).
Epoch [24/50], Loss: 0.5511, Train Acc: 0.7969
Validation Acc: 0.8906
No improvement (8/10).
Epoch [25/50], Loss: 0.5412, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [26/50], Loss: 0.5427, Train Acc: 0.7891
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5430
Validation Acc: 0.4688
Epoch [2/50], Loss: 0.6886, Train Acc: 0.6172
Validation Acc: 0.4844
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6445
Validation Acc: 0.5156
Epoch [4/50], Loss: 0.6538, Train Acc: 0.6836
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.6298, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/50], Loss: 0.6279, Train Acc: 0.7344
Validation Acc: 0.7656
No improvement (2/10).
Epoch [7/50], Loss: 0.6331, Train Acc: 0.6875
Validation Acc: 0.7656
No improvement (3/10).
Epoch [8/50], Loss: 0.6104, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (4/10).
Epoch [9/50], Loss: 0.5889, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (5/10).
Epoch [10/50], Loss: 0.5888, Train Acc: 0.7539
Validation Acc: 0.7969
No improvement (6/10).
Epoch [11/50], Loss: 0.5970, Train Acc: 0.7461
Validation Acc: 0.7656
No improvement (7/10).
Epoch [12/50], Loss: 0.6039, Train Acc: 0.7305
Validation Acc: 0.6094
No improvement (8/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7734
Validation Acc: 0.7969
No improvement (9/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.68 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.00s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.53s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.28s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02074925579994778, 'rho': 6380.43068978461, 'd': 0.7346486353974884, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [7:15:21<5:31:27, 1325.82s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3407_1200/steady_state_trajectories/m_traj_3407.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.14
    - Variance: 3115.71

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4347, Train Acc: 0.4961
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9525, Train Acc: 0.6133
Validation Acc: 0.5781
No improvement (1/10).
Epoch [3/100], Loss: 0.8548, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.6965, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5658, Train Acc: 0.7734
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4791, Train Acc: 0.7734
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3757, Train Acc: 0.8555
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.4457, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3794, Train Acc: 0.8203
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.3533, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (3/10).
Epoch [12/100], Loss: 0.3828, Train Acc: 0.8359
Validation Acc: 0.6250
No improvement (4/10).
Epoch [13/100], Loss: 0.3075, Train Acc: 0.8789
Validation Acc: 0.6094
No improvement (5/10).
Epoch [14/100], Loss: 0.2837, Train Acc: 0.8633
Validation Acc: 0.6406
No improvement (6/10).
Epoch [15/100], Loss: 0.2768, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (7/10).
Epoch [16/100], Loss: 0.2844, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.2910, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (9/10).
Epoch [18/100], Loss: 0.2758, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6617, Train Acc: 0.8633
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6083, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5790, Train Acc: 0.8945
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5677, Train Acc: 0.8359
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5462, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5491, Train Acc: 0.8438
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5523, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5595, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [12/50], Loss: 0.5449, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5488, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5438, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6907, Train Acc: 0.5898
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6619, Train Acc: 0.6875
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6186, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5920, Train Acc: 0.8164
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5808, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5854, Train Acc: 0.7734
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5645, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5830, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (1/10).
Epoch [11/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5156
No improvement (2/10).
Epoch [12/50], Loss: 0.6692, Train Acc: 0.6250
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/50], Loss: 0.7016, Train Acc: 0.5625
Validation Acc: 0.5000
No improvement (4/10).
Epoch [14/50], Loss: 0.7065, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (5/10).
Epoch [15/50], Loss: 0.7008, Train Acc: 0.5508
Validation Acc: 0.5000
No improvement (6/10).
Epoch [16/50], Loss: 0.7052, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (7/10).
Epoch [17/50], Loss: 0.6965, Train Acc: 0.5430
Validation Acc: 0.5156
No improvement (8/10).
Epoch [18/50], Loss: 0.6867, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (9/10).
Epoch [19/50], Loss: 0.6792, Train Acc: 0.5586
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.57 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6402.912521585526, 'sigma_b': 0.020676335247858495, 'd': 0.7346492628581288}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.35s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.97s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.12
    - Variance: 3259.21

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.57 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.79 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2194, Train Acc: 0.5391
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.9078, Train Acc: 0.6445
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.8419, Train Acc: 0.6602
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.6175, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/100], Loss: 0.5355, Train Acc: 0.7617
Validation Acc: 0.7031
Epoch [6/100], Loss: 0.4776, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (1/10).
Epoch [7/100], Loss: 0.5173, Train Acc: 0.7227
Validation Acc: 0.7188
Epoch [8/100], Loss: 0.3650, Train Acc: 0.8398
Validation Acc: 0.7031
No improvement (1/10).
Epoch [9/100], Loss: 0.4634, Train Acc: 0.7930
Validation Acc: 0.7344
Epoch [10/100], Loss: 0.4408, Train Acc: 0.8125
Validation Acc: 0.7812
Epoch [11/100], Loss: 0.3912, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [12/100], Loss: 0.3057, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [13/100], Loss: 0.3201, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/100], Loss: 0.3172, Train Acc: 0.8711
Validation Acc: 0.7812
No improvement (2/10).
Epoch [15/100], Loss: 0.2986, Train Acc: 0.8594
Validation Acc: 0.7500
No improvement (3/10).
Epoch [16/100], Loss: 0.2723, Train Acc: 0.8555
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/100], Loss: 0.2858, Train Acc: 0.8828
Validation Acc: 0.7344
No improvement (5/10).
Epoch [18/100], Loss: 0.2507, Train Acc: 0.8867
Validation Acc: 0.7656
No improvement (6/10).
Epoch [19/100], Loss: 0.2486, Train Acc: 0.8906
Validation Acc: 0.7656
No improvement (7/10).
Epoch [20/100], Loss: 0.2394, Train Acc: 0.8867
Validation Acc: 0.7500
No improvement (8/10).
Epoch [21/100], Loss: 0.2176, Train Acc: 0.9102
Validation Acc: 0.7656
No improvement (9/10).
Epoch [22/100], Loss: 0.1727, Train Acc: 0.9336
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7266
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.7930
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6237, Train Acc: 0.8320
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5918, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5736, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (1/10).
Epoch [7/50], Loss: 0.5908, Train Acc: 0.8164
Validation Acc: 0.9375
Epoch [8/50], Loss: 0.5689, Train Acc: 0.8125
Validation Acc: 0.7969
No improvement (1/10).
Epoch [9/50], Loss: 0.5627, Train Acc: 0.8086
Validation Acc: 0.7031
No improvement (2/10).
Epoch [10/50], Loss: 0.5565, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (3/10).
Epoch [11/50], Loss: 0.5628, Train Acc: 0.7812
Validation Acc: 0.9375
No improvement (4/10).
Epoch [12/50], Loss: 0.5486, Train Acc: 0.7969
Validation Acc: 0.8906
No improvement (5/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.7539
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5467, Train Acc: 0.7812
Validation Acc: 0.9531
No improvement (1/10).
Epoch [15/50], Loss: 0.5426, Train Acc: 0.7773
Validation Acc: 0.8438
No improvement (2/10).
Epoch [16/50], Loss: 0.5307, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (3/10).
Epoch [17/50], Loss: 0.5219, Train Acc: 0.8242
Validation Acc: 0.9062
No improvement (4/10).
Epoch [18/50], Loss: 0.5469, Train Acc: 0.7852
Validation Acc: 0.9531
No improvement (5/10).
Epoch [19/50], Loss: 0.5186, Train Acc: 0.8047
Validation Acc: 0.9531
No improvement (6/10).
Epoch [20/50], Loss: 0.5086, Train Acc: 0.8320
Validation Acc: 0.9531
No improvement (7/10).
Epoch [21/50], Loss: 0.5231, Train Acc: 0.7773
Validation Acc: 0.9531
No improvement (8/10).
Epoch [22/50], Loss: 0.5185, Train Acc: 0.8008
Validation Acc: 0.9219
No improvement (9/10).
Epoch [23/50], Loss: 0.5143, Train Acc: 0.8398
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6899, Train Acc: 0.6055
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6799, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [4/50], Loss: 0.6666, Train Acc: 0.6445
Validation Acc: 0.6250
Epoch [5/50], Loss: 0.6555, Train Acc: 0.6758
Validation Acc: 0.7344
Epoch [6/50], Loss: 0.6334, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (1/10).
Epoch [7/50], Loss: 0.6344, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6488, Train Acc: 0.6562
Validation Acc: 0.6562
No improvement (3/10).
Epoch [9/50], Loss: 0.6567, Train Acc: 0.6289
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6438, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6400, Train Acc: 0.6406
Validation Acc: 0.6875
No improvement (6/10).
Epoch [12/50], Loss: 0.6313, Train Acc: 0.6562
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.6009, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (1/10).
Epoch [14/50], Loss: 0.5923, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6584, Train Acc: 0.5898
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6317, Train Acc: 0.6562
Validation Acc: 0.7344
No improvement (4/10).
Epoch [17/50], Loss: 0.6215, Train Acc: 0.6914
Validation Acc: 0.7188
No improvement (5/10).
Epoch [18/50], Loss: 0.6211, Train Acc: 0.6602
Validation Acc: 0.7656
No improvement (6/10).
Epoch [19/50], Loss: 0.6077, Train Acc: 0.7148
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.6129, Train Acc: 0.6797
Validation Acc: 0.7500
No improvement (8/10).
Epoch [21/50], Loss: 0.6259, Train Acc: 0.6445
Validation Acc: 0.7500
No improvement (9/10).
Epoch [22/50], Loss: 0.6191, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.40s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.49s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.11s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.17s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.40s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.07s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.43s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.13s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.18s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.49s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.10s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.39s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.10s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.41s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.40s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.11s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.38s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020676335247858495, 'rho': 6402.912521585526, 'd': 0.7346492628581288, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [7:38:34<5:14:02, 1345.90s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running Variance Ratio Simulations:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [8:22:10<6:14:12, 1727.13s/it]<lambdifygenerated-570623>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-570623>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3419_1200/steady_state_trajectories/m_traj_3419.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.26
    - Variance: 3281.05

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3360, Train Acc: 0.5156
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.7043, Train Acc: 0.6836
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6308, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6056, Train Acc: 0.7344
Validation Acc: 0.6562
Epoch [6/100], Loss: 0.5526, Train Acc: 0.7305
Validation Acc: 0.6719
Epoch [7/100], Loss: 0.4788, Train Acc: 0.7969
Validation Acc: 0.6719
No improvement (1/10).
Epoch [8/100], Loss: 0.3968, Train Acc: 0.8320
Validation Acc: 0.6250
No improvement (2/10).
Epoch [9/100], Loss: 0.4035, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (3/10).
Epoch [10/100], Loss: 0.4096, Train Acc: 0.8125
Validation Acc: 0.6719
No improvement (4/10).
Epoch [11/100], Loss: 0.3287, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3205, Train Acc: 0.8711
Validation Acc: 0.6094
No improvement (6/10).
Epoch [13/100], Loss: 0.3504, Train Acc: 0.8555
Validation Acc: 0.6562
No improvement (7/10).
Epoch [14/100], Loss: 0.3203, Train Acc: 0.8555
Validation Acc: 0.6719
No improvement (8/10).
Epoch [15/100], Loss: 0.2895, Train Acc: 0.8594
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/100], Loss: 0.2880, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6645, Train Acc: 0.8477
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6103, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5803, Train Acc: 0.8672
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5781, Train Acc: 0.8281
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.5737, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.5557, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (2/10).
Epoch [9/50], Loss: 0.5511, Train Acc: 0.8516
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5428, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5527, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (2/10).
Epoch [12/50], Loss: 0.5325, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [13/50], Loss: 0.5409, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [14/50], Loss: 0.5425, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [15/50], Loss: 0.5249, Train Acc: 0.8867
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5223, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5092, Train Acc: 0.9023
Validation Acc: 0.8594
No improvement (8/10).
Epoch [18/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (9/10).
Epoch [19/50], Loss: 0.5203, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6879, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6562
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6525, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6272, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (2/10).
Epoch [6/50], Loss: 0.6132, Train Acc: 0.7617
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/50], Loss: 0.6042, Train Acc: 0.7500
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.5853, Train Acc: 0.7734
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6048, Train Acc: 0.7188
Validation Acc: 0.5781
No improvement (2/10).
Epoch [10/50], Loss: 0.6143, Train Acc: 0.6992
Validation Acc: 0.6094
No improvement (3/10).
Epoch [11/50], Loss: 0.5862, Train Acc: 0.7500
Validation Acc: 0.6406
No improvement (4/10).
Epoch [12/50], Loss: 0.5795, Train Acc: 0.7656
Validation Acc: 0.6250
No improvement (5/10).
Epoch [13/50], Loss: 0.6036, Train Acc: 0.7188
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6180, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6282, Train Acc: 0.6719
Validation Acc: 0.5625
No improvement (8/10).
Epoch [16/50], Loss: 0.6256, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6308, Train Acc: 0.6719
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] âŒ No suitable solution found.
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138044316, 'sigma_b': 0.060145439998485865, 'd': 0.7827636158617431}
âš ï¸ Skipping simulation for ratio 2.8600 due to stress failure.

Attempt 1/10
Attempt 2/10
Attempt 3/10
[STRESS] âœ… Found: {'rho': 6447.8761737851955, 'sigma_b': 0.020532021035931845, 'd': 0.7346505046730973}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138069436, 'sigma_b': 0.06014543999850966, 'd': 0.7827636158617518}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.11
    - Variance: 3507.89

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.66
    - Variance: 1104.62
=== SVM (RBF Kernel) Classification Accuracy: 0.60 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.79 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2134, Train Acc: 0.5234
Validation Acc: 0.4688
Epoch [2/100], Loss: 0.8359, Train Acc: 0.6953
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.8094, Train Acc: 0.6719
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6119, Train Acc: 0.7109
Validation Acc: 0.5938
Epoch [5/100], Loss: 0.4846, Train Acc: 0.7695
Validation Acc: 0.6250
Epoch [6/100], Loss: 0.4765, Train Acc: 0.7656
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/100], Loss: 0.4613, Train Acc: 0.7773
Validation Acc: 0.5781
No improvement (2/10).
Epoch [8/100], Loss: 0.3645, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (3/10).
Epoch [9/100], Loss: 0.4006, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [10/100], Loss: 0.3477, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/100], Loss: 0.3329, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.6094
No improvement (7/10).
Epoch [13/100], Loss: 0.2656, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (8/10).
Epoch [14/100], Loss: 0.2909, Train Acc: 0.8672
Validation Acc: 0.5781
No improvement (9/10).
Epoch [15/100], Loss: 0.2254, Train Acc: 0.8867
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6859, Train Acc: 0.7266
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6647, Train Acc: 0.8242
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6160, Train Acc: 0.8359
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5870, Train Acc: 0.8594
Validation Acc: 0.8281
No improvement (1/10).
Epoch [6/50], Loss: 0.5737, Train Acc: 0.8359
Validation Acc: 0.9375
Epoch [7/50], Loss: 0.5733, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (1/10).
Epoch [8/50], Loss: 0.5597, Train Acc: 0.8125
Validation Acc: 0.9688
Epoch [9/50], Loss: 0.5642, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (1/10).
Epoch [10/50], Loss: 0.5572, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (2/10).
Epoch [11/50], Loss: 0.5583, Train Acc: 0.8008
Validation Acc: 0.9219
No improvement (3/10).
Epoch [12/50], Loss: 0.5416, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (4/10).
Epoch [13/50], Loss: 0.5629, Train Acc: 0.7695
Validation Acc: 0.9062
No improvement (5/10).
Epoch [14/50], Loss: 0.5498, Train Acc: 0.7773
Validation Acc: 0.9688
No improvement (6/10).
Epoch [15/50], Loss: 0.5548, Train Acc: 0.7969
Validation Acc: 0.9688
No improvement (7/10).
Epoch [16/50], Loss: 0.5427, Train Acc: 0.8008
Validation Acc: 0.9688
No improvement (8/10).
Epoch [17/50], Loss: 0.5332, Train Acc: 0.8320
Validation Acc: 0.9688
No improvement (9/10).
Epoch [18/50], Loss: 0.5388, Train Acc: 0.7930
Validation Acc: 0.9688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5547
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6856, Train Acc: 0.6680
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6679, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6431, Train Acc: 0.7383
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6206, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/50], Loss: 0.6615, Train Acc: 0.6406
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/50], Loss: 0.6191, Train Acc: 0.7148
Validation Acc: 0.6719
No improvement (4/10).
Epoch [8/50], Loss: 0.6068, Train Acc: 0.7383
Validation Acc: 0.7969
Epoch [9/50], Loss: 0.5875, Train Acc: 0.7656
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5989, Train Acc: 0.7344
Validation Acc: 0.7812
No improvement (1/10).
Epoch [11/50], Loss: 0.5962, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (2/10).
Epoch [12/50], Loss: 0.5982, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5852, Train Acc: 0.7422
Validation Acc: 0.8281
No improvement (4/10).
Epoch [14/50], Loss: 0.5736, Train Acc: 0.7539
Validation Acc: 0.8438
Epoch [15/50], Loss: 0.5677, Train Acc: 0.7500
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5489, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5581, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [18/50], Loss: 0.5509, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (4/10).
Epoch [19/50], Loss: 0.5468, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (5/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (6/10).
Epoch [21/50], Loss: 0.5470, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (7/10).
Epoch [22/50], Loss: 0.5448, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (8/10).
Epoch [23/50], Loss: 0.5431, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [24/50], Loss: 0.5399, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.37s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.96s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.41s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.13s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.95s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.99s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.03s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.04s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.39s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.00s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020532021035931845, 'rho': 6447.8761737851955, 'd': 0.7346505046730973, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.09s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [8:34:29<4:46:07, 1430.63s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running Variance Ratio Simulations:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [9:18:04<5:27:26, 1786.06s/it]Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999850966, 'rho': 1179.1338138069436, 'd': 0.7827636158617518, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3443_1200/steady_state_trajectories/m_traj_3443.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.04
    - Variance: 3497.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3949, Train Acc: 0.4688
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8667, Train Acc: 0.6211
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.7756, Train Acc: 0.6836
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.7653, Train Acc: 0.6562
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/100], Loss: 0.6202, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4836, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.5003, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/100], Loss: 0.4526, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (5/10).
Epoch [9/100], Loss: 0.4226, Train Acc: 0.8047
Validation Acc: 0.6875
Epoch [10/100], Loss: 0.4309, Train Acc: 0.7852
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.3700, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (2/10).
Epoch [12/100], Loss: 0.4421, Train Acc: 0.7930
Validation Acc: 0.6250
No improvement (3/10).
Epoch [13/100], Loss: 0.3188, Train Acc: 0.8633
Validation Acc: 0.6250
No improvement (4/10).
Epoch [14/100], Loss: 0.3652, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (5/10).
Epoch [15/100], Loss: 0.3278, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (6/10).
Epoch [16/100], Loss: 0.2961, Train Acc: 0.8516
Validation Acc: 0.6406
No improvement (7/10).
Epoch [17/100], Loss: 0.2204, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.2346, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/100], Loss: 0.2804, Train Acc: 0.8672
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.71 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6046, Train Acc: 0.8945
Validation Acc: 0.8125
Epoch [5/50], Loss: 0.5787, Train Acc: 0.9023
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5560, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.5675, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5496, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (3/10).
Epoch [9/50], Loss: 0.5530, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5355, Train Acc: 0.8359
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.5383, Train Acc: 0.8359
Validation Acc: 0.8906
Epoch [12/50], Loss: 0.5248, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5284, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (2/10).
Epoch [14/50], Loss: 0.5344, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5254, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (4/10).
Epoch [16/50], Loss: 0.5115, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (5/10).
Epoch [17/50], Loss: 0.5013, Train Acc: 0.8906
Validation Acc: 0.8438
No improvement (6/10).
Epoch [18/50], Loss: 0.5201, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (7/10).
Epoch [19/50], Loss: 0.5147, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (8/10).
Epoch [20/50], Loss: 0.5194, Train Acc: 0.8516
Validation Acc: 0.8438
No improvement (9/10).
Epoch [21/50], Loss: 0.5176, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6250
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6680
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6497, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6162, Train Acc: 0.8047
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6151, Train Acc: 0.7617
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.6229, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.6219, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (3/10).
Epoch [9/50], Loss: 0.6100, Train Acc: 0.7266
Validation Acc: 0.6562
No improvement (4/10).
Epoch [10/50], Loss: 0.6102, Train Acc: 0.7148
Validation Acc: 0.6562
No improvement (5/10).
Epoch [11/50], Loss: 0.6045, Train Acc: 0.7422
Validation Acc: 0.6719
No improvement (6/10).
Epoch [12/50], Loss: 0.5925, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (7/10).
Epoch [13/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (8/10).
Epoch [14/50], Loss: 0.5809, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (9/10).
Epoch [15/50], Loss: 0.5729, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] âŒ No suitable solution found.
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138044316, 'sigma_b': 0.060145439998485865, 'd': 0.7827636158617431}
âš ï¸ Skipping simulation for ratio 2.8800 due to stress failure.

Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
[STRESS] âœ… Found: {'rho': 6492.839846238991, 'sigma_b': 0.02038970739353482, 'd': 0.7346517293162085}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138053677, 'sigma_b': 0.06014543999849313, 'd': 0.7827636158617437}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.52s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.18s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.36
    - Variance: 3257.81

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.68
    - Variance: 1113.87
=== SVM (RBF Kernel) Classification Accuracy: 0.65 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3973, Train Acc: 0.4844
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9225, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7243, Train Acc: 0.6562
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.6713, Train Acc: 0.6953
Validation Acc: 0.6250
Epoch [5/100], Loss: 0.6555, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (1/10).
Epoch [6/100], Loss: 0.5351, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [7/100], Loss: 0.4764, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (3/10).
Epoch [8/100], Loss: 0.3976, Train Acc: 0.7969
Validation Acc: 0.5938
No improvement (4/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.8242
Validation Acc: 0.6719
Epoch [10/100], Loss: 0.4852, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (1/10).
Epoch [11/100], Loss: 0.3668, Train Acc: 0.8477
Validation Acc: 0.6875
Epoch [12/100], Loss: 0.3398, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (1/10).
Epoch [13/100], Loss: 0.3102, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (2/10).
Epoch [14/100], Loss: 0.3021, Train Acc: 0.8633
Validation Acc: 0.6719
No improvement (3/10).
Epoch [15/100], Loss: 0.2792, Train Acc: 0.8945
Validation Acc: 0.6250
No improvement (4/10).
Epoch [16/100], Loss: 0.3095, Train Acc: 0.8789
Validation Acc: 0.6562
No improvement (5/10).
Epoch [17/100], Loss: 0.2559, Train Acc: 0.8906
Validation Acc: 0.6875
No improvement (6/10).
Epoch [18/100], Loss: 0.2870, Train Acc: 0.8867
Validation Acc: 0.6562
No improvement (7/10).
Epoch [19/100], Loss: 0.2871, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (8/10).
Epoch [20/100], Loss: 0.2426, Train Acc: 0.8867
Validation Acc: 0.6875
No improvement (9/10).
Epoch [21/100], Loss: 0.2528, Train Acc: 0.8789
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6758
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8281
Validation Acc: 0.8594
Epoch [4/50], Loss: 0.6187, Train Acc: 0.8398
Validation Acc: 0.8438
No improvement (1/10).
Epoch [5/50], Loss: 0.5824, Train Acc: 0.8867
Validation Acc: 0.7500
No improvement (2/10).
Epoch [6/50], Loss: 0.5667, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.5801, Train Acc: 0.7891
Validation Acc: 0.7188
No improvement (4/10).
Epoch [8/50], Loss: 0.5677, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5679, Train Acc: 0.7930
Validation Acc: 0.5469
No improvement (6/10).
Epoch [10/50], Loss: 0.5568, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (7/10).
Epoch [11/50], Loss: 0.5552, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5496, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (1/10).
Epoch [13/50], Loss: 0.5536, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (2/10).
Epoch [14/50], Loss: 0.5632, Train Acc: 0.7656
Validation Acc: 0.9062
Epoch [15/50], Loss: 0.5538, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (1/10).
Epoch [16/50], Loss: 0.5370, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (2/10).
Epoch [17/50], Loss: 0.5378, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (3/10).
Epoch [18/50], Loss: 0.5508, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [19/50], Loss: 0.5432, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (5/10).
Epoch [20/50], Loss: 0.5322, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (6/10).
Epoch [21/50], Loss: 0.5446, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (7/10).
Epoch [22/50], Loss: 0.5307, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (8/10).
Epoch [23/50], Loss: 0.5236, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (9/10).
Epoch [24/50], Loss: 0.5405, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6934, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6914, Train Acc: 0.6055
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6823, Train Acc: 0.6367
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/50], Loss: 0.6644, Train Acc: 0.6641
Validation Acc: 0.6562
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7344
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6293, Train Acc: 0.7383
Validation Acc: 0.7344
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7500
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.6241, Train Acc: 0.6992
Validation Acc: 0.5469
No improvement (2/10).
Epoch [9/50], Loss: 0.6236, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (3/10).
Epoch [10/50], Loss: 0.6214, Train Acc: 0.7031
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/50], Loss: 0.6182, Train Acc: 0.7109
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/50], Loss: 0.6120, Train Acc: 0.7188
Validation Acc: 0.6406
No improvement (6/10).
Epoch [13/50], Loss: 0.6065, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (7/10).
Epoch [14/50], Loss: 0.5991, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (8/10).
Epoch [15/50], Loss: 0.6074, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (9/10).
Epoch [16/50], Loss: 0.5954, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.72s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.21s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.28s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.61s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.11s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.18s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.01s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.33s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.43s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.64s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.13s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.21s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.65s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.17s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.24s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.75s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.23s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.31s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.80s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.29s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.36s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.72s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.17s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.25s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.79s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.02038970739353482, 'rho': 6492.839846238991, 'd': 0.7346517293162085, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.27s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.35s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [9:45:53<4:51:49, 1750.94s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running Variance Ratio Simulations:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [10:28:52<4:59:53, 1999.29s/it]Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3467_1200/steady_state_trajectories/m_traj_3467.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.98
    - Variance: 3477.91

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3975, Train Acc: 0.4648
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8898, Train Acc: 0.6328
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7159, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.6311, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.4981, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [6/100], Loss: 0.4680, Train Acc: 0.8164
Validation Acc: 0.4219
No improvement (4/10).
Epoch [7/100], Loss: 0.4283, Train Acc: 0.8203
Validation Acc: 0.4375
No improvement (5/10).
Epoch [8/100], Loss: 0.3522, Train Acc: 0.8320
Validation Acc: 0.4844
No improvement (6/10).
Epoch [9/100], Loss: 0.3831, Train Acc: 0.8125
Validation Acc: 0.4688
No improvement (7/10).
Epoch [10/100], Loss: 0.4143, Train Acc: 0.8203
Validation Acc: 0.5156
No improvement (8/10).
Epoch [11/100], Loss: 0.2919, Train Acc: 0.8867
Validation Acc: 0.5312
No improvement (9/10).
Epoch [12/100], Loss: 0.2563, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8398
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6120, Train Acc: 0.8633
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5797, Train Acc: 0.8945
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5721, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (1/10).
Epoch [7/50], Loss: 0.5788, Train Acc: 0.8047
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.8164
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5589, Train Acc: 0.8359
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.5535, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5623, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5497, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (8/10).
Epoch [14/50], Loss: 0.5531, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (9/10).
Epoch [15/50], Loss: 0.5408, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6875, Train Acc: 0.6641
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6728, Train Acc: 0.6719
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6758
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6482, Train Acc: 0.6836
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6326, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6198, Train Acc: 0.7227
Validation Acc: 0.7344
Epoch [8/50], Loss: 0.6229, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (1/10).
Epoch [9/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.6875
No improvement (2/10).
Epoch [10/50], Loss: 0.6490, Train Acc: 0.6328
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/50], Loss: 0.6159, Train Acc: 0.6953
Validation Acc: 0.7344
No improvement (4/10).
Epoch [12/50], Loss: 0.5812, Train Acc: 0.7617
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5884, Train Acc: 0.7383
Validation Acc: 0.7500
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.6095, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (3/10).
Epoch [16/50], Loss: 0.6144, Train Acc: 0.7188
Validation Acc: 0.6875
No improvement (4/10).
Epoch [17/50], Loss: 0.6125, Train Acc: 0.7070
Validation Acc: 0.7031
No improvement (5/10).
Epoch [18/50], Loss: 0.6161, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (6/10).
Epoch [19/50], Loss: 0.6108, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (7/10).
Epoch [20/50], Loss: 0.6143, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (8/10).
Epoch [21/50], Loss: 0.6128, Train Acc: 0.7148
Validation Acc: 0.7031
No improvement (9/10).
Epoch [22/50], Loss: 0.6011, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] âŒ No suitable solution found.
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138044316, 'sigma_b': 0.060145439998485865, 'd': 0.7827636158617431}
âš ï¸ Skipping simulation for ratio 2.9000 due to stress failure.

Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
[STRESS] âœ… Found: {'rho': 6537.803506862811, 'sigma_b': 0.020249353015011615, 'd': 0.734652937140171}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138053677, 'sigma_b': 0.06014543999849313, 'd': 0.7827636158617437}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.41s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.07s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.76
    - Variance: 3186.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.68
    - Variance: 1113.87
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1380, Train Acc: 0.5352
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8485, Train Acc: 0.6445
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.6140, Train Acc: 0.7344
Validation Acc: 0.5625
No improvement (2/10).
Epoch [4/100], Loss: 0.5352, Train Acc: 0.7617
Validation Acc: 0.5781
No improvement (3/10).
Epoch [5/100], Loss: 0.5687, Train Acc: 0.7695
Validation Acc: 0.5469
No improvement (4/10).
Epoch [6/100], Loss: 0.3569, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (5/10).
Epoch [7/100], Loss: 0.4115, Train Acc: 0.8477
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.6094
Epoch [9/100], Loss: 0.3544, Train Acc: 0.8281
Validation Acc: 0.6562
Epoch [10/100], Loss: 0.3547, Train Acc: 0.8242
Validation Acc: 0.6562
No improvement (1/10).
Epoch [11/100], Loss: 0.2883, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (2/10).
Epoch [12/100], Loss: 0.2903, Train Acc: 0.8711
Validation Acc: 0.6406
No improvement (3/10).
Epoch [13/100], Loss: 0.2692, Train Acc: 0.8750
Validation Acc: 0.6562
No improvement (4/10).
Epoch [14/100], Loss: 0.1897, Train Acc: 0.9375
Validation Acc: 0.6094
No improvement (5/10).
Epoch [15/100], Loss: 0.1853, Train Acc: 0.9297
Validation Acc: 0.6250
No improvement (6/10).
Epoch [16/100], Loss: 0.2703, Train Acc: 0.9102
Validation Acc: 0.6094
No improvement (7/10).
Epoch [17/100], Loss: 0.2180, Train Acc: 0.9180
Validation Acc: 0.6406
No improvement (8/10).
Epoch [18/100], Loss: 0.1783, Train Acc: 0.9297
Validation Acc: 0.6250
No improvement (9/10).
Epoch [19/100], Loss: 0.2137, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.68 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6602
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6691, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [4/50], Loss: 0.6210, Train Acc: 0.8398
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5913, Train Acc: 0.8438
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5799, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (1/10).
Epoch [7/50], Loss: 0.5865, Train Acc: 0.7539
Validation Acc: 0.8281
No improvement (2/10).
Epoch [8/50], Loss: 0.5544, Train Acc: 0.8164
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5651, Train Acc: 0.8125
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5555, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [12/50], Loss: 0.5412, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (3/10).
Epoch [13/50], Loss: 0.5491, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (4/10).
Epoch [14/50], Loss: 0.5386, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5259, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (6/10).
Epoch [16/50], Loss: 0.5118, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5064, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (8/10).
Epoch [18/50], Loss: 0.5355, Train Acc: 0.8164
Validation Acc: 0.9062
Epoch [19/50], Loss: 0.5172, Train Acc: 0.8633
Validation Acc: 0.8750
No improvement (1/10).
Epoch [20/50], Loss: 0.5158, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (2/10).
Epoch [21/50], Loss: 0.5251, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (3/10).
Epoch [22/50], Loss: 0.5097, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (4/10).
Epoch [23/50], Loss: 0.5134, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (5/10).
Epoch [24/50], Loss: 0.5198, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (6/10).
Epoch [25/50], Loss: 0.5118, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (7/10).
Epoch [26/50], Loss: 0.5128, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (8/10).
Epoch [27/50], Loss: 0.5053, Train Acc: 0.8594
Validation Acc: 0.8594
No improvement (9/10).
Epoch [28/50], Loss: 0.5196, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6133
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6641
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/50], Loss: 0.6522, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/50], Loss: 0.6327, Train Acc: 0.7422
Validation Acc: 0.5938
No improvement (3/10).
Epoch [6/50], Loss: 0.6131, Train Acc: 0.7617
Validation Acc: 0.6562
Epoch [7/50], Loss: 0.5925, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (1/10).
Epoch [8/50], Loss: 0.5888, Train Acc: 0.7656
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.6157, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [10/50], Loss: 0.5854, Train Acc: 0.7578
Validation Acc: 0.7188
Epoch [11/50], Loss: 0.6065, Train Acc: 0.7383
Validation Acc: 0.7969
Epoch [12/50], Loss: 0.5999, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7422
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5944, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (2/10).
Epoch [15/50], Loss: 0.7451, Train Acc: 0.5195
Validation Acc: 0.5000
No improvement (3/10).
Epoch [16/50], Loss: 0.7475, Train Acc: 0.5039
Validation Acc: 0.5156
No improvement (4/10).
Epoch [17/50], Loss: 0.7373, Train Acc: 0.5156
Validation Acc: 0.5312
No improvement (5/10).
Epoch [18/50], Loss: 0.7230, Train Acc: 0.5234
Validation Acc: 0.5625
No improvement (6/10).
Epoch [19/50], Loss: 0.7041, Train Acc: 0.5391
Validation Acc: 0.5781
No improvement (7/10).
Epoch [20/50], Loss: 0.6835, Train Acc: 0.5469
Validation Acc: 0.6250
No improvement (8/10).
Epoch [21/50], Loss: 0.6670, Train Acc: 0.6094
Validation Acc: 0.6719
No improvement (9/10).
Epoch [22/50], Loss: 0.6611, Train Acc: 0.6367
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.62 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.08s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.00s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.12s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.15s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.18s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.96s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  6.00s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.16s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.00s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.98s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.14s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020249353015011615, 'rho': 6537.803506862811, 'd': 0.734652937140171, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.02s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.05s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [10:56:27<4:12:48, 1896.06s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-762027>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-762027>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849313, 'rho': 1179.1338138053677, 'd': 0.7827636158617437, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3491_1200/steady_state_trajectories/m_traj_3491.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.09
    - Variance: 3047.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4790, Train Acc: 0.5078
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8925, Train Acc: 0.6836
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7238, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [4/100], Loss: 0.6564, Train Acc: 0.7188
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5283, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4967, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (3/10).
Epoch [7/100], Loss: 0.4723, Train Acc: 0.7891
Validation Acc: 0.5625
No improvement (4/10).
Epoch [8/100], Loss: 0.3904, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3507, Train Acc: 0.8516
Validation Acc: 0.5156
No improvement (6/10).
Epoch [10/100], Loss: 0.3303, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (7/10).
Epoch [11/100], Loss: 0.2550, Train Acc: 0.8867
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3354, Train Acc: 0.8594
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2795, Train Acc: 0.8906
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7344
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6610, Train Acc: 0.8477
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6062, Train Acc: 0.8789
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5789, Train Acc: 0.8906
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (2/10).
Epoch [7/50], Loss: 0.5799, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (3/10).
Epoch [8/50], Loss: 0.5655, Train Acc: 0.8008
Validation Acc: 0.6562
No improvement (4/10).
Epoch [9/50], Loss: 0.5579, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [10/50], Loss: 0.5497, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (6/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [12/50], Loss: 0.5432, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (8/10).
Epoch [13/50], Loss: 0.5503, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (9/10).
Epoch [14/50], Loss: 0.5456, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6749, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6797
Validation Acc: 0.4531
No improvement (1/10).
Epoch [5/50], Loss: 0.6362, Train Acc: 0.7422
Validation Acc: 0.4844
No improvement (2/10).
Epoch [6/50], Loss: 0.6390, Train Acc: 0.7070
Validation Acc: 0.4844
No improvement (3/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.6102, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (5/10).
Epoch [9/50], Loss: 0.5928, Train Acc: 0.7617
Validation Acc: 0.6875
No improvement (6/10).
Epoch [10/50], Loss: 0.5882, Train Acc: 0.7500
Validation Acc: 0.7344
Epoch [11/50], Loss: 0.5869, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5837, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/50], Loss: 0.5904, Train Acc: 0.7578
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5784, Train Acc: 0.7656
Validation Acc: 0.7500
Epoch [16/50], Loss: 0.5858, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (1/10).
Epoch [17/50], Loss: 0.5820, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (2/10).
Epoch [18/50], Loss: 0.5809, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (3/10).
Epoch [19/50], Loss: 0.5767, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (4/10).
Epoch [20/50], Loss: 0.5725, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (5/10).
Epoch [21/50], Loss: 0.5826, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (6/10).
Epoch [22/50], Loss: 0.5633, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (7/10).
Epoch [23/50], Loss: 0.5529, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (8/10).
Epoch [24/50], Loss: 0.5601, Train Acc: 0.7852
Validation Acc: 0.6875
No improvement (9/10).
Epoch [25/50], Loss: 0.5625, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6560.285336804428, 'sigma_b': 0.020179897948226215, 'd': 0.7346535348530091}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.65
    - Variance: 3612.00

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.1628, Train Acc: 0.5625
Validation Acc: 0.4844
Epoch [2/100], Loss: 0.9354, Train Acc: 0.6445
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.8467, Train Acc: 0.6641
Validation Acc: 0.4688
No improvement (1/10).
Epoch [4/100], Loss: 0.6421, Train Acc: 0.7305
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5757, Train Acc: 0.7812
Validation Acc: 0.5469
Epoch [6/100], Loss: 0.4132, Train Acc: 0.8242
Validation Acc: 0.5625
Epoch [7/100], Loss: 0.4973, Train Acc: 0.7695
Validation Acc: 0.5469
No improvement (1/10).
Epoch [8/100], Loss: 0.3866, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (2/10).
Epoch [9/100], Loss: 0.3834, Train Acc: 0.8789
Validation Acc: 0.5156
No improvement (3/10).
Epoch [10/100], Loss: 0.3758, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (4/10).
Epoch [11/100], Loss: 0.2621, Train Acc: 0.8828
Validation Acc: 0.5781
Epoch [12/100], Loss: 0.3309, Train Acc: 0.8594
Validation Acc: 0.5938
Epoch [13/100], Loss: 0.2841, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (1/10).
Epoch [14/100], Loss: 0.2810, Train Acc: 0.8750
Validation Acc: 0.5469
No improvement (2/10).
Epoch [15/100], Loss: 0.2667, Train Acc: 0.8906
Validation Acc: 0.5000
No improvement (3/10).
Epoch [16/100], Loss: 0.2416, Train Acc: 0.8984
Validation Acc: 0.5312
No improvement (4/10).
Epoch [17/100], Loss: 0.2523, Train Acc: 0.9023
Validation Acc: 0.5000
No improvement (5/10).
Epoch [18/100], Loss: 0.2078, Train Acc: 0.9297
Validation Acc: 0.5156
No improvement (6/10).
Epoch [19/100], Loss: 0.2688, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (7/10).
Epoch [20/100], Loss: 0.1896, Train Acc: 0.9180
Validation Acc: 0.5781
No improvement (8/10).
Epoch [21/100], Loss: 0.2125, Train Acc: 0.9023
Validation Acc: 0.6250
Epoch [22/100], Loss: 0.1916, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (1/10).
Epoch [23/100], Loss: 0.2007, Train Acc: 0.9102
Validation Acc: 0.5469
No improvement (2/10).
Epoch [24/100], Loss: 0.1422, Train Acc: 0.9492
Validation Acc: 0.5938
No improvement (3/10).
Epoch [25/100], Loss: 0.1957, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [26/100], Loss: 0.1248, Train Acc: 0.9375
Validation Acc: 0.5625
No improvement (5/10).
Epoch [27/100], Loss: 0.1677, Train Acc: 0.9336
Validation Acc: 0.5781
No improvement (6/10).
Epoch [28/100], Loss: 0.1591, Train Acc: 0.9453
Validation Acc: 0.5781
No improvement (7/10).
Epoch [29/100], Loss: 0.1452, Train Acc: 0.9453
Validation Acc: 0.6094
No improvement (8/10).
Epoch [30/100], Loss: 0.1061, Train Acc: 0.9688
Validation Acc: 0.6406
Epoch [31/100], Loss: 0.1531, Train Acc: 0.9531
Validation Acc: 0.6719
Epoch [32/100], Loss: 0.1069, Train Acc: 0.9648
Validation Acc: 0.6406
No improvement (1/10).
Epoch [33/100], Loss: 0.1278, Train Acc: 0.9531
Validation Acc: 0.5938
No improvement (2/10).
Epoch [34/100], Loss: 0.1078, Train Acc: 0.9531
Validation Acc: 0.6562
No improvement (3/10).
Epoch [35/100], Loss: 0.1133, Train Acc: 0.9570
Validation Acc: 0.6250
No improvement (4/10).
Epoch [36/100], Loss: 0.0933, Train Acc: 0.9688
Validation Acc: 0.5938
No improvement (5/10).
Epoch [37/100], Loss: 0.0734, Train Acc: 0.9766
Validation Acc: 0.5781
No improvement (6/10).
Epoch [38/100], Loss: 0.0975, Train Acc: 0.9727
Validation Acc: 0.5938
No improvement (7/10).
Epoch [39/100], Loss: 0.0964, Train Acc: 0.9570
Validation Acc: 0.5469
No improvement (8/10).
Epoch [40/100], Loss: 0.0963, Train Acc: 0.9727
Validation Acc: 0.5625
No improvement (9/10).
Epoch [41/100], Loss: 0.0979, Train Acc: 0.9648
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8281
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6207, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [5/50], Loss: 0.5957, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.5752, Train Acc: 0.8477
Validation Acc: 0.8281
Epoch [7/50], Loss: 0.5961, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5721, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5764, Train Acc: 0.7656
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5637, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5740, Train Acc: 0.7617
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5518, Train Acc: 0.7969
Validation Acc: 0.8906
No improvement (3/10).
Epoch [13/50], Loss: 0.5708, Train Acc: 0.7656
Validation Acc: 0.8906
No improvement (4/10).
Epoch [14/50], Loss: 0.5521, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (5/10).
Epoch [15/50], Loss: 0.5504, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7773
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5391, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (1/10).
Epoch [19/50], Loss: 0.5443, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [20/50], Loss: 0.5263, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (3/10).
Epoch [21/50], Loss: 0.5323, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (4/10).
Epoch [22/50], Loss: 0.5435, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (5/10).
Epoch [23/50], Loss: 0.5398, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [24/50], Loss: 0.5425, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (7/10).
Epoch [25/50], Loss: 0.5390, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (8/10).
Epoch [26/50], Loss: 0.5296, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (9/10).
Epoch [27/50], Loss: 0.5346, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5586
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6445
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6756, Train Acc: 0.6445
Validation Acc: 0.5781
Epoch [4/50], Loss: 0.6593, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [5/50], Loss: 0.6416, Train Acc: 0.7109
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.6211, Train Acc: 0.7422
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.6066, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (1/10).
Epoch [8/50], Loss: 0.6146, Train Acc: 0.7188
Validation Acc: 0.7656
No improvement (2/10).
Epoch [9/50], Loss: 0.6135, Train Acc: 0.7188
Validation Acc: 0.7656
No improvement (3/10).
Epoch [10/50], Loss: 0.6051, Train Acc: 0.7383
Validation Acc: 0.7656
No improvement (4/10).
Epoch [11/50], Loss: 0.5942, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5854, Train Acc: 0.7656
Validation Acc: 0.8438
No improvement (6/10).
Epoch [13/50], Loss: 0.5887, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (7/10).
Epoch [14/50], Loss: 0.5805, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (8/10).
Epoch [15/50], Loss: 0.5885, Train Acc: 0.7422
Validation Acc: 0.7812
No improvement (9/10).
Epoch [16/50], Loss: 0.5812, Train Acc: 0.7539
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.45s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.33s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.34s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  6.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.17s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.75s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.40s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.49s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.35s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020179897948226215, 'rho': 6560.285336804428, 'd': 0.7346535348530091, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [11:20:04<3:24:24, 1752.14s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3503_1200/steady_state_trajectories/m_traj_3503.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.55
    - Variance: 4103.55

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.78 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3048, Train Acc: 0.5039
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.8320, Train Acc: 0.6211
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7235, Train Acc: 0.7188
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6788, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (2/10).
Epoch [5/100], Loss: 0.5695, Train Acc: 0.7656
Validation Acc: 0.5156
No improvement (3/10).
Epoch [6/100], Loss: 0.4859, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (4/10).
Epoch [7/100], Loss: 0.4820, Train Acc: 0.7891
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3378, Train Acc: 0.8477
Validation Acc: 0.5156
No improvement (6/10).
Epoch [9/100], Loss: 0.4224, Train Acc: 0.8281
Validation Acc: 0.5000
No improvement (7/10).
Epoch [10/100], Loss: 0.3752, Train Acc: 0.8555
Validation Acc: 0.4844
No improvement (8/10).
Epoch [11/100], Loss: 0.3366, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (9/10).
Epoch [12/100], Loss: 0.3344, Train Acc: 0.8672
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6665, Train Acc: 0.8359
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6176, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5876, Train Acc: 0.8672
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5809, Train Acc: 0.8125
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5784, Train Acc: 0.8008
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.5632, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5653, Train Acc: 0.8281
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5519, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [11/50], Loss: 0.5574, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5384, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (3/10).
Epoch [13/50], Loss: 0.5513, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5390, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (5/10).
Epoch [15/50], Loss: 0.5374, Train Acc: 0.8711
Validation Acc: 0.8750
No improvement (6/10).
Epoch [16/50], Loss: 0.5376, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (7/10).
Epoch [17/50], Loss: 0.5331, Train Acc: 0.8828
Validation Acc: 0.8906
No improvement (8/10).
Epoch [18/50], Loss: 0.5354, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (9/10).
Epoch [19/50], Loss: 0.5376, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.6289
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6748, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (1/10).
Epoch [4/50], Loss: 0.6546, Train Acc: 0.7109
Validation Acc: 0.4844
No improvement (2/10).
Epoch [5/50], Loss: 0.6263, Train Acc: 0.7734
Validation Acc: 0.6406
Epoch [6/50], Loss: 0.6084, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (1/10).
Epoch [7/50], Loss: 0.6062, Train Acc: 0.7383
Validation Acc: 0.6250
No improvement (2/10).
Epoch [8/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.6094
No improvement (3/10).
Epoch [9/50], Loss: 0.6027, Train Acc: 0.7383
Validation Acc: 0.6562
Epoch [10/50], Loss: 0.6237, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (1/10).
Epoch [11/50], Loss: 0.5993, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [12/50], Loss: 0.5815, Train Acc: 0.7578
Validation Acc: 0.6875
Epoch [13/50], Loss: 0.5977, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (1/10).
Epoch [14/50], Loss: 0.5917, Train Acc: 0.7305
Validation Acc: 0.6562
No improvement (2/10).
Epoch [15/50], Loss: 0.5909, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (3/10).
Epoch [16/50], Loss: 0.5891, Train Acc: 0.7461
Validation Acc: 0.6406
No improvement (4/10).
Epoch [17/50], Loss: 0.5772, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (5/10).
Epoch [18/50], Loss: 0.5821, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (6/10).
Epoch [19/50], Loss: 0.5803, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (7/10).
Epoch [20/50], Loss: 0.5774, Train Acc: 0.7539
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5812, Train Acc: 0.7461
Validation Acc: 0.6562
No improvement (9/10).
Epoch [22/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.78 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6582.767166483512, 'sigma_b': 0.020110917713967565, 'd': 0.7346541284894523}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.62s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.29s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.34s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.45
    - Variance: 3001.40

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2539, Train Acc: 0.5469
Validation Acc: 0.4844
Epoch [2/100], Loss: 0.9422, Train Acc: 0.6602
Validation Acc: 0.5000
Epoch [3/100], Loss: 0.7439, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.6289, Train Acc: 0.7227
Validation Acc: 0.5156
Epoch [5/100], Loss: 0.5010, Train Acc: 0.7578
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.5243, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (2/10).
Epoch [7/100], Loss: 0.4138, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/100], Loss: 0.4377, Train Acc: 0.8047
Validation Acc: 0.4688
No improvement (4/10).
Epoch [9/100], Loss: 0.3489, Train Acc: 0.8203
Validation Acc: 0.5469
Epoch [10/100], Loss: 0.4205, Train Acc: 0.8125
Validation Acc: 0.5781
Epoch [11/100], Loss: 0.3149, Train Acc: 0.8555
Validation Acc: 0.5938
Epoch [12/100], Loss: 0.2807, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (1/10).
Epoch [13/100], Loss: 0.2568, Train Acc: 0.8906
Validation Acc: 0.5312
No improvement (2/10).
Epoch [14/100], Loss: 0.2581, Train Acc: 0.8945
Validation Acc: 0.5000
No improvement (3/10).
Epoch [15/100], Loss: 0.2765, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [16/100], Loss: 0.2456, Train Acc: 0.8828
Validation Acc: 0.5469
No improvement (5/10).
Epoch [17/100], Loss: 0.2357, Train Acc: 0.9062
Validation Acc: 0.5312
No improvement (6/10).
Epoch [18/100], Loss: 0.1921, Train Acc: 0.9141
Validation Acc: 0.5469
No improvement (7/10).
Epoch [19/100], Loss: 0.2051, Train Acc: 0.9102
Validation Acc: 0.5156
No improvement (8/10).
Epoch [20/100], Loss: 0.2141, Train Acc: 0.9023
Validation Acc: 0.5000
No improvement (9/10).
Epoch [21/100], Loss: 0.2020, Train Acc: 0.9375
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6926, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6856, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6628, Train Acc: 0.8555
Validation Acc: 0.8594
Epoch [4/50], Loss: 0.6150, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5795, Train Acc: 0.8906
Validation Acc: 0.9375
Epoch [6/50], Loss: 0.5604, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (1/10).
Epoch [7/50], Loss: 0.5752, Train Acc: 0.8281
Validation Acc: 0.7188
No improvement (2/10).
Epoch [8/50], Loss: 0.5677, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [9/50], Loss: 0.5514, Train Acc: 0.8086
Validation Acc: 0.9219
No improvement (4/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (5/10).
Epoch [11/50], Loss: 0.5586, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (6/10).
Epoch [12/50], Loss: 0.5507, Train Acc: 0.7891
Validation Acc: 0.9219
No improvement (7/10).
Epoch [13/50], Loss: 0.5526, Train Acc: 0.7695
Validation Acc: 0.9375
No improvement (8/10).
Epoch [14/50], Loss: 0.5402, Train Acc: 0.8008
Validation Acc: 0.9219
No improvement (9/10).
Epoch [15/50], Loss: 0.5549, Train Acc: 0.7656
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6925, Train Acc: 0.5586
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6445
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6709, Train Acc: 0.6758
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6521, Train Acc: 0.6797
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6356, Train Acc: 0.7031
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/50], Loss: 0.6251, Train Acc: 0.7148
Validation Acc: 0.5469
No improvement (2/10).
Epoch [7/50], Loss: 0.6127, Train Acc: 0.7344
Validation Acc: 0.7344
No improvement (3/10).
Epoch [8/50], Loss: 0.6079, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (4/10).
Epoch [9/50], Loss: 0.6010, Train Acc: 0.7500
Validation Acc: 0.7031
No improvement (5/10).
Epoch [10/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.6719
No improvement (6/10).
Epoch [11/50], Loss: 0.6084, Train Acc: 0.7383
Validation Acc: 0.6406
No improvement (7/10).
Epoch [12/50], Loss: 0.6118, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.5908, Train Acc: 0.7656
Validation Acc: 0.7656
Epoch [14/50], Loss: 0.5770, Train Acc: 0.7891
Validation Acc: 0.7969
Epoch [15/50], Loss: 0.5687, Train Acc: 0.8008
Validation Acc: 0.7812
No improvement (1/10).
Epoch [16/50], Loss: 0.5745, Train Acc: 0.7852
Validation Acc: 0.7656
No improvement (2/10).
Epoch [17/50], Loss: 0.5745, Train Acc: 0.7773
Validation Acc: 0.7656
No improvement (3/10).
Epoch [18/50], Loss: 0.5802, Train Acc: 0.7734
Validation Acc: 0.7656
No improvement (4/10).
Epoch [19/50], Loss: 0.5654, Train Acc: 0.7891
Validation Acc: 0.7812
No improvement (5/10).
Epoch [20/50], Loss: 0.5515, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [21/50], Loss: 0.5403, Train Acc: 0.8359
Validation Acc: 0.8125
Epoch [22/50], Loss: 0.5406, Train Acc: 0.8320
Validation Acc: 0.8281
Epoch [23/50], Loss: 0.5315, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (1/10).
Epoch [24/50], Loss: 0.5240, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (2/10).
Epoch [25/50], Loss: 0.5265, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (3/10).
Epoch [26/50], Loss: 0.5245, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (4/10).
Epoch [27/50], Loss: 0.5160, Train Acc: 0.8672
Validation Acc: 0.8281
No improvement (5/10).
Epoch [28/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [29/50], Loss: 0.5165, Train Acc: 0.8594
Validation Acc: 0.8281
No improvement (7/10).
Epoch [30/50], Loss: 0.5216, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (8/10).
Epoch [31/50], Loss: 0.5193, Train Acc: 0.8594
Validation Acc: 0.8281
No improvement (9/10).
Epoch [32/50], Loss: 0.5239, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.90s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.45s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.52s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.91s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.45s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.52s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.55s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.48s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.55s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.51s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.07s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.66s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.50s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020110917713967565, 'rho': 6582.767166483512, 'd': 0.7346541284894523, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.50s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [11:44:11<2:46:03, 1660.63s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3515_1200/steady_state_trajectories/m_traj_3515.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.74
    - Variance: 3098.06

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4237, Train Acc: 0.4766
Validation Acc: 0.6719
Epoch [2/100], Loss: 1.0637, Train Acc: 0.5508
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.8581, Train Acc: 0.6406
Validation Acc: 0.6562
No improvement (2/10).
Epoch [4/100], Loss: 0.7066, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (3/10).
Epoch [5/100], Loss: 0.4972, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (4/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (5/10).
Epoch [7/100], Loss: 0.4959, Train Acc: 0.7852
Validation Acc: 0.6719
No improvement (6/10).
Epoch [8/100], Loss: 0.4218, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.4164, Train Acc: 0.8398
Validation Acc: 0.6562
No improvement (8/10).
Epoch [10/100], Loss: 0.3497, Train Acc: 0.8320
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.4155, Train Acc: 0.8086
Validation Acc: 0.6562
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.64 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8555
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6080, Train Acc: 0.8672
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5778, Train Acc: 0.8750
Validation Acc: 0.7031
No improvement (1/10).
Epoch [6/50], Loss: 0.5659, Train Acc: 0.8398
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5739, Train Acc: 0.7773
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5447, Train Acc: 0.8320
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.5457, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (3/10).
Epoch [10/50], Loss: 0.5512, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (4/10).
Epoch [11/50], Loss: 0.5537, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (5/10).
Epoch [12/50], Loss: 0.5392, Train Acc: 0.8438
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5531, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (7/10).
Epoch [14/50], Loss: 0.5458, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [15/50], Loss: 0.5436, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5311, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6406
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6743, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6528, Train Acc: 0.7031
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6344, Train Acc: 0.7305
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6099, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6007, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5972, Train Acc: 0.7500
Validation Acc: 0.7344
No improvement (3/10).
Epoch [9/50], Loss: 0.5981, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (4/10).
Epoch [10/50], Loss: 0.5993, Train Acc: 0.7461
Validation Acc: 0.7656
Epoch [11/50], Loss: 0.5816, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/50], Loss: 0.5873, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (2/10).
Epoch [13/50], Loss: 0.5821, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [14/50], Loss: 0.5839, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (4/10).
Epoch [15/50], Loss: 0.5800, Train Acc: 0.7695
Validation Acc: 0.6875
No improvement (5/10).
Epoch [16/50], Loss: 0.5779, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/50], Loss: 0.5823, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (7/10).
Epoch [18/50], Loss: 0.5751, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (8/10).
Epoch [19/50], Loss: 0.5731, Train Acc: 0.7812
Validation Acc: 0.7031
No improvement (9/10).
Epoch [20/50], Loss: 0.5840, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6605.248995949894, 'sigma_b': 0.020042407459520864, 'd': 0.7346547180910648}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.46s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.51s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 3248.49

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.68 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2166, Train Acc: 0.5625
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.9302, Train Acc: 0.6367
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7849, Train Acc: 0.7227
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.5894, Train Acc: 0.7578
Validation Acc: 0.5781
Epoch [5/100], Loss: 0.4949, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/100], Loss: 0.4159, Train Acc: 0.8320
Validation Acc: 0.5625
No improvement (2/10).
Epoch [7/100], Loss: 0.4501, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [8/100], Loss: 0.3421, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [9/100], Loss: 0.3482, Train Acc: 0.8398
Validation Acc: 0.6406
Epoch [10/100], Loss: 0.3008, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (1/10).
Epoch [11/100], Loss: 0.2668, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [12/100], Loss: 0.3178, Train Acc: 0.8398
Validation Acc: 0.6406
No improvement (3/10).
Epoch [13/100], Loss: 0.2083, Train Acc: 0.9102
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2700, Train Acc: 0.8906
Validation Acc: 0.6719
Epoch [15/100], Loss: 0.2396, Train Acc: 0.8828
Validation Acc: 0.6719
No improvement (1/10).
Epoch [16/100], Loss: 0.1797, Train Acc: 0.9219
Validation Acc: 0.6719
No improvement (2/10).
Epoch [17/100], Loss: 0.1940, Train Acc: 0.9375
Validation Acc: 0.6719
No improvement (3/10).
Epoch [18/100], Loss: 0.1674, Train Acc: 0.9297
Validation Acc: 0.7031
Epoch [19/100], Loss: 0.2214, Train Acc: 0.9141
Validation Acc: 0.6406
No improvement (1/10).
Epoch [20/100], Loss: 0.1482, Train Acc: 0.9609
Validation Acc: 0.5938
No improvement (2/10).
Epoch [21/100], Loss: 0.1404, Train Acc: 0.9531
Validation Acc: 0.5781
No improvement (3/10).
Epoch [22/100], Loss: 0.1647, Train Acc: 0.9453
Validation Acc: 0.5781
No improvement (4/10).
Epoch [23/100], Loss: 0.1527, Train Acc: 0.9414
Validation Acc: 0.5781
No improvement (5/10).
Epoch [24/100], Loss: 0.1748, Train Acc: 0.9414
Validation Acc: 0.6094
No improvement (6/10).
Epoch [25/100], Loss: 0.1196, Train Acc: 0.9492
Validation Acc: 0.6094
No improvement (7/10).
Epoch [26/100], Loss: 0.1115, Train Acc: 0.9727
Validation Acc: 0.6250
No improvement (8/10).
Epoch [27/100], Loss: 0.1095, Train Acc: 0.9609
Validation Acc: 0.6094
No improvement (9/10).
Epoch [28/100], Loss: 0.0961, Train Acc: 0.9648
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6857, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6625, Train Acc: 0.8203
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6144, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5781, Train Acc: 0.8789
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.5628, Train Acc: 0.8711
Validation Acc: 0.8125
No improvement (1/10).
Epoch [7/50], Loss: 0.5959, Train Acc: 0.7930
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5616, Train Acc: 0.8047
Validation Acc: 0.9062
Epoch [9/50], Loss: 0.5594, Train Acc: 0.8047
Validation Acc: 0.8906
No improvement (1/10).
Epoch [10/50], Loss: 0.5573, Train Acc: 0.8242
Validation Acc: 0.9062
No improvement (2/10).
Epoch [11/50], Loss: 0.5715, Train Acc: 0.7617
Validation Acc: 0.8125
No improvement (3/10).
Epoch [12/50], Loss: 0.5419, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (4/10).
Epoch [13/50], Loss: 0.5478, Train Acc: 0.7695
Validation Acc: 0.9062
No improvement (5/10).
Epoch [14/50], Loss: 0.5486, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (6/10).
Epoch [15/50], Loss: 0.5445, Train Acc: 0.7930
Validation Acc: 0.9062
No improvement (7/10).
Epoch [16/50], Loss: 0.5380, Train Acc: 0.7930
Validation Acc: 0.9062
No improvement (8/10).
Epoch [17/50], Loss: 0.5241, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (9/10).
Epoch [18/50], Loss: 0.5291, Train Acc: 0.7891
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.84 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6923, Train Acc: 0.5703
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6849, Train Acc: 0.6680
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6689, Train Acc: 0.6641
Validation Acc: 0.5938
Epoch [4/50], Loss: 0.6567, Train Acc: 0.6602
Validation Acc: 0.6250
Epoch [5/50], Loss: 0.6425, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.6406
Epoch [7/50], Loss: 0.6349, Train Acc: 0.6875
Validation Acc: 0.6562
Epoch [8/50], Loss: 0.6346, Train Acc: 0.6797
Validation Acc: 0.6094
No improvement (1/10).
Epoch [9/50], Loss: 0.6219, Train Acc: 0.7109
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6278, Train Acc: 0.6992
Validation Acc: 0.6875
Epoch [11/50], Loss: 0.5871, Train Acc: 0.7773
Validation Acc: 0.8281
Epoch [12/50], Loss: 0.5564, Train Acc: 0.8281
Validation Acc: 0.8594
Epoch [13/50], Loss: 0.5433, Train Acc: 0.8320
Validation Acc: 0.7031
No improvement (1/10).
Epoch [14/50], Loss: 0.5299, Train Acc: 0.8594
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5474, Train Acc: 0.8242
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5516, Train Acc: 0.8125
Validation Acc: 0.6562
No improvement (4/10).
Epoch [17/50], Loss: 0.6426, Train Acc: 0.6680
Validation Acc: 0.6719
No improvement (5/10).
Epoch [18/50], Loss: 0.5513, Train Acc: 0.8125
Validation Acc: 0.7812
No improvement (6/10).
Epoch [19/50], Loss: 0.5092, Train Acc: 0.8711
Validation Acc: 0.7969
No improvement (7/10).
Epoch [20/50], Loss: 0.5626, Train Acc: 0.7930
Validation Acc: 0.7969
No improvement (8/10).
Epoch [21/50], Loss: 0.5448, Train Acc: 0.8242
Validation Acc: 0.8281
No improvement (9/10).
Epoch [22/50], Loss: 0.4962, Train Acc: 0.8789
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.99s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.99s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.58s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.38s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.74s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.04s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.88s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.90s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.68s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  6.98s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.09s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020042407459520864, 'rho': 6605.248995949894, 'd': 0.7346547180910648, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [12:08:49<2:13:48, 1605.77s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3527_1200/steady_state_trajectories/m_traj_3527.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.08
    - Variance: 3272.82

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3627, Train Acc: 0.4922
Validation Acc: 0.6094
Epoch [2/100], Loss: 0.9029, Train Acc: 0.6094
Validation Acc: 0.6094
No improvement (1/10).
Epoch [3/100], Loss: 0.7587, Train Acc: 0.6523
Validation Acc: 0.5938
No improvement (2/10).
Epoch [4/100], Loss: 0.6424, Train Acc: 0.7383
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.5146, Train Acc: 0.7695
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5055, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (5/10).
Epoch [7/100], Loss: 0.5203, Train Acc: 0.8203
Validation Acc: 0.5625
No improvement (6/10).
Epoch [8/100], Loss: 0.4039, Train Acc: 0.8125
Validation Acc: 0.5625
No improvement (7/10).
Epoch [9/100], Loss: 0.3739, Train Acc: 0.8281
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.4216, Train Acc: 0.8242
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3380, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6674, Train Acc: 0.8203
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6196, Train Acc: 0.8398
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5928, Train Acc: 0.8633
Validation Acc: 0.8594
Epoch [6/50], Loss: 0.5795, Train Acc: 0.8242
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7930
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/50], Loss: 0.5635, Train Acc: 0.7617
Validation Acc: 0.6562
No improvement (2/10).
Epoch [9/50], Loss: 0.5806, Train Acc: 0.7539
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/50], Loss: 0.5539, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [11/50], Loss: 0.5790, Train Acc: 0.7500
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5422, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5594, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5541, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (8/10).
Epoch [15/50], Loss: 0.5487, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (9/10).
Epoch [16/50], Loss: 0.5544, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.6680
Validation Acc: 0.6719
Epoch [3/50], Loss: 0.6702, Train Acc: 0.6914
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6510, Train Acc: 0.6992
Validation Acc: 0.7500
No improvement (1/10).
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (2/10).
Epoch [6/50], Loss: 0.6206, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6146, Train Acc: 0.7305
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6118, Train Acc: 0.7266
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6006, Train Acc: 0.7500
Validation Acc: 0.7188
No improvement (6/10).
Epoch [10/50], Loss: 0.6074, Train Acc: 0.7422
Validation Acc: 0.7188
No improvement (7/10).
Epoch [11/50], Loss: 0.5999, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5952, Train Acc: 0.7578
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (1/10).
Epoch [14/50], Loss: 0.5676, Train Acc: 0.8047
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5774, Train Acc: 0.8008
Validation Acc: 0.7656
No improvement (3/10).
Epoch [16/50], Loss: 0.5691, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5664, Train Acc: 0.8047
Validation Acc: 0.7500
No improvement (5/10).
Epoch [18/50], Loss: 0.5629, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (6/10).
Epoch [19/50], Loss: 0.5623, Train Acc: 0.8047
Validation Acc: 0.7344
No improvement (7/10).
Epoch [20/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (8/10).
Epoch [21/50], Loss: 0.5650, Train Acc: 0.8086
Validation Acc: 0.7344
No improvement (9/10).
Epoch [22/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.76 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
[STRESS] âœ… Found: {'rho': 6627.730825168414, 'sigma_b': 0.01997436239803019, 'd': 0.7346553036988404}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138067617, 'sigma_b': 0.060145439998530295, 'd': 0.7827636158617833}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.75s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.13
    - Variance: 3615.15

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.66
    - Variance: 1097.76
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2388, Train Acc: 0.5469
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8356, Train Acc: 0.6367
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.8067, Train Acc: 0.7070
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6093, Train Acc: 0.7070
Validation Acc: 0.5938
No improvement (1/10).
Epoch [5/100], Loss: 0.3827, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [6/100], Loss: 0.4218, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (3/10).
Epoch [7/100], Loss: 0.3527, Train Acc: 0.8477
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3303, Train Acc: 0.8516
Validation Acc: 0.5938
No improvement (5/10).
Epoch [9/100], Loss: 0.3873, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3314, Train Acc: 0.8516
Validation Acc: 0.6250
No improvement (7/10).
Epoch [11/100], Loss: 0.3279, Train Acc: 0.8711
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.2964, Train Acc: 0.8438
Validation Acc: 0.6094
No improvement (9/10).
Epoch [13/100], Loss: 0.2887, Train Acc: 0.8789
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6857, Train Acc: 0.7344
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6629, Train Acc: 0.8125
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6151, Train Acc: 0.8672
Validation Acc: 0.8750
Epoch [5/50], Loss: 0.5843, Train Acc: 0.8750
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5664, Train Acc: 0.8477
Validation Acc: 0.6875
No improvement (1/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.5590, Train Acc: 0.8125
Validation Acc: 0.5469
No improvement (3/10).
Epoch [9/50], Loss: 0.5604, Train Acc: 0.8125
Validation Acc: 0.6875
No improvement (4/10).
Epoch [10/50], Loss: 0.5548, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (5/10).
Epoch [11/50], Loss: 0.5605, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5431, Train Acc: 0.8594
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5586, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5515, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (9/10).
Epoch [15/50], Loss: 0.5454, Train Acc: 0.8320
Validation Acc: 0.9062
Epoch [16/50], Loss: 0.5448, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (1/10).
Epoch [17/50], Loss: 0.5393, Train Acc: 0.8555
Validation Acc: 0.8438
No improvement (2/10).
Epoch [18/50], Loss: 0.5471, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (3/10).
Epoch [19/50], Loss: 0.5483, Train Acc: 0.8438
Validation Acc: 0.9062
No improvement (4/10).
Epoch [20/50], Loss: 0.5358, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (5/10).
Epoch [21/50], Loss: 0.5504, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [22/50], Loss: 0.5374, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (7/10).
Epoch [23/50], Loss: 0.5400, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (8/10).
Epoch [24/50], Loss: 0.5498, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (9/10).
Epoch [25/50], Loss: 0.5419, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5469
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6602
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6875
Validation Acc: 0.6875
Epoch [4/50], Loss: 0.6457, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/50], Loss: 0.6275, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/50], Loss: 0.6378, Train Acc: 0.6836
Validation Acc: 0.7188
Epoch [7/50], Loss: 0.6096, Train Acc: 0.7461
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6057, Train Acc: 0.7461
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5890, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (2/10).
Epoch [10/50], Loss: 0.5922, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (3/10).
Epoch [11/50], Loss: 0.5895, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (4/10).
Epoch [12/50], Loss: 0.5975, Train Acc: 0.7383
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5792, Train Acc: 0.7656
Validation Acc: 0.7969
No improvement (1/10).
Epoch [14/50], Loss: 0.5855, Train Acc: 0.7617
Validation Acc: 0.7656
No improvement (2/10).
Epoch [15/50], Loss: 0.5768, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5767, Train Acc: 0.7734
Validation Acc: 0.7656
No improvement (4/10).
Epoch [17/50], Loss: 0.5813, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (5/10).
Epoch [18/50], Loss: 0.5894, Train Acc: 0.7539
Validation Acc: 0.7656
No improvement (6/10).
Epoch [19/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.7656
No improvement (7/10).
Epoch [20/50], Loss: 0.5806, Train Acc: 0.7617
Validation Acc: 0.7812
No improvement (8/10).
Epoch [21/50], Loss: 0.5776, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (9/10).
Epoch [22/50], Loss: 0.5753, Train Acc: 0.7656
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.93s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.15s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:14<00:00,  7.27s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.52s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.61s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.50s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.57s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.74s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.46s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.50s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.81s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.44s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.49s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.51s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.01997436239803019, 'rho': 6627.730825168414, 'd': 0.7346553036988404, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.53s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [12:24:44<1:34:02, 1410.66s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3539_1200/steady_state_trajectories/m_traj_3539.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.91
    - Variance: 3465.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.75 ===
=== Logistic Regression Accuracy: 0.53 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4573, Train Acc: 0.4961
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8817, Train Acc: 0.6016
Validation Acc: 0.6562
Epoch [3/100], Loss: 0.7755, Train Acc: 0.6719
Validation Acc: 0.6250
No improvement (1/10).
Epoch [4/100], Loss: 0.6710, Train Acc: 0.7148
Validation Acc: 0.7031
Epoch [5/100], Loss: 0.6421, Train Acc: 0.7227
Validation Acc: 0.6250
No improvement (1/10).
Epoch [6/100], Loss: 0.4982, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [7/100], Loss: 0.5111, Train Acc: 0.7656
Validation Acc: 0.6719
No improvement (3/10).
Epoch [8/100], Loss: 0.4003, Train Acc: 0.7969
Validation Acc: 0.7188
Epoch [9/100], Loss: 0.3841, Train Acc: 0.8320
Validation Acc: 0.7188
No improvement (1/10).
Epoch [10/100], Loss: 0.3705, Train Acc: 0.8438
Validation Acc: 0.7500
Epoch [11/100], Loss: 0.3801, Train Acc: 0.8281
Validation Acc: 0.7344
No improvement (1/10).
Epoch [12/100], Loss: 0.3738, Train Acc: 0.8438
Validation Acc: 0.7188
No improvement (2/10).
Epoch [13/100], Loss: 0.2802, Train Acc: 0.8750
Validation Acc: 0.7188
No improvement (3/10).
Epoch [14/100], Loss: 0.3365, Train Acc: 0.8281
Validation Acc: 0.7031
No improvement (4/10).
Epoch [15/100], Loss: 0.2970, Train Acc: 0.8750
Validation Acc: 0.7344
No improvement (5/10).
Epoch [16/100], Loss: 0.2906, Train Acc: 0.8672
Validation Acc: 0.7188
No improvement (6/10).
Epoch [17/100], Loss: 0.2379, Train Acc: 0.9023
Validation Acc: 0.7031
No improvement (7/10).
Epoch [18/100], Loss: 0.2199, Train Acc: 0.8984
Validation Acc: 0.7031
No improvement (8/10).
Epoch [19/100], Loss: 0.1860, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (9/10).
Epoch [20/100], Loss: 0.2095, Train Acc: 0.9258
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6643, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6091, Train Acc: 0.8516
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5771, Train Acc: 0.8906
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8203
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5758, Train Acc: 0.7891
Validation Acc: 0.8750
Epoch [8/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.5644, Train Acc: 0.8164
Validation Acc: 0.8906
Epoch [10/50], Loss: 0.5603, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5550, Train Acc: 0.8516
Validation Acc: 0.9219
Epoch [12/50], Loss: 0.5383, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (1/10).
Epoch [13/50], Loss: 0.5377, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (2/10).
Epoch [14/50], Loss: 0.5405, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (3/10).
Epoch [15/50], Loss: 0.5257, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (4/10).
Epoch [16/50], Loss: 0.5208, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (5/10).
Epoch [17/50], Loss: 0.5099, Train Acc: 0.8672
Validation Acc: 0.8750
No improvement (6/10).
Epoch [18/50], Loss: 0.5160, Train Acc: 0.8633
Validation Acc: 0.8906
No improvement (7/10).
Epoch [19/50], Loss: 0.5112, Train Acc: 0.8750
Validation Acc: 0.8906
No improvement (8/10).
Epoch [20/50], Loss: 0.5152, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (9/10).
Epoch [21/50], Loss: 0.5157, Train Acc: 0.8594
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/50], Loss: 0.6686, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6396, Train Acc: 0.7539
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6045, Train Acc: 0.8164
Validation Acc: 0.6875
No improvement (2/10).
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (3/10).
Epoch [7/50], Loss: 0.5735, Train Acc: 0.8047
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5892, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5978, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5762, Train Acc: 0.7969
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [13/50], Loss: 0.5529, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5304, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [15/50], Loss: 0.5353, Train Acc: 0.8398
Validation Acc: 0.8125
No improvement (8/10).
Epoch [16/50], Loss: 0.5493, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (9/10).
Epoch [17/50], Loss: 0.5543, Train Acc: 0.8008
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6650.212654144843, 'sigma_b': 0.0199067778074453, 'd': 0.7346558853532238}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.85s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.51s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.56s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.30
    - Variance: 3207.73

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.65 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2178, Train Acc: 0.5664
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8252, Train Acc: 0.6641
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.6499, Train Acc: 0.7461
Validation Acc: 0.5156
No improvement (1/10).
Epoch [4/100], Loss: 0.5393, Train Acc: 0.7852
Validation Acc: 0.5312
Epoch [5/100], Loss: 0.4479, Train Acc: 0.8125
Validation Acc: 0.5156
No improvement (1/10).
Epoch [6/100], Loss: 0.4181, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (2/10).
Epoch [7/100], Loss: 0.3858, Train Acc: 0.8438
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.2778, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (1/10).
Epoch [9/100], Loss: 0.2700, Train Acc: 0.8906
Validation Acc: 0.5000
No improvement (2/10).
Epoch [10/100], Loss: 0.2817, Train Acc: 0.8828
Validation Acc: 0.4844
No improvement (3/10).
Epoch [11/100], Loss: 0.2032, Train Acc: 0.9219
Validation Acc: 0.5156
No improvement (4/10).
Epoch [12/100], Loss: 0.2391, Train Acc: 0.9062
Validation Acc: 0.5469
No improvement (5/10).
Epoch [13/100], Loss: 0.2837, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (6/10).
Epoch [14/100], Loss: 0.2216, Train Acc: 0.9023
Validation Acc: 0.5156
No improvement (7/10).
Epoch [15/100], Loss: 0.2192, Train Acc: 0.9102
Validation Acc: 0.5156
No improvement (8/10).
Epoch [16/100], Loss: 0.2589, Train Acc: 0.8828
Validation Acc: 0.4844
No improvement (9/10).
Epoch [17/100], Loss: 0.2276, Train Acc: 0.9141
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6855, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6638, Train Acc: 0.8555
Validation Acc: 0.7969
Epoch [4/50], Loss: 0.6137, Train Acc: 0.8672
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8828
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5756, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (1/10).
Epoch [7/50], Loss: 0.5722, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (2/10).
Epoch [8/50], Loss: 0.5705, Train Acc: 0.7891
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5572, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (4/10).
Epoch [10/50], Loss: 0.5735, Train Acc: 0.7930
Validation Acc: 0.8906
No improvement (5/10).
Epoch [11/50], Loss: 0.5655, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (6/10).
Epoch [12/50], Loss: 0.5380, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (7/10).
Epoch [13/50], Loss: 0.5522, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5445, Train Acc: 0.8047
Validation Acc: 0.9062
Epoch [15/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5464, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (2/10).
Epoch [17/50], Loss: 0.5248, Train Acc: 0.8789
Validation Acc: 0.8906
No improvement (3/10).
Epoch [18/50], Loss: 0.5448, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (4/10).
Epoch [19/50], Loss: 0.5448, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (5/10).
Epoch [20/50], Loss: 0.5228, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (6/10).
Epoch [21/50], Loss: 0.5452, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (7/10).
Epoch [22/50], Loss: 0.5345, Train Acc: 0.8555
Validation Acc: 0.9062
No improvement (8/10).
Epoch [23/50], Loss: 0.5448, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (9/10).
Epoch [24/50], Loss: 0.5563, Train Acc: 0.8242
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5430
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6883, Train Acc: 0.6562
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6757, Train Acc: 0.6484
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6634, Train Acc: 0.6602
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6508, Train Acc: 0.6758
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6369, Train Acc: 0.6875
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.6281, Train Acc: 0.6992
Validation Acc: 0.7969
Epoch [8/50], Loss: 0.6128, Train Acc: 0.7266
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5885, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/50], Loss: 0.5834, Train Acc: 0.7891
Validation Acc: 0.6406
No improvement (2/10).
Epoch [11/50], Loss: 0.5846, Train Acc: 0.7734
Validation Acc: 0.8281
Epoch [12/50], Loss: 0.5739, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (1/10).
Epoch [13/50], Loss: 0.5615, Train Acc: 0.8047
Validation Acc: 0.7812
No improvement (2/10).
Epoch [14/50], Loss: 0.5662, Train Acc: 0.7930
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5737, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (4/10).
Epoch [16/50], Loss: 0.5321, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [17/50], Loss: 0.5468, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (1/10).
Epoch [18/50], Loss: 0.5778, Train Acc: 0.7656
Validation Acc: 0.8125
No improvement (2/10).
Epoch [19/50], Loss: 0.5895, Train Acc: 0.7500
Validation Acc: 0.7969
No improvement (3/10).
Epoch [20/50], Loss: 0.5930, Train Acc: 0.7500
Validation Acc: 0.8125
No improvement (4/10).
Epoch [21/50], Loss: 0.5887, Train Acc: 0.7422
Validation Acc: 0.8125
No improvement (5/10).
Epoch [22/50], Loss: 0.5727, Train Acc: 0.7695
Validation Acc: 0.8438
No improvement (6/10).
Epoch [23/50], Loss: 0.5684, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (7/10).
Epoch [24/50], Loss: 0.5648, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (8/10).
Epoch [25/50], Loss: 0.5610, Train Acc: 0.7930
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5604, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.67s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.45s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.48s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.79s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.60s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.74s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.52s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.55s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.70s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.49s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.52s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.63s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.41s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.44s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.76s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.86s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.60s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.90s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.61s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.70s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0199067778074453, 'rho': 6650.212654144843, 'd': 0.7346558853532238, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.43s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.47s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [12:48:44<1:10:58, 1419.58s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3551_1200/steady_state_trajectories/m_traj_3551.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 3071.65

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.71 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.44 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4805, Train Acc: 0.4883
Validation Acc: 0.5312
Epoch [2/100], Loss: 0.7989, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7420, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.6440, Train Acc: 0.7383
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.4855, Train Acc: 0.7969
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4329, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.3840, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/100], Loss: 0.2760, Train Acc: 0.8633
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.3618, Train Acc: 0.8359
Validation Acc: 0.6094
No improvement (1/10).
Epoch [10/100], Loss: 0.3421, Train Acc: 0.8555
Validation Acc: 0.6094
No improvement (2/10).
Epoch [11/100], Loss: 0.2600, Train Acc: 0.8711
Validation Acc: 0.5781
No improvement (3/10).
Epoch [12/100], Loss: 0.2570, Train Acc: 0.8945
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.2183, Train Acc: 0.9062
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2482, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (6/10).
Epoch [15/100], Loss: 0.2238, Train Acc: 0.9023
Validation Acc: 0.5469
No improvement (7/10).
Epoch [16/100], Loss: 0.2141, Train Acc: 0.9102
Validation Acc: 0.5312
No improvement (8/10).
Epoch [17/100], Loss: 0.1373, Train Acc: 0.9453
Validation Acc: 0.5469
No improvement (9/10).
Epoch [18/100], Loss: 0.1360, Train Acc: 0.9570
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.7188
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6620, Train Acc: 0.8516
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6098, Train Acc: 0.8477
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5920, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5750, Train Acc: 0.8164
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7422
Validation Acc: 0.6562
No improvement (1/10).
Epoch [8/50], Loss: 0.5613, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [9/50], Loss: 0.5689, Train Acc: 0.7969
Validation Acc: 0.7812
No improvement (1/10).
Epoch [10/50], Loss: 0.5601, Train Acc: 0.8164
Validation Acc: 0.7656
No improvement (2/10).
Epoch [11/50], Loss: 0.5619, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (3/10).
Epoch [12/50], Loss: 0.5513, Train Acc: 0.8281
Validation Acc: 0.8125
No improvement (4/10).
Epoch [13/50], Loss: 0.5524, Train Acc: 0.8047
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5553, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [15/50], Loss: 0.5469, Train Acc: 0.8398
Validation Acc: 0.8906
No improvement (7/10).
Epoch [16/50], Loss: 0.5403, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (8/10).
Epoch [17/50], Loss: 0.5423, Train Acc: 0.8438
Validation Acc: 0.8125
No improvement (9/10).
Epoch [18/50], Loss: 0.5395, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6484
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6701, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6548, Train Acc: 0.6797
Validation Acc: 0.6875
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6264, Train Acc: 0.7344
Validation Acc: 0.5000
No improvement (3/10).
Epoch [7/50], Loss: 0.6323, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.5961, Train Acc: 0.7539
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6167, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (2/10).
Epoch [10/50], Loss: 0.6161, Train Acc: 0.6875
Validation Acc: 0.6719
No improvement (3/10).
Epoch [11/50], Loss: 0.5937, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (4/10).
Epoch [12/50], Loss: 0.5974, Train Acc: 0.7344
Validation Acc: 0.7188
No improvement (5/10).
Epoch [13/50], Loss: 0.6012, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (6/10).
Epoch [14/50], Loss: 0.5916, Train Acc: 0.7422
Validation Acc: 0.6875
No improvement (7/10).
Epoch [15/50], Loss: 0.5956, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (8/10).
Epoch [16/50], Loss: 0.5865, Train Acc: 0.7461
Validation Acc: 0.6875
No improvement (9/10).
Epoch [17/50], Loss: 0.5958, Train Acc: 0.7266
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6672.694482879823, 'sigma_b': 0.019839649029406714, 'd': 0.7346564630941124}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.84s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.70
    - Variance: 3137.94

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.60 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2094, Train Acc: 0.5156
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9354, Train Acc: 0.6758
Validation Acc: 0.4688
No improvement (1/10).
Epoch [3/100], Loss: 0.8221, Train Acc: 0.6992
Validation Acc: 0.4531
No improvement (2/10).
Epoch [4/100], Loss: 0.6140, Train Acc: 0.7305
Validation Acc: 0.5312
Epoch [5/100], Loss: 0.4691, Train Acc: 0.8281
Validation Acc: 0.5312
No improvement (1/10).
Epoch [6/100], Loss: 0.4804, Train Acc: 0.7578
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.4203, Train Acc: 0.8125
Validation Acc: 0.6406
Epoch [8/100], Loss: 0.3838, Train Acc: 0.8359
Validation Acc: 0.6406
No improvement (1/10).
Epoch [9/100], Loss: 0.3162, Train Acc: 0.8516
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/100], Loss: 0.3464, Train Acc: 0.8594
Validation Acc: 0.5938
No improvement (3/10).
Epoch [11/100], Loss: 0.2995, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/100], Loss: 0.2937, Train Acc: 0.8555
Validation Acc: 0.5938
No improvement (5/10).
Epoch [13/100], Loss: 0.3235, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (6/10).
Epoch [14/100], Loss: 0.2713, Train Acc: 0.8750
Validation Acc: 0.6094
No improvement (7/10).
Epoch [15/100], Loss: 0.2639, Train Acc: 0.8789
Validation Acc: 0.6406
No improvement (8/10).
Epoch [16/100], Loss: 0.1820, Train Acc: 0.9375
Validation Acc: 0.6250
No improvement (9/10).
Epoch [17/100], Loss: 0.2019, Train Acc: 0.9375
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6640, Train Acc: 0.8477
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6173, Train Acc: 0.8164
Validation Acc: 0.7812
No improvement (1/10).
Epoch [5/50], Loss: 0.5921, Train Acc: 0.8555
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5765, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [7/50], Loss: 0.5900, Train Acc: 0.7617
Validation Acc: 0.8594
No improvement (1/10).
Epoch [8/50], Loss: 0.5644, Train Acc: 0.8086
Validation Acc: 0.7031
No improvement (2/10).
Epoch [9/50], Loss: 0.5734, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (3/10).
Epoch [10/50], Loss: 0.5659, Train Acc: 0.7891
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5701, Train Acc: 0.7773
Validation Acc: 0.8906
No improvement (1/10).
Epoch [12/50], Loss: 0.5446, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (2/10).
Epoch [13/50], Loss: 0.5555, Train Acc: 0.7969
Validation Acc: 0.9219
Epoch [14/50], Loss: 0.5552, Train Acc: 0.7695
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5517, Train Acc: 0.7852
Validation Acc: 0.8906
No improvement (2/10).
Epoch [16/50], Loss: 0.5389, Train Acc: 0.8086
Validation Acc: 0.9219
No improvement (3/10).
Epoch [17/50], Loss: 0.5228, Train Acc: 0.8555
Validation Acc: 0.9219
No improvement (4/10).
Epoch [18/50], Loss: 0.5335, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (5/10).
Epoch [19/50], Loss: 0.5334, Train Acc: 0.7852
Validation Acc: 0.9062
No improvement (6/10).
Epoch [20/50], Loss: 0.5171, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (7/10).
Epoch [21/50], Loss: 0.5258, Train Acc: 0.7969
Validation Acc: 0.9219
No improvement (8/10).
Epoch [22/50], Loss: 0.5143, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5180, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6923, Train Acc: 0.5703
Validation Acc: 0.4688
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6367
Validation Acc: 0.4219
No improvement (1/10).
Epoch [3/50], Loss: 0.6736, Train Acc: 0.6289
Validation Acc: 0.4844
Epoch [4/50], Loss: 0.6641, Train Acc: 0.6484
Validation Acc: 0.5781
Epoch [5/50], Loss: 0.6512, Train Acc: 0.6758
Validation Acc: 0.6719
Epoch [6/50], Loss: 0.6468, Train Acc: 0.6719
Validation Acc: 0.5000
No improvement (1/10).
Epoch [7/50], Loss: 0.6491, Train Acc: 0.6445
Validation Acc: 0.6094
No improvement (2/10).
Epoch [8/50], Loss: 0.6392, Train Acc: 0.6758
Validation Acc: 0.6406
No improvement (3/10).
Epoch [9/50], Loss: 0.6363, Train Acc: 0.6719
Validation Acc: 0.6719
No improvement (4/10).
Epoch [10/50], Loss: 0.6339, Train Acc: 0.6680
Validation Acc: 0.7500
Epoch [11/50], Loss: 0.6257, Train Acc: 0.6914
Validation Acc: 0.7188
No improvement (1/10).
Epoch [12/50], Loss: 0.6129, Train Acc: 0.7227
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5928, Train Acc: 0.7773
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.5604, Train Acc: 0.8125
Validation Acc: 0.9062
Epoch [15/50], Loss: 0.5433, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (1/10).
Epoch [16/50], Loss: 0.6012, Train Acc: 0.7383
Validation Acc: 0.7812
No improvement (2/10).
Epoch [17/50], Loss: 0.5766, Train Acc: 0.7773
Validation Acc: 0.9062
No improvement (3/10).
Epoch [18/50], Loss: 0.5243, Train Acc: 0.8633
Validation Acc: 0.7812
No improvement (4/10).
Epoch [19/50], Loss: 0.5262, Train Acc: 0.8633
Validation Acc: 0.8125
No improvement (5/10).
Epoch [20/50], Loss: 0.5222, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5333, Train Acc: 0.8516
Validation Acc: 0.8906
No improvement (7/10).
Epoch [22/50], Loss: 0.5079, Train Acc: 0.8984
Validation Acc: 0.9219
Epoch [23/50], Loss: 0.5406, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (1/10).
Epoch [24/50], Loss: 0.5410, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (2/10).
Epoch [25/50], Loss: 0.5333, Train Acc: 0.8438
Validation Acc: 0.8594
No improvement (3/10).
Epoch [26/50], Loss: 0.5338, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (4/10).
Epoch [27/50], Loss: 0.5201, Train Acc: 0.8633
Validation Acc: 0.9062
No improvement (5/10).
Epoch [28/50], Loss: 0.5210, Train Acc: 0.8633
Validation Acc: 0.9219
No improvement (6/10).
Epoch [29/50], Loss: 0.5188, Train Acc: 0.8633
Validation Acc: 0.9219
No improvement (7/10).
Epoch [30/50], Loss: 0.5253, Train Acc: 0.8516
Validation Acc: 0.9219
No improvement (8/10).
Epoch [31/50], Loss: 0.5138, Train Acc: 0.8750
Validation Acc: 0.9062
No improvement (9/10).
Epoch [32/50], Loss: 0.5161, Train Acc: 0.8711
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.82 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.07s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.03s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.26s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.17s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.19s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.40s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.36s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.43s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.98s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.64s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.30s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.50s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.42s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.42s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.57s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.13s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  8.92s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.10s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.12s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019839649029406714, 'rho': 6672.694482879823, 'd': 0.7346564630941124, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.13s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.13s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [13:14:33<48:36, 1458.38s/it]  /home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-899402>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-899402>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3563_1200/steady_state_trajectories/m_traj_3563.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.95
    - Variance: 3307.86

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.79 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.5398, Train Acc: 0.4570
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8403, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7892, Train Acc: 0.6680
Validation Acc: 0.6406
Epoch [4/100], Loss: 0.6004, Train Acc: 0.7070
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5567, Train Acc: 0.7383
Validation Acc: 0.6094
No improvement (2/10).
Epoch [6/100], Loss: 0.5427, Train Acc: 0.7695
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4191, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (4/10).
Epoch [8/100], Loss: 0.3513, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.3235, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.2958, Train Acc: 0.8633
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.2820, Train Acc: 0.8750
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3666, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.2868, Train Acc: 0.8789
Validation Acc: 0.6562
Epoch [14/100], Loss: 0.2997, Train Acc: 0.8555
Validation Acc: 0.6406
No improvement (1/10).
Epoch [15/100], Loss: 0.2218, Train Acc: 0.8984
Validation Acc: 0.5781
No improvement (2/10).
Epoch [16/100], Loss: 0.2806, Train Acc: 0.8828
Validation Acc: 0.6250
No improvement (3/10).
Epoch [17/100], Loss: 0.2364, Train Acc: 0.8867
Validation Acc: 0.6094
No improvement (4/10).
Epoch [18/100], Loss: 0.2270, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (5/10).
Epoch [19/100], Loss: 0.2097, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (6/10).
Epoch [20/100], Loss: 0.2062, Train Acc: 0.9102
Validation Acc: 0.6562
No improvement (7/10).
Epoch [21/100], Loss: 0.2010, Train Acc: 0.9219
Validation Acc: 0.6562
No improvement (8/10).
Epoch [22/100], Loss: 0.1978, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (9/10).
Epoch [23/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6632, Train Acc: 0.8438
Validation Acc: 0.8438
Epoch [4/50], Loss: 0.6087, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5809, Train Acc: 0.8867
Validation Acc: 0.9219
Epoch [6/50], Loss: 0.5702, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (1/10).
Epoch [7/50], Loss: 0.5796, Train Acc: 0.7812
Validation Acc: 0.5938
No improvement (2/10).
Epoch [8/50], Loss: 0.5562, Train Acc: 0.8125
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5552, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5538, Train Acc: 0.8203
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5508, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.5401, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (7/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (8/10).
Epoch [14/50], Loss: 0.5422, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (9/10).
Epoch [15/50], Loss: 0.5429, Train Acc: 0.8320
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6888, Train Acc: 0.6250
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6875
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6532, Train Acc: 0.7070
Validation Acc: 0.4688
No improvement (1/10).
Epoch [5/50], Loss: 0.6189, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (2/10).
Epoch [6/50], Loss: 0.5948, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (3/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7930
Validation Acc: 0.6406
No improvement (4/10).
Epoch [8/50], Loss: 0.5869, Train Acc: 0.7773
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/50], Loss: 0.5899, Train Acc: 0.7656
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.5792, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5835, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (2/10).
Epoch [12/50], Loss: 0.5863, Train Acc: 0.7695
Validation Acc: 0.7656
No improvement (3/10).
Epoch [13/50], Loss: 0.5829, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (4/10).
Epoch [14/50], Loss: 0.5760, Train Acc: 0.7852
Validation Acc: 0.7500
No improvement (5/10).
Epoch [15/50], Loss: 0.5873, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (6/10).
Epoch [16/50], Loss: 0.5820, Train Acc: 0.7734
Validation Acc: 0.7812
No improvement (7/10).
Epoch [17/50], Loss: 0.5797, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (8/10).
Epoch [18/50], Loss: 0.5855, Train Acc: 0.7578
Validation Acc: 0.7969
No improvement (9/10).
Epoch [19/50], Loss: 0.5859, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
[STRESS] âœ… Found: {'rho': 6695.176311177033, 'sigma_b': 0.019772971468292492, 'd': 0.7346570369607585}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138062267, 'sigma_b': 0.0601454399985078, 'd': 0.7827636158617528}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.51s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.37s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.39s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.26
    - Variance: 2848.98

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.80
    - Variance: 1128.74
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.68 ===
=== Random Forest Accuracy: 0.78 ===
=== Logistic Regression Accuracy: 0.64 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2693, Train Acc: 0.5469
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.7491, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.6898, Train Acc: 0.7227
Validation Acc: 0.5469
Epoch [4/100], Loss: 0.5847, Train Acc: 0.7578
Validation Acc: 0.5625
Epoch [5/100], Loss: 0.5430, Train Acc: 0.7539
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4497, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (1/10).
Epoch [7/100], Loss: 0.4236, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (2/10).
Epoch [8/100], Loss: 0.3167, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (3/10).
Epoch [9/100], Loss: 0.3710, Train Acc: 0.8398
Validation Acc: 0.5938
Epoch [10/100], Loss: 0.3023, Train Acc: 0.8711
Validation Acc: 0.5469
No improvement (1/10).
Epoch [11/100], Loss: 0.3078, Train Acc: 0.8750
Validation Acc: 0.5469
No improvement (2/10).
Epoch [12/100], Loss: 0.3238, Train Acc: 0.8906
Validation Acc: 0.5000
No improvement (3/10).
Epoch [13/100], Loss: 0.2648, Train Acc: 0.8945
Validation Acc: 0.5156
No improvement (4/10).
Epoch [14/100], Loss: 0.2706, Train Acc: 0.8633
Validation Acc: 0.5469
No improvement (5/10).
Epoch [15/100], Loss: 0.2411, Train Acc: 0.8945
Validation Acc: 0.5781
No improvement (6/10).
Epoch [16/100], Loss: 0.2002, Train Acc: 0.9141
Validation Acc: 0.5781
No improvement (7/10).
Epoch [17/100], Loss: 0.2046, Train Acc: 0.9258
Validation Acc: 0.5312
No improvement (8/10).
Epoch [18/100], Loss: 0.2106, Train Acc: 0.9219
Validation Acc: 0.5469
No improvement (9/10).
Epoch [19/100], Loss: 0.1822, Train Acc: 0.9336
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6866, Train Acc: 0.7031
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6665, Train Acc: 0.7891
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6233, Train Acc: 0.8359
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5830, Train Acc: 0.8594
Validation Acc: 0.7188
No improvement (1/10).
Epoch [6/50], Loss: 0.5734, Train Acc: 0.8359
Validation Acc: 0.9062
Epoch [7/50], Loss: 0.5912, Train Acc: 0.7656
Validation Acc: 0.9219
Epoch [8/50], Loss: 0.5755, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5758, Train Acc: 0.7852
Validation Acc: 0.9375
Epoch [10/50], Loss: 0.5692, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5919, Train Acc: 0.7461
Validation Acc: 0.8906
No improvement (2/10).
Epoch [12/50], Loss: 0.5612, Train Acc: 0.7812
Validation Acc: 0.9062
No improvement (3/10).
Epoch [13/50], Loss: 0.5776, Train Acc: 0.7461
Validation Acc: 0.8750
No improvement (4/10).
Epoch [14/50], Loss: 0.5636, Train Acc: 0.7578
Validation Acc: 0.9219
No improvement (5/10).
Epoch [15/50], Loss: 0.5555, Train Acc: 0.7930
Validation Acc: 0.9062
No improvement (6/10).
Epoch [16/50], Loss: 0.5615, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (7/10).
Epoch [17/50], Loss: 0.5529, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (8/10).
Epoch [18/50], Loss: 0.5630, Train Acc: 0.7734
Validation Acc: 0.8906
No improvement (9/10).
Epoch [19/50], Loss: 0.5464, Train Acc: 0.7734
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6891, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6778, Train Acc: 0.6562
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6586, Train Acc: 0.6953
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.6350, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6210, Train Acc: 0.7422
Validation Acc: 0.7969
No improvement (1/10).
Epoch [7/50], Loss: 0.5982, Train Acc: 0.7578
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5815, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [9/50], Loss: 0.6123, Train Acc: 0.7266
Validation Acc: 0.8125
No improvement (2/10).
Epoch [10/50], Loss: 0.5741, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (3/10).
Epoch [11/50], Loss: 0.5903, Train Acc: 0.7734
Validation Acc: 0.7969
No improvement (4/10).
Epoch [12/50], Loss: 0.5924, Train Acc: 0.7617
Validation Acc: 0.7969
No improvement (5/10).
Epoch [13/50], Loss: 0.6016, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (6/10).
Epoch [14/50], Loss: 0.5860, Train Acc: 0.7695
Validation Acc: 0.7969
No improvement (7/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7656
No improvement (8/10).
Epoch [16/50], Loss: 0.5725, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [17/50], Loss: 0.5720, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.47s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.44s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.66s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00, 10.04s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:20<00:00, 10.13s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.20s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.17s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.06s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.81s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.61s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.61s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.04s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.19s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.32s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.47s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.56s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019772971468292492, 'rho': 6695.176311177033, 'd': 0.7346570369607585, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.10s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.24s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [13:24:35<20:01, 1201.43s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-906448>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-906448>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-923873>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-923873>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399985078, 'rho': 1179.1338138062267, 'd': 0.7827636158617528, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3575_1200/steady_state_trajectories/m_traj_3575.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2946.90

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3199, Train Acc: 0.5195
Validation Acc: 0.7188
Epoch [2/100], Loss: 0.9578, Train Acc: 0.6250
Validation Acc: 0.6719
No improvement (1/10).
Epoch [3/100], Loss: 0.7069, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (2/10).
Epoch [4/100], Loss: 0.6362, Train Acc: 0.6992
Validation Acc: 0.6406
No improvement (3/10).
Epoch [5/100], Loss: 0.5398, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (4/10).
Epoch [6/100], Loss: 0.4661, Train Acc: 0.8125
Validation Acc: 0.6250
No improvement (5/10).
Epoch [7/100], Loss: 0.4707, Train Acc: 0.7852
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.3525, Train Acc: 0.8359
Validation Acc: 0.6719
No improvement (7/10).
Epoch [9/100], Loss: 0.3633, Train Acc: 0.8398
Validation Acc: 0.6719
No improvement (8/10).
Epoch [10/100], Loss: 0.4186, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (9/10).
Epoch [11/100], Loss: 0.3335, Train Acc: 0.8633
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.51 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6992
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6649, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6101, Train Acc: 0.8750
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5774, Train Acc: 0.8945
Validation Acc: 0.8438
No improvement (1/10).
Epoch [6/50], Loss: 0.5665, Train Acc: 0.8242
Validation Acc: 0.5000
No improvement (2/10).
Epoch [7/50], Loss: 0.5776, Train Acc: 0.7734
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5491, Train Acc: 0.8086
Validation Acc: 0.8594
Epoch [9/50], Loss: 0.5623, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (1/10).
Epoch [10/50], Loss: 0.5576, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [12/50], Loss: 0.5498, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5518, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (2/10).
Epoch [14/50], Loss: 0.5562, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [15/50], Loss: 0.5434, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (1/10).
Epoch [16/50], Loss: 0.5378, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (2/10).
Epoch [17/50], Loss: 0.5283, Train Acc: 0.8711
Validation Acc: 0.8438
No improvement (3/10).
Epoch [18/50], Loss: 0.5259, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (4/10).
Epoch [19/50], Loss: 0.5362, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (5/10).
Epoch [20/50], Loss: 0.5186, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (6/10).
Epoch [21/50], Loss: 0.5192, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (7/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8477
Validation Acc: 0.8594
No improvement (8/10).
Epoch [23/50], Loss: 0.5217, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (9/10).
Epoch [24/50], Loss: 0.5322, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5156
Validation Acc: 0.4844
Epoch [2/50], Loss: 0.6865, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6696, Train Acc: 0.6875
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6464, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6222, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (1/10).
Epoch [6/50], Loss: 0.6021, Train Acc: 0.7539
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.5909, Train Acc: 0.7734
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.5900, Train Acc: 0.7734
Validation Acc: 0.7344
No improvement (4/10).
Epoch [9/50], Loss: 0.5971, Train Acc: 0.7539
Validation Acc: 0.7500
No improvement (5/10).
Epoch [10/50], Loss: 0.5971, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5923, Train Acc: 0.7695
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5821, Train Acc: 0.7773
Validation Acc: 0.7812
Epoch [13/50], Loss: 0.5794, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (1/10).
Epoch [14/50], Loss: 0.5734, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (2/10).
Epoch [15/50], Loss: 0.5683, Train Acc: 0.8008
Validation Acc: 0.7969
Epoch [16/50], Loss: 0.5687, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (1/10).
Epoch [17/50], Loss: 0.5683, Train Acc: 0.7852
Validation Acc: 0.5781
No improvement (2/10).
Epoch [18/50], Loss: 0.5581, Train Acc: 0.7891
Validation Acc: 0.7969
No improvement (3/10).
Epoch [19/50], Loss: 0.5482, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (4/10).
Epoch [20/50], Loss: 0.5471, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (5/10).
Epoch [21/50], Loss: 0.5466, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (6/10).
Epoch [22/50], Loss: 0.5453, Train Acc: 0.8086
Validation Acc: 0.7812
No improvement (7/10).
Epoch [23/50], Loss: 0.5581, Train Acc: 0.7930
Validation Acc: 0.7656
No improvement (8/10).
Epoch [24/50], Loss: 0.5506, Train Acc: 0.7969
Validation Acc: 0.7656
No improvement (9/10).
Epoch [25/50], Loss: 0.5501, Train Acc: 0.8008
Validation Acc: 0.7500
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.70 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 6717.6581396806905, 'sigma_b': 0.019706740589625894, 'd': 0.7346576069923381}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813800028, 'sigma_b': 0.06014543999825035, 'd': 0.7827636158614006}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.18s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.94s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.97s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.32
    - Variance: 3494.88

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1100.71
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.59 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3056, Train Acc: 0.5664
Validation Acc: 0.5469
Epoch [2/100], Loss: 0.8963, Train Acc: 0.6406
Validation Acc: 0.5312
No improvement (1/10).
Epoch [3/100], Loss: 0.7861, Train Acc: 0.6719
Validation Acc: 0.4531
No improvement (2/10).
Epoch [4/100], Loss: 0.6231, Train Acc: 0.7539
Validation Acc: 0.5000
No improvement (3/10).
Epoch [5/100], Loss: 0.4522, Train Acc: 0.8047
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.4176, Train Acc: 0.8203
Validation Acc: 0.5625
Epoch [7/100], Loss: 0.3831, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (1/10).
Epoch [8/100], Loss: 0.3462, Train Acc: 0.8477
Validation Acc: 0.5938
Epoch [9/100], Loss: 0.3392, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (1/10).
Epoch [10/100], Loss: 0.3310, Train Acc: 0.8555
Validation Acc: 0.5781
No improvement (2/10).
Epoch [11/100], Loss: 0.3228, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (3/10).
Epoch [12/100], Loss: 0.2954, Train Acc: 0.8594
Validation Acc: 0.5469
No improvement (4/10).
Epoch [13/100], Loss: 0.3205, Train Acc: 0.8477
Validation Acc: 0.5625
No improvement (5/10).
Epoch [14/100], Loss: 0.2274, Train Acc: 0.8984
Validation Acc: 0.5938
No improvement (6/10).
Epoch [15/100], Loss: 0.1881, Train Acc: 0.9062
Validation Acc: 0.6094
Epoch [16/100], Loss: 0.1777, Train Acc: 0.9219
Validation Acc: 0.6094
No improvement (1/10).
Epoch [17/100], Loss: 0.1899, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (2/10).
Epoch [18/100], Loss: 0.1723, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (3/10).
Epoch [19/100], Loss: 0.2001, Train Acc: 0.9180
Validation Acc: 0.5781
No improvement (4/10).
Epoch [20/100], Loss: 0.2111, Train Acc: 0.9102
Validation Acc: 0.5938
No improvement (5/10).
Epoch [21/100], Loss: 0.1456, Train Acc: 0.9336
Validation Acc: 0.6250
Epoch [22/100], Loss: 0.1353, Train Acc: 0.9570
Validation Acc: 0.5938
No improvement (1/10).
Epoch [23/100], Loss: 0.1733, Train Acc: 0.9414
Validation Acc: 0.5781
No improvement (2/10).
Epoch [24/100], Loss: 0.1508, Train Acc: 0.9375
Validation Acc: 0.5625
No improvement (3/10).
Epoch [25/100], Loss: 0.1292, Train Acc: 0.9609
Validation Acc: 0.5938
No improvement (4/10).
Epoch [26/100], Loss: 0.1062, Train Acc: 0.9609
Validation Acc: 0.6094
No improvement (5/10).
Epoch [27/100], Loss: 0.1168, Train Acc: 0.9453
Validation Acc: 0.6250
No improvement (6/10).
Epoch [28/100], Loss: 0.1040, Train Acc: 0.9688
Validation Acc: 0.6094
No improvement (7/10).
Epoch [29/100], Loss: 0.0964, Train Acc: 0.9688
Validation Acc: 0.5625
No improvement (8/10).
Epoch [30/100], Loss: 0.1031, Train Acc: 0.9648
Validation Acc: 0.6094
No improvement (9/10).
Epoch [31/100], Loss: 0.0939, Train Acc: 0.9727
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6858, Train Acc: 0.7383
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6641, Train Acc: 0.8398
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6173, Train Acc: 0.8242
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5924, Train Acc: 0.8438
Validation Acc: 0.9062
No improvement (1/10).
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8242
Validation Acc: 0.9375
Epoch [7/50], Loss: 0.5873, Train Acc: 0.7930
Validation Acc: 0.8594
No improvement (1/10).
Epoch [8/50], Loss: 0.5590, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [9/50], Loss: 0.5619, Train Acc: 0.8203
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5580, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (4/10).
Epoch [11/50], Loss: 0.5730, Train Acc: 0.7812
Validation Acc: 0.9219
No improvement (5/10).
Epoch [12/50], Loss: 0.5475, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5630, Train Acc: 0.8008
Validation Acc: 0.9375
No improvement (7/10).
Epoch [14/50], Loss: 0.5587, Train Acc: 0.7695
Validation Acc: 0.9375
No improvement (8/10).
Epoch [15/50], Loss: 0.5586, Train Acc: 0.8164
Validation Acc: 0.9375
No improvement (9/10).
Epoch [16/50], Loss: 0.5454, Train Acc: 0.8281
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.5117
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6912, Train Acc: 0.5781
Validation Acc: 0.4688
No improvement (1/10).
Epoch [3/50], Loss: 0.6854, Train Acc: 0.5977
Validation Acc: 0.5469
Epoch [4/50], Loss: 0.6708, Train Acc: 0.6406
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6552, Train Acc: 0.6875
Validation Acc: 0.5938
Epoch [6/50], Loss: 0.6432, Train Acc: 0.7070
Validation Acc: 0.5156
No improvement (1/10).
Epoch [7/50], Loss: 0.6128, Train Acc: 0.7500
Validation Acc: 0.8281
Epoch [8/50], Loss: 0.5831, Train Acc: 0.7852
Validation Acc: 0.9062
Epoch [9/50], Loss: 0.5624, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (1/10).
Epoch [10/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [11/50], Loss: 0.5470, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (3/10).
Epoch [12/50], Loss: 0.5500, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (4/10).
Epoch [13/50], Loss: 0.5490, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (5/10).
Epoch [14/50], Loss: 0.5367, Train Acc: 0.8242
Validation Acc: 0.8438
No improvement (6/10).
Epoch [15/50], Loss: 0.5381, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (7/10).
Epoch [16/50], Loss: 0.5392, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (8/10).
Epoch [17/50], Loss: 0.5549, Train Acc: 0.7852
Validation Acc: 0.8281
No improvement (9/10).
Epoch [18/50], Loss: 0.5706, Train Acc: 0.7539
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.68 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:08<00:08,  8.45s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.11s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.16s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.02s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.45s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.53s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.87s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.94s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.93s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:17<00:00,  8.98s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.18s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.20s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.70s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.47s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.50s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.39s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.15s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.34s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:10<00:10, 10.21s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.30s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:18<00:00,  9.44s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:11<00:11, 11.51s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.019706740589625894, 'rho': 6717.6581396806905, 'd': 0.7346576069923381, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.47s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [13:56:31<00:00, 1415.75s/it]Running Variance Ratio Simulations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [13:56:31<00:00, 1434.04s/it]
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999825035, 'rho': 1179.133813800028, 'd': 0.7827636158614006, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3587_1200/steady_state_trajectories/m_traj_3587.999999999998_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.18
    - Variance: 3469.30

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.45 ===
=== Random Forest Accuracy: 0.65 ===
=== Logistic Regression Accuracy: 0.50 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2906, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8561, Train Acc: 0.6016
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/100], Loss: 0.7843, Train Acc: 0.6797
Validation Acc: 0.5156
No improvement (2/10).
Epoch [4/100], Loss: 0.6809, Train Acc: 0.6992
Validation Acc: 0.5156
No improvement (3/10).
Epoch [5/100], Loss: 0.4624, Train Acc: 0.7891
Validation Acc: 0.5156
No improvement (4/10).
Epoch [6/100], Loss: 0.4098, Train Acc: 0.8086
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4273, Train Acc: 0.8125
Validation Acc: 0.5312
No improvement (6/10).
Epoch [8/100], Loss: 0.3558, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.3208, Train Acc: 0.8438
Validation Acc: 0.5781
No improvement (8/10).
Epoch [10/100], Loss: 0.3583, Train Acc: 0.8281
Validation Acc: 0.5469
No improvement (9/10).
Epoch [11/100], Loss: 0.3582, Train Acc: 0.8477
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5352
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.7148
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8594
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6114, Train Acc: 0.8672
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5825, Train Acc: 0.8789
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (1/10).
Epoch [7/50], Loss: 0.5781, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5671, Train Acc: 0.8242
Validation Acc: 0.5625
No improvement (1/10).
Epoch [10/50], Loss: 0.5533, Train Acc: 0.8438
Validation Acc: 0.7031
No improvement (2/10).
Epoch [11/50], Loss: 0.5564, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [12/50], Loss: 0.5365, Train Acc: 0.8516
Validation Acc: 0.8750
Epoch [13/50], Loss: 0.5505, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (1/10).
Epoch [14/50], Loss: 0.5439, Train Acc: 0.8086
Validation Acc: 0.7969
No improvement (2/10).
Epoch [15/50], Loss: 0.5584, Train Acc: 0.8203
Validation Acc: 0.7969
No improvement (3/10).
Epoch [16/50], Loss: 0.5324, Train Acc: 0.8320
Validation Acc: 0.8906
Epoch [17/50], Loss: 0.5256, Train Acc: 0.8555
Validation Acc: 0.9062
Epoch [18/50], Loss: 0.5301, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (1/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8047
Validation Acc: 0.8281
No improvement (2/10).
Epoch [20/50], Loss: 0.5189, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (3/10).
Epoch [21/50], Loss: 0.5178, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (4/10).
Epoch [22/50], Loss: 0.5174, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [23/50], Loss: 0.5043, Train Acc: 0.8359
Validation Acc: 0.9219
Epoch [24/50], Loss: 0.5232, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [25/50], Loss: 0.5027, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (2/10).
Epoch [26/50], Loss: 0.5139, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (3/10).
Epoch [27/50], Loss: 0.5009, Train Acc: 0.8281
Validation Acc: 0.9062
No improvement (4/10).
Epoch [28/50], Loss: 0.4998, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (5/10).
Epoch [29/50], Loss: 0.4948, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (6/10).
Epoch [30/50], Loss: 0.4854, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [31/50], Loss: 0.4932, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (8/10).
Epoch [32/50], Loss: 0.4874, Train Acc: 0.8672
Validation Acc: 0.8906
No improvement (9/10).
Epoch [33/50], Loss: 0.4887, Train Acc: 0.8438
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6933, Train Acc: 0.4883
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6910, Train Acc: 0.6055
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6851, Train Acc: 0.6562
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6664, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6354, Train Acc: 0.7617
Validation Acc: 0.6719
No improvement (2/10).
Epoch [6/50], Loss: 0.6594, Train Acc: 0.6289
Validation Acc: 0.6094
No improvement (3/10).
Epoch [7/50], Loss: 0.6421, Train Acc: 0.6641
Validation Acc: 0.7031
No improvement (4/10).
Epoch [8/50], Loss: 0.6371, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (5/10).
Epoch [9/50], Loss: 0.6314, Train Acc: 0.6875
Validation Acc: 0.7031
No improvement (6/10).
Epoch [10/50], Loss: 0.6245, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (7/10).
Epoch [11/50], Loss: 0.5986, Train Acc: 0.7656
Validation Acc: 0.7344
No improvement (8/10).
Epoch [12/50], Loss: 0.6010, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (9/10).
Epoch [13/50], Loss: 0.5909, Train Acc: 0.7695
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.75 ===

âš ï¸ Variance ratios where STRESS solution failed:
  Index 15, Ratio = 2.8000
  Index 21, Ratio = 2.8600
  Index 23, Ratio = 2.8800
  Index 25, Ratio = 2.9000
