Running Variance Ratio Simulations:   0%|          | 0/42 [00:00<?, ?it/s]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
[STRESS] âœ… Found: {'rho': 5795.902957972253, 'sigma_b': 0.0228439520955587, 'd': 0.7346306158358888}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138059741, 'sigma_b': 0.06014543999849757, 'd': 0.7827636158617448}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.98s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.82
    - Variance: 2914.54

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.82
    - Variance: 1168.54
=== SVM (RBF Kernel) Classification Accuracy: 0.66 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.79 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2642, Train Acc: 0.5703
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.9541, Train Acc: 0.6211
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.6885, Train Acc: 0.6953
Validation Acc: 0.5000
No improvement (2/10).
Epoch [4/100], Loss: 0.7112, Train Acc: 0.6875
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.5947, Train Acc: 0.7461
Validation Acc: 0.5312
No improvement (4/10).
Epoch [6/100], Loss: 0.5164, Train Acc: 0.7656
Validation Acc: 0.5312
No improvement (5/10).
Epoch [7/100], Loss: 0.4565, Train Acc: 0.7578
Validation Acc: 0.5156
No improvement (6/10).
Epoch [8/100], Loss: 0.3765, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (7/10).
Epoch [9/100], Loss: 0.4319, Train Acc: 0.8164
Validation Acc: 0.5156
No improvement (8/10).
Epoch [10/100], Loss: 0.3264, Train Acc: 0.8359
Validation Acc: 0.5312
No improvement (9/10).
Epoch [11/100], Loss: 0.3521, Train Acc: 0.8477
Validation Acc: 0.5312
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.4844
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6876, Train Acc: 0.6562
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6728, Train Acc: 0.7891
Validation Acc: 0.6250
Epoch [4/50], Loss: 0.6288, Train Acc: 0.8164
Validation Acc: 0.6719
Epoch [5/50], Loss: 0.6033, Train Acc: 0.8438
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.5846, Train Acc: 0.8125
Validation Acc: 0.7344
Epoch [7/50], Loss: 0.5843, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [8/50], Loss: 0.5683, Train Acc: 0.7734
Validation Acc: 0.8125
No improvement (1/10).
Epoch [9/50], Loss: 0.5720, Train Acc: 0.8008
Validation Acc: 0.8750
Epoch [10/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (1/10).
Epoch [11/50], Loss: 0.5575, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (2/10).
Epoch [12/50], Loss: 0.5676, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (3/10).
Epoch [13/50], Loss: 0.5730, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (4/10).
Epoch [14/50], Loss: 0.5842, Train Acc: 0.7305
Validation Acc: 0.8594
No improvement (5/10).
Epoch [15/50], Loss: 0.5539, Train Acc: 0.7969
Validation Acc: 0.9062
Epoch [16/50], Loss: 0.5434, Train Acc: 0.8125
Validation Acc: 0.8750
No improvement (1/10).
Epoch [17/50], Loss: 0.5468, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (2/10).
Epoch [18/50], Loss: 0.5349, Train Acc: 0.8438
Validation Acc: 0.9062
No improvement (3/10).
Epoch [19/50], Loss: 0.5247, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (4/10).
Epoch [20/50], Loss: 0.5335, Train Acc: 0.8555
Validation Acc: 0.8906
No improvement (5/10).
Epoch [21/50], Loss: 0.5328, Train Acc: 0.8359
Validation Acc: 0.8906
No improvement (6/10).
Epoch [22/50], Loss: 0.5416, Train Acc: 0.8672
Validation Acc: 0.9062
No improvement (7/10).
Epoch [23/50], Loss: 0.5296, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (8/10).
Epoch [24/50], Loss: 0.5315, Train Acc: 0.8438
Validation Acc: 0.9062
No improvement (9/10).
Epoch [25/50], Loss: 0.5365, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5312
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6889, Train Acc: 0.6211
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6792, Train Acc: 0.6367
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6729, Train Acc: 0.6250
Validation Acc: 0.6094
No improvement (1/10).
Epoch [5/50], Loss: 0.6634, Train Acc: 0.6445
Validation Acc: 0.6562
Epoch [6/50], Loss: 0.6602, Train Acc: 0.6523
Validation Acc: 0.6719
Epoch [7/50], Loss: 0.6538, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.6515, Train Acc: 0.6602
Validation Acc: 0.6406
No improvement (2/10).
Epoch [9/50], Loss: 0.6434, Train Acc: 0.6641
Validation Acc: 0.6875
Epoch [10/50], Loss: 0.6356, Train Acc: 0.6914
Validation Acc: 0.7812
Epoch [11/50], Loss: 0.6322, Train Acc: 0.6836
Validation Acc: 0.7500
No improvement (1/10).
Epoch [12/50], Loss: 0.6013, Train Acc: 0.7539
Validation Acc: 0.7969
Epoch [13/50], Loss: 0.5843, Train Acc: 0.7695
Validation Acc: 0.8438
Epoch [14/50], Loss: 0.6135, Train Acc: 0.7461
Validation Acc: 0.8281
No improvement (1/10).
Epoch [15/50], Loss: 0.6784, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (2/10).
Epoch [16/50], Loss: 0.6263, Train Acc: 0.7031
Validation Acc: 0.6406
No improvement (3/10).
Epoch [17/50], Loss: 0.6885, Train Acc: 0.5938
Validation Acc: 0.5000
No improvement (4/10).
Epoch [18/50], Loss: 0.7364, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (5/10).
Epoch [19/50], Loss: 0.7330, Train Acc: 0.5117
Validation Acc: 0.5000
No improvement (6/10).
Epoch [20/50], Loss: 0.7361, Train Acc: 0.5000
Validation Acc: 0.5000
No improvement (7/10).
Epoch [21/50], Loss: 0.7188, Train Acc: 0.5234
Validation Acc: 0.5000
No improvement (8/10).
Epoch [22/50], Loss: 0.7245, Train Acc: 0.5078
Validation Acc: 0.5000
No improvement (9/10).
Epoch [23/50], Loss: 0.7269, Train Acc: 0.5039
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.50 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.93s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.0228439520955587, 'rho': 5795.902957972253, 'd': 0.7346306158358888, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   2%|â–         | 1/42 [24:23<16:40:11, 1463.68s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
<lambdifygenerated-36454>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-36454>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849757, 'rho': 1179.1338138059741, 'd': 0.7827636158617448, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3095_1200/steady_state_trajectories/m_traj_3095.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.66
    - Variance: 2949.50

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3552, Train Acc: 0.4805
Validation Acc: 0.6562
Epoch [2/100], Loss: 0.8409, Train Acc: 0.6523
Validation Acc: 0.6250
No improvement (1/10).
Epoch [3/100], Loss: 0.7387, Train Acc: 0.6602
Validation Acc: 0.6094
No improvement (2/10).
Epoch [4/100], Loss: 0.7457, Train Acc: 0.6797
Validation Acc: 0.6250
No improvement (3/10).
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.5356, Train Acc: 0.7852
Validation Acc: 0.5938
No improvement (5/10).
Epoch [7/100], Loss: 0.4743, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (6/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (7/10).
Epoch [9/100], Loss: 0.4207, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [10/100], Loss: 0.4430, Train Acc: 0.8008
Validation Acc: 0.6406
No improvement (9/10).
Epoch [11/100], Loss: 0.3518, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6865, Train Acc: 0.7227
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6644, Train Acc: 0.8438
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6134, Train Acc: 0.8555
Validation Acc: 0.7656
Epoch [5/50], Loss: 0.5836, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5745, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.5000
No improvement (1/10).
Epoch [8/50], Loss: 0.5671, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [9/50], Loss: 0.5910, Train Acc: 0.7695
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5799, Train Acc: 0.7891
Validation Acc: 0.8906
Epoch [11/50], Loss: 0.5657, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (1/10).
Epoch [12/50], Loss: 0.5569, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (2/10).
Epoch [13/50], Loss: 0.5500, Train Acc: 0.7969
Validation Acc: 0.8438
No improvement (3/10).
Epoch [14/50], Loss: 0.5464, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5318, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5272, Train Acc: 0.8203
Validation Acc: 0.8906
No improvement (6/10).
Epoch [17/50], Loss: 0.5146, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5215, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5300, Train Acc: 0.8008
Validation Acc: 0.8594
No improvement (9/10).
Epoch [20/50], Loss: 0.5199, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.91 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6887, Train Acc: 0.6211
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6781, Train Acc: 0.6484
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6653, Train Acc: 0.6523
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6568, Train Acc: 0.6836
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6380, Train Acc: 0.6836
Validation Acc: 0.7656
No improvement (1/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7031
Validation Acc: 0.7344
No improvement (2/10).
Epoch [8/50], Loss: 0.6296, Train Acc: 0.6758
Validation Acc: 0.7812
No improvement (3/10).
Epoch [9/50], Loss: 0.5993, Train Acc: 0.7383
Validation Acc: 0.7969
No improvement (4/10).
Epoch [10/50], Loss: 0.5973, Train Acc: 0.7227
Validation Acc: 0.7344
No improvement (5/10).
Epoch [11/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (6/10).
Epoch [12/50], Loss: 0.6049, Train Acc: 0.7070
Validation Acc: 0.7344
No improvement (7/10).
Epoch [13/50], Loss: 0.5962, Train Acc: 0.7539
Validation Acc: 0.7812
No improvement (8/10).
Epoch [14/50], Loss: 0.6080, Train Acc: 0.7266
Validation Acc: 0.7969
No improvement (9/10).
Epoch [15/50], Loss: 0.5990, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
[STRESS] âœ… Found: {'rho': 5818.384797787495, 'sigma_b': 0.022755596610530164, 'd': 0.7346313757269837}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138056506, 'sigma_b': 0.0601454399984868, 'd': 0.7827636158617403}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.09s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.30
    - Variance: 3156.19

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1078.58
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.74 ===
=== Logistic Regression Accuracy: 0.55 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2742, Train Acc: 0.5312
Validation Acc: 0.4219
Epoch [2/100], Loss: 0.9561, Train Acc: 0.5977
Validation Acc: 0.5156
Epoch [3/100], Loss: 0.6699, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [4/100], Loss: 0.5642, Train Acc: 0.7422
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5583, Train Acc: 0.7695
Validation Acc: 0.4844
No improvement (3/10).
Epoch [6/100], Loss: 0.5078, Train Acc: 0.7617
Validation Acc: 0.4688
No improvement (4/10).
Epoch [7/100], Loss: 0.4526, Train Acc: 0.7695
Validation Acc: 0.4531
No improvement (5/10).
Epoch [8/100], Loss: 0.3871, Train Acc: 0.8125
Validation Acc: 0.4531
No improvement (6/10).
Epoch [9/100], Loss: 0.3406, Train Acc: 0.8359
Validation Acc: 0.4375
No improvement (7/10).
Epoch [10/100], Loss: 0.2757, Train Acc: 0.8711
Validation Acc: 0.4531
No improvement (8/10).
Epoch [11/100], Loss: 0.3044, Train Acc: 0.8711
Validation Acc: 0.4531
No improvement (9/10).
Epoch [12/100], Loss: 0.3228, Train Acc: 0.8438
Validation Acc: 0.4688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.55 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5000
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6869, Train Acc: 0.6875
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6687, Train Acc: 0.8438
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6152, Train Acc: 0.8555
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.5804, Train Acc: 0.8828
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5706, Train Acc: 0.8516
Validation Acc: 0.9062
Epoch [7/50], Loss: 0.5751, Train Acc: 0.7969
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.5622, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (1/10).
Epoch [9/50], Loss: 0.5664, Train Acc: 0.8008
Validation Acc: 0.6719
No improvement (2/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (3/10).
Epoch [11/50], Loss: 0.5594, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (4/10).
Epoch [12/50], Loss: 0.5354, Train Acc: 0.8477
Validation Acc: 0.9375
No improvement (5/10).
Epoch [13/50], Loss: 0.5396, Train Acc: 0.8281
Validation Acc: 0.9688
Epoch [14/50], Loss: 0.5310, Train Acc: 0.8203
Validation Acc: 0.9531
No improvement (1/10).
Epoch [15/50], Loss: 0.5370, Train Acc: 0.8438
Validation Acc: 0.9219
No improvement (2/10).
Epoch [16/50], Loss: 0.5152, Train Acc: 0.8633
Validation Acc: 0.9375
No improvement (3/10).
Epoch [17/50], Loss: 0.5170, Train Acc: 0.8945
Validation Acc: 0.9688
No improvement (4/10).
Epoch [18/50], Loss: 0.5380, Train Acc: 0.8320
Validation Acc: 0.9531
No improvement (5/10).
Epoch [19/50], Loss: 0.5229, Train Acc: 0.8477
Validation Acc: 0.9688
No improvement (6/10).
Epoch [20/50], Loss: 0.5161, Train Acc: 0.8672
Validation Acc: 0.9688
No improvement (7/10).
Epoch [21/50], Loss: 0.5311, Train Acc: 0.8320
Validation Acc: 0.9688
No improvement (8/10).
Epoch [22/50], Loss: 0.5374, Train Acc: 0.8516
Validation Acc: 0.9688
No improvement (9/10).
Epoch [23/50], Loss: 0.5248, Train Acc: 0.8594
Validation Acc: 0.9688
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.90 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6172
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6800, Train Acc: 0.6289
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6650, Train Acc: 0.6406
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6451, Train Acc: 0.7070
Validation Acc: 0.8125
Epoch [6/50], Loss: 0.6110, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6024, Train Acc: 0.7578
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.6223, Train Acc: 0.7148
Validation Acc: 0.5312
No improvement (3/10).
Epoch [9/50], Loss: 0.6644, Train Acc: 0.6250
Validation Acc: 0.6406
No improvement (4/10).
Epoch [10/50], Loss: 0.6530, Train Acc: 0.6406
Validation Acc: 0.6406
No improvement (5/10).
Epoch [11/50], Loss: 0.6253, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (6/10).
Epoch [12/50], Loss: 0.6184, Train Acc: 0.7109
Validation Acc: 0.6875
No improvement (7/10).
Epoch [13/50], Loss: 0.6185, Train Acc: 0.7031
Validation Acc: 0.6875
No improvement (8/10).
Epoch [14/50], Loss: 0.6120, Train Acc: 0.7148
Validation Acc: 0.6875
No improvement (9/10).
Epoch [15/50], Loss: 0.6068, Train Acc: 0.7227
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.68 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.94s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.83s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.83s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.89s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.57s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.81s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.55s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.79s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.90s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.01s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022755596610530164, 'rho': 5818.384797787495, 'd': 0.7346313757269837, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   5%|â–         | 2/42 [1:02:46<21:44:49, 1957.24s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3107_1200/steady_state_trajectories/m_traj_3107.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 3093.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.51 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3840, Train Acc: 0.5273
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8633, Train Acc: 0.6602
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.8300, Train Acc: 0.6758
Validation Acc: 0.5312
No improvement (1/10).
Epoch [4/100], Loss: 0.7692, Train Acc: 0.6992
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.5483, Train Acc: 0.7578
Validation Acc: 0.6094
No improvement (3/10).
Epoch [6/100], Loss: 0.5325, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.5557, Train Acc: 0.7461
Validation Acc: 0.6094
No improvement (5/10).
Epoch [8/100], Loss: 0.3716, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [9/100], Loss: 0.4488, Train Acc: 0.8008
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.4157, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (8/10).
Epoch [11/100], Loss: 0.3954, Train Acc: 0.8242
Validation Acc: 0.6094
No improvement (9/10).
Epoch [12/100], Loss: 0.3845, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.61 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.7070
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6657, Train Acc: 0.8320
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8555
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5828, Train Acc: 0.8711
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5770, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [7/50], Loss: 0.5797, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (1/10).
Epoch [8/50], Loss: 0.5586, Train Acc: 0.8047
Validation Acc: 0.9219
No improvement (2/10).
Epoch [9/50], Loss: 0.5612, Train Acc: 0.8164
Validation Acc: 0.9219
No improvement (3/10).
Epoch [10/50], Loss: 0.5574, Train Acc: 0.8164
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5685, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (5/10).
Epoch [12/50], Loss: 0.5469, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (6/10).
Epoch [13/50], Loss: 0.5550, Train Acc: 0.7930
Validation Acc: 0.9219
No improvement (7/10).
Epoch [14/50], Loss: 0.5649, Train Acc: 0.7734
Validation Acc: 0.9219
No improvement (8/10).
Epoch [15/50], Loss: 0.5514, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [16/50], Loss: 0.5405, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.85 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6885, Train Acc: 0.6133
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6768, Train Acc: 0.6719
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6616, Train Acc: 0.6680
Validation Acc: 0.5156
No improvement (1/10).
Epoch [5/50], Loss: 0.6408, Train Acc: 0.7148
Validation Acc: 0.5156
No improvement (2/10).
Epoch [6/50], Loss: 0.6204, Train Acc: 0.7344
Validation Acc: 0.6875
No improvement (3/10).
Epoch [7/50], Loss: 0.6225, Train Acc: 0.7148
Validation Acc: 0.7812
Epoch [8/50], Loss: 0.6039, Train Acc: 0.7461
Validation Acc: 0.7500
No improvement (1/10).
Epoch [9/50], Loss: 0.6008, Train Acc: 0.7539
Validation Acc: 0.8281
Epoch [10/50], Loss: 0.5851, Train Acc: 0.7617
Validation Acc: 0.8281
No improvement (1/10).
Epoch [11/50], Loss: 0.5700, Train Acc: 0.7969
Validation Acc: 0.8125
No improvement (2/10).
Epoch [12/50], Loss: 0.5696, Train Acc: 0.7930
Validation Acc: 0.9062
Epoch [13/50], Loss: 0.5319, Train Acc: 0.8398
Validation Acc: 0.9531
Epoch [14/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.9062
No improvement (1/10).
Epoch [15/50], Loss: 0.5721, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (2/10).
Epoch [16/50], Loss: 0.5807, Train Acc: 0.7734
Validation Acc: 0.7031
No improvement (3/10).
Epoch [17/50], Loss: 0.5457, Train Acc: 0.8164
Validation Acc: 0.6719
No improvement (4/10).
Epoch [18/50], Loss: 0.5661, Train Acc: 0.7812
Validation Acc: 0.8281
No improvement (5/10).
Epoch [19/50], Loss: 0.5528, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (6/10).
Epoch [20/50], Loss: 0.5499, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (7/10).
Epoch [21/50], Loss: 0.5571, Train Acc: 0.7812
Validation Acc: 0.8906
No improvement (8/10).
Epoch [22/50], Loss: 0.5365, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (9/10).
Epoch [23/50], Loss: 0.5332, Train Acc: 0.8164
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.75 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
[STRESS] âœ… Found: {'rho': 5840.866637398382, 'sigma_b': 0.022667921974224795, 'd': 0.7346321297792521}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138058743, 'sigma_b': 0.06014543999849509, 'd': 0.7827636158617438}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.48
    - Variance: 3209.49

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.51
    - Variance: 1056.90
=== SVM (RBF Kernel) Classification Accuracy: 0.80 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.62 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2794, Train Acc: 0.5078
Validation Acc: 0.6250
Epoch [2/100], Loss: 0.8785, Train Acc: 0.6406
Validation Acc: 0.6406
Epoch [3/100], Loss: 0.6239, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (1/10).
Epoch [4/100], Loss: 0.5931, Train Acc: 0.7656
Validation Acc: 0.6094
No improvement (2/10).
Epoch [5/100], Loss: 0.4818, Train Acc: 0.7852
Validation Acc: 0.6250
No improvement (3/10).
Epoch [6/100], Loss: 0.5483, Train Acc: 0.7617
Validation Acc: 0.5781
No improvement (4/10).
Epoch [7/100], Loss: 0.4611, Train Acc: 0.7773
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.4455, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (6/10).
Epoch [9/100], Loss: 0.4551, Train Acc: 0.8086
Validation Acc: 0.6094
No improvement (7/10).
Epoch [10/100], Loss: 0.3159, Train Acc: 0.8398
Validation Acc: 0.5469
No improvement (8/10).
Epoch [11/100], Loss: 0.2969, Train Acc: 0.8711
Validation Acc: 0.5469
No improvement (9/10).
Epoch [12/100], Loss: 0.4109, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6877, Train Acc: 0.6641
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6691, Train Acc: 0.8203
Validation Acc: 0.8594
Epoch [4/50], Loss: 0.6278, Train Acc: 0.8320
Validation Acc: 0.8281
No improvement (1/10).
Epoch [5/50], Loss: 0.5992, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (2/10).
Epoch [6/50], Loss: 0.5835, Train Acc: 0.8047
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/50], Loss: 0.5922, Train Acc: 0.7383
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/50], Loss: 0.5682, Train Acc: 0.7969
Validation Acc: 0.7344
No improvement (5/10).
Epoch [9/50], Loss: 0.5736, Train Acc: 0.7891
Validation Acc: 0.6094
No improvement (6/10).
Epoch [10/50], Loss: 0.5716, Train Acc: 0.8008
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/50], Loss: 0.5665, Train Acc: 0.7930
Validation Acc: 0.7500
No improvement (8/10).
Epoch [12/50], Loss: 0.5595, Train Acc: 0.8008
Validation Acc: 0.8438
No improvement (9/10).
Epoch [13/50], Loss: 0.5708, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.82 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6925, Train Acc: 0.5508
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6868, Train Acc: 0.6602
Validation Acc: 0.5625
Epoch [3/50], Loss: 0.6731, Train Acc: 0.6641
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6554, Train Acc: 0.6836
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6336, Train Acc: 0.7109
Validation Acc: 0.7500
Epoch [6/50], Loss: 0.6012, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.5947, Train Acc: 0.7617
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5915, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5961, Train Acc: 0.7422
Validation Acc: 0.7344
No improvement (4/10).
Epoch [10/50], Loss: 0.6113, Train Acc: 0.7227
Validation Acc: 0.7500
No improvement (5/10).
Epoch [11/50], Loss: 0.6124, Train Acc: 0.7109
Validation Acc: 0.5000
No improvement (6/10).
Epoch [12/50], Loss: 0.6228, Train Acc: 0.6797
Validation Acc: 0.7188
No improvement (7/10).
Epoch [13/50], Loss: 0.5775, Train Acc: 0.7773
Validation Acc: 0.7500
No improvement (8/10).
Epoch [14/50], Loss: 0.5810, Train Acc: 0.7695
Validation Acc: 0.7344
No improvement (9/10).
Epoch [15/50], Loss: 0.5785, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.72 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.44s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.92s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.35s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.35s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.89s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.31s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.21s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.88s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.93s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.17s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022667921974224795, 'rho': 5840.866637398382, 'd': 0.7346321297792521, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.81s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.87s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:   7%|â–‹         | 3/42 [1:32:54<20:27:49, 1888.96s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849509, 'rho': 1179.1338138058743, 'd': 0.7827636158617438, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3119_1200/steady_state_trajectories/m_traj_3119.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.09
    - Variance: 3518.33

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.59 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2903, Train Acc: 0.5000
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.7355, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [3/100], Loss: 0.7357, Train Acc: 0.7031
Validation Acc: 0.6250
Epoch [4/100], Loss: 0.6623, Train Acc: 0.7148
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5515, Train Acc: 0.7305
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.5206, Train Acc: 0.7734
Validation Acc: 0.5781
No improvement (3/10).
Epoch [7/100], Loss: 0.4308, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (4/10).
Epoch [8/100], Loss: 0.3700, Train Acc: 0.8047
Validation Acc: 0.6094
No improvement (5/10).
Epoch [9/100], Loss: 0.4121, Train Acc: 0.8164
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3848, Train Acc: 0.8281
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3706, Train Acc: 0.8359
Validation Acc: 0.5469
No improvement (8/10).
Epoch [12/100], Loss: 0.3143, Train Acc: 0.8516
Validation Acc: 0.5625
No improvement (9/10).
Epoch [13/100], Loss: 0.2944, Train Acc: 0.8555
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.56 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6914
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6708, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6286, Train Acc: 0.8047
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.6021, Train Acc: 0.8320
Validation Acc: 0.7969
No improvement (1/10).
Epoch [6/50], Loss: 0.5957, Train Acc: 0.7773
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.6011, Train Acc: 0.7539
Validation Acc: 0.6250
No improvement (1/10).
Epoch [8/50], Loss: 0.5873, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [9/50], Loss: 0.5757, Train Acc: 0.7891
Validation Acc: 0.8125
No improvement (3/10).
Epoch [10/50], Loss: 0.5758, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (4/10).
Epoch [11/50], Loss: 0.5677, Train Acc: 0.8086
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (6/10).
Epoch [13/50], Loss: 0.5648, Train Acc: 0.7891
Validation Acc: 0.8438
No improvement (7/10).
Epoch [14/50], Loss: 0.5726, Train Acc: 0.7812
Validation Acc: 0.8125
No improvement (8/10).
Epoch [15/50], Loss: 0.5609, Train Acc: 0.8047
Validation Acc: 0.8125
No improvement (9/10).
Epoch [16/50], Loss: 0.5547, Train Acc: 0.8086
Validation Acc: 0.8125
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6867, Train Acc: 0.6523
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6587, Train Acc: 0.6758
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.6532, Train Acc: 0.6523
Validation Acc: 0.6562
No improvement (1/10).
Epoch [6/50], Loss: 0.6382, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (2/10).
Epoch [7/50], Loss: 0.6305, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [8/50], Loss: 0.6308, Train Acc: 0.6875
Validation Acc: 0.7188
No improvement (1/10).
Epoch [9/50], Loss: 0.6193, Train Acc: 0.7188
Validation Acc: 0.7969
Epoch [10/50], Loss: 0.6063, Train Acc: 0.7109
Validation Acc: 0.7031
No improvement (1/10).
Epoch [11/50], Loss: 0.6192, Train Acc: 0.6797
Validation Acc: 0.6719
No improvement (2/10).
Epoch [12/50], Loss: 0.6051, Train Acc: 0.6992
Validation Acc: 0.6875
No improvement (3/10).
Epoch [13/50], Loss: 0.5968, Train Acc: 0.6953
Validation Acc: 0.7969
No improvement (4/10).
Epoch [14/50], Loss: 0.5929, Train Acc: 0.7227
Validation Acc: 0.7812
No improvement (5/10).
Epoch [15/50], Loss: 0.5974, Train Acc: 0.7266
Validation Acc: 0.7656
No improvement (6/10).
Epoch [16/50], Loss: 0.5859, Train Acc: 0.7422
Validation Acc: 0.8125
Epoch [17/50], Loss: 0.5686, Train Acc: 0.7695
Validation Acc: 0.7500
No improvement (1/10).
Epoch [18/50], Loss: 0.5598, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [19/50], Loss: 0.5336, Train Acc: 0.8164
Validation Acc: 0.7500
No improvement (3/10).
Epoch [20/50], Loss: 0.5532, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (4/10).
Epoch [21/50], Loss: 0.5460, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (5/10).
Epoch [22/50], Loss: 0.5482, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (6/10).
Epoch [23/50], Loss: 0.5322, Train Acc: 0.8242
Validation Acc: 0.7188
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8008
Validation Acc: 0.7188
No improvement (8/10).
Epoch [25/50], Loss: 0.5199, Train Acc: 0.8438
Validation Acc: 0.7344
No improvement (9/10).
Epoch [26/50], Loss: 0.5464, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.84 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
[STRESS] âœ… Found: {'rho': 5863.348476641109, 'sigma_b': 0.022580920346634288, 'd': 0.7346328780588599}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138056506, 'sigma_b': 0.0601454399984868, 'd': 0.7827636158617403}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.28s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.30
    - Variance: 2728.83

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1078.58
=== SVM (RBF Kernel) Classification Accuracy: 0.62 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.49 ===
=== Random Forest Accuracy: 0.81 ===
=== Logistic Regression Accuracy: 0.42 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2011, Train Acc: 0.5508
Validation Acc: 0.6406
Epoch [2/100], Loss: 0.8504, Train Acc: 0.6484
Validation Acc: 0.6875
Epoch [3/100], Loss: 0.6527, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (1/10).
Epoch [4/100], Loss: 0.5659, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (2/10).
Epoch [5/100], Loss: 0.4680, Train Acc: 0.8086
Validation Acc: 0.6875
No improvement (3/10).
Epoch [6/100], Loss: 0.4504, Train Acc: 0.7930
Validation Acc: 0.6719
No improvement (4/10).
Epoch [7/100], Loss: 0.3955, Train Acc: 0.8320
Validation Acc: 0.6719
No improvement (5/10).
Epoch [8/100], Loss: 0.3176, Train Acc: 0.8750
Validation Acc: 0.6562
No improvement (6/10).
Epoch [9/100], Loss: 0.3779, Train Acc: 0.8242
Validation Acc: 0.6875
No improvement (7/10).
Epoch [10/100], Loss: 0.2618, Train Acc: 0.8828
Validation Acc: 0.6406
No improvement (8/10).
Epoch [11/100], Loss: 0.2958, Train Acc: 0.8750
Validation Acc: 0.6562
No improvement (9/10).
Epoch [12/100], Loss: 0.2526, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.53 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6694, Train Acc: 0.8086
Validation Acc: 0.8906
Epoch [4/50], Loss: 0.6206, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [5/50], Loss: 0.5801, Train Acc: 0.8828
Validation Acc: 0.8750
No improvement (1/10).
Epoch [6/50], Loss: 0.5747, Train Acc: 0.8477
Validation Acc: 0.7812
No improvement (2/10).
Epoch [7/50], Loss: 0.5802, Train Acc: 0.7734
Validation Acc: 0.6875
No improvement (3/10).
Epoch [8/50], Loss: 0.5643, Train Acc: 0.8047
Validation Acc: 0.7031
No improvement (4/10).
Epoch [9/50], Loss: 0.5707, Train Acc: 0.7969
Validation Acc: 0.8281
No improvement (5/10).
Epoch [10/50], Loss: 0.5667, Train Acc: 0.7812
Validation Acc: 0.9688
Epoch [11/50], Loss: 0.5588, Train Acc: 0.8242
Validation Acc: 0.9375
No improvement (1/10).
Epoch [12/50], Loss: 0.5499, Train Acc: 0.8047
Validation Acc: 0.9375
No improvement (2/10).
Epoch [13/50], Loss: 0.5498, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (3/10).
Epoch [14/50], Loss: 0.5589, Train Acc: 0.7695
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.7812
Validation Acc: 0.8750
No improvement (5/10).
Epoch [16/50], Loss: 0.5411, Train Acc: 0.8047
Validation Acc: 0.9375
No improvement (6/10).
Epoch [17/50], Loss: 0.5354, Train Acc: 0.8398
Validation Acc: 0.9688
No improvement (7/10).
Epoch [18/50], Loss: 0.5466, Train Acc: 0.7891
Validation Acc: 0.9375
No improvement (8/10).
Epoch [19/50], Loss: 0.5420, Train Acc: 0.8047
Validation Acc: 0.9375
No improvement (9/10).
Epoch [20/50], Loss: 0.5306, Train Acc: 0.8359
Validation Acc: 0.9219
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6925, Train Acc: 0.5625
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6866, Train Acc: 0.6367
Validation Acc: 0.6562
Epoch [3/50], Loss: 0.6746, Train Acc: 0.6562
Validation Acc: 0.6562
No improvement (1/10).
Epoch [4/50], Loss: 0.6605, Train Acc: 0.6641
Validation Acc: 0.6719
Epoch [5/50], Loss: 0.6407, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [6/50], Loss: 0.6401, Train Acc: 0.6758
Validation Acc: 0.7344
Epoch [7/50], Loss: 0.6244, Train Acc: 0.7070
Validation Acc: 0.7188
No improvement (1/10).
Epoch [8/50], Loss: 0.6046, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (2/10).
Epoch [9/50], Loss: 0.5719, Train Acc: 0.7930
Validation Acc: 0.8125
Epoch [10/50], Loss: 0.5771, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (1/10).
Epoch [11/50], Loss: 0.5786, Train Acc: 0.7695
Validation Acc: 0.7031
No improvement (2/10).
Epoch [12/50], Loss: 0.6148, Train Acc: 0.7031
Validation Acc: 0.6094
No improvement (3/10).
Epoch [13/50], Loss: 0.6773, Train Acc: 0.5781
Validation Acc: 0.5938
No improvement (4/10).
Epoch [14/50], Loss: 0.6741, Train Acc: 0.5508
Validation Acc: 0.5156
No improvement (5/10).
Epoch [15/50], Loss: 0.6512, Train Acc: 0.5664
Validation Acc: 0.5469
No improvement (6/10).
Epoch [16/50], Loss: 0.6321, Train Acc: 0.6016
Validation Acc: 0.5625
No improvement (7/10).
Epoch [17/50], Loss: 0.5996, Train Acc: 0.6641
Validation Acc: 0.5781
No improvement (8/10).
Epoch [18/50], Loss: 0.5838, Train Acc: 0.6836
Validation Acc: 0.6094
No improvement (9/10).
Epoch [19/50], Loss: 0.5770, Train Acc: 0.7266
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.68 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.80s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.76s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.85s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.77s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.59s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.79s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022580920346634288, 'rho': 5863.348476641109, 'd': 0.7346328780588599, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  10%|â–‰         | 4/42 [2:10:45<21:31:50, 2039.76s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-164788>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-164788>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3131_1200/steady_state_trajectories/m_traj_3131.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.38
    - Variance: 2795.20

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.65 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.62 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3944, Train Acc: 0.5117
Validation Acc: 0.5938
Epoch [2/100], Loss: 0.8580, Train Acc: 0.6367
Validation Acc: 0.5625
No improvement (1/10).
Epoch [3/100], Loss: 0.8393, Train Acc: 0.6758
Validation Acc: 0.6562
Epoch [4/100], Loss: 0.6511, Train Acc: 0.6992
Validation Acc: 0.6562
No improvement (1/10).
Epoch [5/100], Loss: 0.6469, Train Acc: 0.7227
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5747, Train Acc: 0.7578
Validation Acc: 0.6562
No improvement (3/10).
Epoch [7/100], Loss: 0.5052, Train Acc: 0.8008
Validation Acc: 0.6250
No improvement (4/10).
Epoch [8/100], Loss: 0.4256, Train Acc: 0.8164
Validation Acc: 0.6562
No improvement (5/10).
Epoch [9/100], Loss: 0.3938, Train Acc: 0.7891
Validation Acc: 0.6250
No improvement (6/10).
Epoch [10/100], Loss: 0.4635, Train Acc: 0.8281
Validation Acc: 0.6094
No improvement (7/10).
Epoch [11/100], Loss: 0.3417, Train Acc: 0.8477
Validation Acc: 0.6250
No improvement (8/10).
Epoch [12/100], Loss: 0.3754, Train Acc: 0.8086
Validation Acc: 0.6250
No improvement (9/10).
Epoch [13/100], Loss: 0.2860, Train Acc: 0.8906
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6864, Train Acc: 0.7148
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6634, Train Acc: 0.8320
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6095, Train Acc: 0.8516
Validation Acc: 0.7188
Epoch [5/50], Loss: 0.5887, Train Acc: 0.8672
Validation Acc: 0.7656
Epoch [6/50], Loss: 0.5761, Train Acc: 0.8203
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.5759, Train Acc: 0.7891
Validation Acc: 0.8594
Epoch [8/50], Loss: 0.5638, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (1/10).
Epoch [9/50], Loss: 0.5597, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5488, Train Acc: 0.8398
Validation Acc: 0.8281
No improvement (3/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (4/10).
Epoch [12/50], Loss: 0.5359, Train Acc: 0.8516
Validation Acc: 0.8281
No improvement (5/10).
Epoch [13/50], Loss: 0.5454, Train Acc: 0.8438
Validation Acc: 0.8281
No improvement (6/10).
Epoch [14/50], Loss: 0.5412, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (7/10).
Epoch [15/50], Loss: 0.5402, Train Acc: 0.8555
Validation Acc: 0.8281
No improvement (8/10).
Epoch [16/50], Loss: 0.5338, Train Acc: 0.8555
Validation Acc: 0.8594
No improvement (9/10).
Epoch [17/50], Loss: 0.5224, Train Acc: 0.8945
Validation Acc: 0.8281
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.88 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/50], Loss: 0.6864, Train Acc: 0.6406
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6680, Train Acc: 0.6992
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6534, Train Acc: 0.6953
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.6337, Train Acc: 0.7305
Validation Acc: 0.6406
No improvement (1/10).
Epoch [6/50], Loss: 0.6144, Train Acc: 0.7461
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.6018, Train Acc: 0.7500
Validation Acc: 0.7500
No improvement (3/10).
Epoch [8/50], Loss: 0.6032, Train Acc: 0.7383
Validation Acc: 0.7812
Epoch [9/50], Loss: 0.5935, Train Acc: 0.7578
Validation Acc: 0.6719
No improvement (1/10).
Epoch [10/50], Loss: 0.6149, Train Acc: 0.7188
Validation Acc: 0.6719
No improvement (2/10).
Epoch [11/50], Loss: 0.5861, Train Acc: 0.7656
Validation Acc: 0.7500
No improvement (3/10).
Epoch [12/50], Loss: 0.5898, Train Acc: 0.7578
Validation Acc: 0.7812
No improvement (4/10).
Epoch [13/50], Loss: 0.5790, Train Acc: 0.7695
Validation Acc: 0.7969
Epoch [14/50], Loss: 0.5874, Train Acc: 0.7578
Validation Acc: 0.7344
No improvement (1/10).
Epoch [15/50], Loss: 0.5868, Train Acc: 0.7578
Validation Acc: 0.7500
No improvement (2/10).
Epoch [16/50], Loss: 0.5839, Train Acc: 0.7617
Validation Acc: 0.7344
No improvement (3/10).
Epoch [17/50], Loss: 0.5694, Train Acc: 0.7891
Validation Acc: 0.7500
No improvement (4/10).
Epoch [18/50], Loss: 0.5691, Train Acc: 0.7812
Validation Acc: 0.7656
No improvement (5/10).
Epoch [19/50], Loss: 0.5621, Train Acc: 0.7891
Validation Acc: 0.7656
No improvement (6/10).
Epoch [20/50], Loss: 0.5662, Train Acc: 0.7812
Validation Acc: 0.7812
No improvement (7/10).
Epoch [21/50], Loss: 0.5699, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (8/10).
Epoch [22/50], Loss: 0.5627, Train Acc: 0.7852
Validation Acc: 0.7812
No improvement (9/10).
Epoch [23/50], Loss: 0.5604, Train Acc: 0.7852
Validation Acc: 0.7969
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.74 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
[STRESS] âœ… Found: {'rho': 5885.830315540584, 'sigma_b': 0.022494584008162108, 'd': 0.7346336206320505}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138056506, 'sigma_b': 0.0601454399984868, 'd': 0.7827636158617403}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.66s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  5.96s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.06s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.07
    - Variance: 2937.34

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1078.58
=== SVM (RBF Kernel) Classification Accuracy: 0.69 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.61 ===
=== Random Forest Accuracy: 0.79 ===
=== Logistic Regression Accuracy: 0.61 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2853, Train Acc: 0.5664
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8944, Train Acc: 0.6016
Validation Acc: 0.5625
Epoch [3/100], Loss: 0.7024, Train Acc: 0.6875
Validation Acc: 0.6875
Epoch [4/100], Loss: 0.6771, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (1/10).
Epoch [5/100], Loss: 0.5545, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (2/10).
Epoch [6/100], Loss: 0.5510, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (3/10).
Epoch [7/100], Loss: 0.4494, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (4/10).
Epoch [8/100], Loss: 0.3771, Train Acc: 0.8008
Validation Acc: 0.5781
No improvement (5/10).
Epoch [9/100], Loss: 0.3872, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [10/100], Loss: 0.3380, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (7/10).
Epoch [11/100], Loss: 0.3935, Train Acc: 0.8242
Validation Acc: 0.5938
No improvement (8/10).
Epoch [12/100], Loss: 0.3435, Train Acc: 0.8477
Validation Acc: 0.5938
No improvement (9/10).
Epoch [13/100], Loss: 0.3246, Train Acc: 0.8672
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6872, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6704, Train Acc: 0.7930
Validation Acc: 0.8906
Epoch [4/50], Loss: 0.6241, Train Acc: 0.8281
Validation Acc: 0.8594
No improvement (1/10).
Epoch [5/50], Loss: 0.5948, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (2/10).
Epoch [6/50], Loss: 0.5829, Train Acc: 0.8320
Validation Acc: 0.8125
No improvement (3/10).
Epoch [7/50], Loss: 0.5999, Train Acc: 0.7344
Validation Acc: 0.9531
Epoch [8/50], Loss: 0.5623, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (1/10).
Epoch [9/50], Loss: 0.5715, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (2/10).
Epoch [10/50], Loss: 0.5628, Train Acc: 0.8164
Validation Acc: 0.9531
No improvement (3/10).
Epoch [11/50], Loss: 0.5590, Train Acc: 0.8047
Validation Acc: 0.9375
No improvement (4/10).
Epoch [12/50], Loss: 0.5502, Train Acc: 0.8047
Validation Acc: 0.9531
No improvement (5/10).
Epoch [13/50], Loss: 0.5520, Train Acc: 0.8086
Validation Acc: 0.9375
No improvement (6/10).
Epoch [14/50], Loss: 0.5431, Train Acc: 0.7930
Validation Acc: 0.9375
No improvement (7/10).
Epoch [15/50], Loss: 0.5526, Train Acc: 0.8047
Validation Acc: 0.9375
No improvement (8/10).
Epoch [16/50], Loss: 0.5359, Train Acc: 0.8242
Validation Acc: 0.9375
No improvement (9/10).
Epoch [17/50], Loss: 0.5337, Train Acc: 0.8477
Validation Acc: 0.9375
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6892, Train Acc: 0.6289
Validation Acc: 0.5469
Epoch [3/50], Loss: 0.6803, Train Acc: 0.6328
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6651, Train Acc: 0.6406
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6529, Train Acc: 0.6914
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6372, Train Acc: 0.7070
Validation Acc: 0.8438
Epoch [7/50], Loss: 0.6363, Train Acc: 0.6992
Validation Acc: 0.7031
No improvement (1/10).
Epoch [8/50], Loss: 0.6475, Train Acc: 0.6641
Validation Acc: 0.6406
No improvement (2/10).
Epoch [9/50], Loss: 0.6814, Train Acc: 0.5859
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/50], Loss: 0.6846, Train Acc: 0.5664
Validation Acc: 0.6250
No improvement (4/10).
Epoch [11/50], Loss: 0.6670, Train Acc: 0.5977
Validation Acc: 0.6719
No improvement (5/10).
Epoch [12/50], Loss: 0.6402, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (6/10).
Epoch [13/50], Loss: 0.5914, Train Acc: 0.7539
Validation Acc: 0.7031
No improvement (7/10).
Epoch [14/50], Loss: 0.5906, Train Acc: 0.7773
Validation Acc: 0.7344
No improvement (8/10).
Epoch [15/50], Loss: 0.6302, Train Acc: 0.6680
Validation Acc: 0.6719
No improvement (9/10).
Epoch [16/50], Loss: 0.6265, Train Acc: 0.6641
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.00s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.82s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.86s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.94s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.02s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.09s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022494584008162108, 'rho': 5885.830315540584, 'd': 0.7346336206320505, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.84s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  12%|â–ˆâ–        | 5/42 [2:48:29<21:47:52, 2120.87s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-212671>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-212671>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3143_1200/steady_state_trajectories/m_traj_3143.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.92
    - Variance: 2857.74

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4311, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.9413, Train Acc: 0.6016
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.7359, Train Acc: 0.6602
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.7062, Train Acc: 0.6758
Validation Acc: 0.5781
No improvement (1/10).
Epoch [5/100], Loss: 0.5799, Train Acc: 0.7422
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.4894, Train Acc: 0.7852
Validation Acc: 0.6094
Epoch [7/100], Loss: 0.5064, Train Acc: 0.7891
Validation Acc: 0.5938
No improvement (1/10).
Epoch [8/100], Loss: 0.3719, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4500, Train Acc: 0.7773
Validation Acc: 0.5938
No improvement (3/10).
Epoch [10/100], Loss: 0.4333, Train Acc: 0.8047
Validation Acc: 0.5781
No improvement (4/10).
Epoch [11/100], Loss: 0.4019, Train Acc: 0.8320
Validation Acc: 0.5469
No improvement (5/10).
Epoch [12/100], Loss: 0.3353, Train Acc: 0.8438
Validation Acc: 0.5625
No improvement (6/10).
Epoch [13/100], Loss: 0.3164, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [14/100], Loss: 0.3424, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (8/10).
Epoch [15/100], Loss: 0.3163, Train Acc: 0.8672
Validation Acc: 0.6094
No improvement (9/10).
Epoch [16/100], Loss: 0.2644, Train Acc: 0.8828
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.57 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6758
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6660, Train Acc: 0.8242
Validation Acc: 0.7344
Epoch [4/50], Loss: 0.6179, Train Acc: 0.8359
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.5856, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5705, Train Acc: 0.8320
Validation Acc: 0.7500
No improvement (1/10).
Epoch [7/50], Loss: 0.5832, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [8/50], Loss: 0.5534, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (3/10).
Epoch [9/50], Loss: 0.5519, Train Acc: 0.8320
Validation Acc: 0.8594
Epoch [10/50], Loss: 0.5502, Train Acc: 0.8438
Validation Acc: 0.9062
Epoch [11/50], Loss: 0.5598, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5531, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (2/10).
Epoch [13/50], Loss: 0.5575, Train Acc: 0.8125
Validation Acc: 0.8281
No improvement (3/10).
Epoch [14/50], Loss: 0.5624, Train Acc: 0.7852
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5427, Train Acc: 0.8320
Validation Acc: 0.8906
No improvement (5/10).
Epoch [16/50], Loss: 0.5386, Train Acc: 0.8203
Validation Acc: 0.8750
No improvement (6/10).
Epoch [17/50], Loss: 0.5344, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.8516
Validation Acc: 0.8750
No improvement (8/10).
Epoch [19/50], Loss: 0.5381, Train Acc: 0.8203
Validation Acc: 0.9062
No improvement (9/10).
Epoch [20/50], Loss: 0.5288, Train Acc: 0.8281
Validation Acc: 0.9219
Epoch [21/50], Loss: 0.5335, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [22/50], Loss: 0.5316, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (2/10).
Epoch [23/50], Loss: 0.5382, Train Acc: 0.8398
Validation Acc: 0.8750
No improvement (3/10).
Epoch [24/50], Loss: 0.5437, Train Acc: 0.8164
Validation Acc: 0.8906
No improvement (4/10).
Epoch [25/50], Loss: 0.5210, Train Acc: 0.8398
Validation Acc: 0.9062
No improvement (5/10).
Epoch [26/50], Loss: 0.5295, Train Acc: 0.8125
Validation Acc: 0.8906
No improvement (6/10).
Epoch [27/50], Loss: 0.5358, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (7/10).
Epoch [28/50], Loss: 0.5408, Train Acc: 0.8008
Validation Acc: 0.9062
No improvement (8/10).
Epoch [29/50], Loss: 0.5203, Train Acc: 0.8125
Validation Acc: 0.9062
No improvement (9/10).
Epoch [30/50], Loss: 0.5193, Train Acc: 0.8789
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.93 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6884, Train Acc: 0.6484
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6741, Train Acc: 0.6758
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6575, Train Acc: 0.6875
Validation Acc: 0.7812
Epoch [5/50], Loss: 0.6338, Train Acc: 0.7344
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/50], Loss: 0.6610, Train Acc: 0.6523
Validation Acc: 0.6875
No improvement (2/10).
Epoch [7/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.7188
No improvement (3/10).
Epoch [8/50], Loss: 0.6080, Train Acc: 0.7305
Validation Acc: 0.7500
No improvement (4/10).
Epoch [9/50], Loss: 0.5819, Train Acc: 0.7891
Validation Acc: 0.7344
No improvement (5/10).
Epoch [10/50], Loss: 0.5876, Train Acc: 0.7695
Validation Acc: 0.7812
No improvement (6/10).
Epoch [11/50], Loss: 0.5865, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (7/10).
Epoch [12/50], Loss: 0.6159, Train Acc: 0.7148
Validation Acc: 0.7188
No improvement (8/10).
Epoch [13/50], Loss: 0.6251, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (9/10).
Epoch [14/50], Loss: 0.6266, Train Acc: 0.6953
Validation Acc: 0.7031
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
[STRESS] âœ… Found: {'rho': 5908.312154100791, 'sigma_b': 0.022408905356785302, 'd': 0.7346343575637883}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138067617, 'sigma_b': 0.060145439998530295, 'd': 0.7827636158617833}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.84s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.76
    - Variance: 2937.85

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.66
    - Variance: 1097.76
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.56 ===
=== Random Forest Accuracy: 0.70 ===
=== Logistic Regression Accuracy: 0.57 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.3194, Train Acc: 0.5586
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8709, Train Acc: 0.6602
Validation Acc: 0.5469
No improvement (1/10).
Epoch [3/100], Loss: 0.7832, Train Acc: 0.6797
Validation Acc: 0.5938
Epoch [4/100], Loss: 0.6972, Train Acc: 0.7227
Validation Acc: 0.6250
Epoch [5/100], Loss: 0.5573, Train Acc: 0.7695
Validation Acc: 0.5938
No improvement (1/10).
Epoch [6/100], Loss: 0.5205, Train Acc: 0.7578
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/100], Loss: 0.4637, Train Acc: 0.7773
Validation Acc: 0.6094
No improvement (3/10).
Epoch [8/100], Loss: 0.3867, Train Acc: 0.8203
Validation Acc: 0.5938
No improvement (4/10).
Epoch [9/100], Loss: 0.3846, Train Acc: 0.8359
Validation Acc: 0.5781
No improvement (5/10).
Epoch [10/100], Loss: 0.3466, Train Acc: 0.8398
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/100], Loss: 0.3318, Train Acc: 0.8516
Validation Acc: 0.5312
No improvement (7/10).
Epoch [12/100], Loss: 0.2852, Train Acc: 0.8711
Validation Acc: 0.5469
No improvement (8/10).
Epoch [13/100], Loss: 0.2847, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (9/10).
Epoch [14/100], Loss: 0.3478, Train Acc: 0.8555
Validation Acc: 0.5469
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.68 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6927, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6861, Train Acc: 0.7266
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6646, Train Acc: 0.8125
Validation Acc: 0.7656
Epoch [4/50], Loss: 0.6190, Train Acc: 0.8477
Validation Acc: 0.8594
Epoch [5/50], Loss: 0.5862, Train Acc: 0.8633
Validation Acc: 0.8594
No improvement (1/10).
Epoch [6/50], Loss: 0.5749, Train Acc: 0.8320
Validation Acc: 0.8281
No improvement (2/10).
Epoch [7/50], Loss: 0.5919, Train Acc: 0.7969
Validation Acc: 0.5312
No improvement (3/10).
Epoch [8/50], Loss: 0.5639, Train Acc: 0.8203
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5586, Train Acc: 0.7812
Validation Acc: 0.5625
No improvement (5/10).
Epoch [10/50], Loss: 0.5645, Train Acc: 0.8438
Validation Acc: 0.7500
No improvement (6/10).
Epoch [11/50], Loss: 0.5679, Train Acc: 0.7891
Validation Acc: 0.8594
No improvement (7/10).
Epoch [12/50], Loss: 0.5530, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (8/10).
Epoch [13/50], Loss: 0.5740, Train Acc: 0.7695
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (1/10).
Epoch [15/50], Loss: 0.5568, Train Acc: 0.7812
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5652, Train Acc: 0.7891
Validation Acc: 0.8750
No improvement (3/10).
Epoch [17/50], Loss: 0.5471, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (4/10).
Epoch [18/50], Loss: 0.5543, Train Acc: 0.7773
Validation Acc: 0.8750
No improvement (5/10).
Epoch [19/50], Loss: 0.5550, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (6/10).
Epoch [20/50], Loss: 0.5425, Train Acc: 0.8477
Validation Acc: 0.8281
No improvement (7/10).
Epoch [21/50], Loss: 0.5624, Train Acc: 0.7891
Validation Acc: 0.8281
No improvement (8/10).
Epoch [22/50], Loss: 0.5517, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (9/10).
Epoch [23/50], Loss: 0.5455, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.89 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.5234
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6289
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6789, Train Acc: 0.6250
Validation Acc: 0.5938
Epoch [4/50], Loss: 0.6656, Train Acc: 0.6602
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/50], Loss: 0.6470, Train Acc: 0.7227
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6384, Train Acc: 0.7109
Validation Acc: 0.8125
Epoch [7/50], Loss: 0.6166, Train Acc: 0.7305
Validation Acc: 0.6875
No improvement (1/10).
Epoch [8/50], Loss: 0.5926, Train Acc: 0.7773
Validation Acc: 0.7812
No improvement (2/10).
Epoch [9/50], Loss: 0.6139, Train Acc: 0.7344
Validation Acc: 0.7969
No improvement (3/10).
Epoch [10/50], Loss: 0.5599, Train Acc: 0.8203
Validation Acc: 0.5312
No improvement (4/10).
Epoch [11/50], Loss: 0.5708, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (5/10).
Epoch [12/50], Loss: 0.5540, Train Acc: 0.8125
Validation Acc: 0.7188
No improvement (6/10).
Epoch [13/50], Loss: 0.5667, Train Acc: 0.7930
Validation Acc: 0.7812
No improvement (7/10).
Epoch [14/50], Loss: 0.5444, Train Acc: 0.8281
Validation Acc: 0.7188
No improvement (8/10).
Epoch [15/50], Loss: 0.5488, Train Acc: 0.8125
Validation Acc: 0.7188
No improvement (9/10).
Epoch [16/50], Loss: 0.5565, Train Acc: 0.8047
Validation Acc: 0.7188
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.71 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.97s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.05s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.93s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.58s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.95s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.61s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.09s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.03s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.75s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.98s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022408905356785302, 'rho': 5908.312154100791, 'd': 0.7346343575637883, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.69s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  14%|â–ˆâ–        | 6/42 [3:05:18<17:25:33, 1742.61s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-230231>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-230231>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998530295, 'rho': 1179.1338138067617, 'd': 0.7827636158617833, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3155_1200/steady_state_trajectories/m_traj_3155.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.99
    - Variance: 2928.29

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.64 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.57 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.56 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.4259, Train Acc: 0.4805
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8672, Train Acc: 0.6406
Validation Acc: 0.5156
No improvement (1/10).
Epoch [3/100], Loss: 0.6860, Train Acc: 0.6797
Validation Acc: 0.4844
No improvement (2/10).
Epoch [4/100], Loss: 0.6434, Train Acc: 0.7656
Validation Acc: 0.4844
No improvement (3/10).
Epoch [5/100], Loss: 0.4805, Train Acc: 0.7969
Validation Acc: 0.5000
No improvement (4/10).
Epoch [6/100], Loss: 0.4667, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (5/10).
Epoch [7/100], Loss: 0.4311, Train Acc: 0.8125
Validation Acc: 0.5625
Epoch [8/100], Loss: 0.4212, Train Acc: 0.8086
Validation Acc: 0.5625
No improvement (1/10).
Epoch [9/100], Loss: 0.3596, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (2/10).
Epoch [10/100], Loss: 0.3844, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (3/10).
Epoch [11/100], Loss: 0.2901, Train Acc: 0.8828
Validation Acc: 0.5312
No improvement (4/10).
Epoch [12/100], Loss: 0.2799, Train Acc: 0.8867
Validation Acc: 0.5156
No improvement (5/10).
Epoch [13/100], Loss: 0.2296, Train Acc: 0.8789
Validation Acc: 0.5469
No improvement (6/10).
Epoch [14/100], Loss: 0.2984, Train Acc: 0.8633
Validation Acc: 0.5781
Epoch [15/100], Loss: 0.2347, Train Acc: 0.8828
Validation Acc: 0.5781
No improvement (1/10).
Epoch [16/100], Loss: 0.2656, Train Acc: 0.8789
Validation Acc: 0.5625
No improvement (2/10).
Epoch [17/100], Loss: 0.1958, Train Acc: 0.8984
Validation Acc: 0.5469
No improvement (3/10).
Epoch [18/100], Loss: 0.1836, Train Acc: 0.9336
Validation Acc: 0.5156
No improvement (4/10).
Epoch [19/100], Loss: 0.2093, Train Acc: 0.9141
Validation Acc: 0.5312
No improvement (5/10).
Epoch [20/100], Loss: 0.1914, Train Acc: 0.9258
Validation Acc: 0.5469
No improvement (6/10).
Epoch [21/100], Loss: 0.1668, Train Acc: 0.9414
Validation Acc: 0.5469
No improvement (7/10).
Epoch [22/100], Loss: 0.1704, Train Acc: 0.9180
Validation Acc: 0.5625
No improvement (8/10).
Epoch [23/100], Loss: 0.1670, Train Acc: 0.9258
Validation Acc: 0.5781
No improvement (9/10).
Epoch [24/100], Loss: 0.1786, Train Acc: 0.9375
Validation Acc: 0.5781
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.60 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5156
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6659, Train Acc: 0.8438
Validation Acc: 0.8125
Epoch [4/50], Loss: 0.6159, Train Acc: 0.8516
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5837, Train Acc: 0.8711
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.5832, Train Acc: 0.8086
Validation Acc: 0.8750
Epoch [7/50], Loss: 0.5782, Train Acc: 0.7812
Validation Acc: 0.6094
No improvement (1/10).
Epoch [8/50], Loss: 0.5554, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5626, Train Acc: 0.8125
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5588, Train Acc: 0.8125
Validation Acc: 0.8125
No improvement (4/10).
Epoch [11/50], Loss: 0.5540, Train Acc: 0.8164
Validation Acc: 0.8281
No improvement (5/10).
Epoch [12/50], Loss: 0.5455, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (6/10).
Epoch [13/50], Loss: 0.5564, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (7/10).
Epoch [14/50], Loss: 0.5527, Train Acc: 0.8008
Validation Acc: 0.8281
No improvement (8/10).
Epoch [15/50], Loss: 0.5572, Train Acc: 0.8125
Validation Acc: 0.8438
No improvement (9/10).
Epoch [16/50], Loss: 0.5497, Train Acc: 0.8164
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.94 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6931, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6897, Train Acc: 0.6367
Validation Acc: 0.5938
Epoch [3/50], Loss: 0.6810, Train Acc: 0.6289
Validation Acc: 0.6562
Epoch [4/50], Loss: 0.6669, Train Acc: 0.6484
Validation Acc: 0.5000
No improvement (1/10).
Epoch [5/50], Loss: 0.6427, Train Acc: 0.7070
Validation Acc: 0.5625
No improvement (2/10).
Epoch [6/50], Loss: 0.6169, Train Acc: 0.7500
Validation Acc: 0.7969
Epoch [7/50], Loss: 0.6228, Train Acc: 0.7148
Validation Acc: 0.8125
Epoch [8/50], Loss: 0.5841, Train Acc: 0.7812
Validation Acc: 0.7344
No improvement (1/10).
Epoch [9/50], Loss: 0.5974, Train Acc: 0.7500
Validation Acc: 0.5156
No improvement (2/10).
Epoch [10/50], Loss: 0.7062, Train Acc: 0.5430
Validation Acc: 0.5000
No improvement (3/10).
Epoch [11/50], Loss: 0.6654, Train Acc: 0.6250
Validation Acc: 0.5781
No improvement (4/10).
Epoch [12/50], Loss: 0.6469, Train Acc: 0.6523
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6269, Train Acc: 0.6875
Validation Acc: 0.6250
No improvement (6/10).
Epoch [14/50], Loss: 0.6219, Train Acc: 0.7031
Validation Acc: 0.6719
No improvement (7/10).
Epoch [15/50], Loss: 0.6229, Train Acc: 0.7109
Validation Acc: 0.6250
No improvement (8/10).
Epoch [16/50], Loss: 0.6377, Train Acc: 0.6914
Validation Acc: 0.5781
No improvement (9/10).
Epoch [17/50], Loss: 0.6476, Train Acc: 0.6680
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.65 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
[STRESS] âœ… Found: {'rho': 5930.793992296405, 'sigma_b': 0.022323876905889967, 'd': 0.7346350889181051}
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.1338138056506, 'sigma_b': 0.0601454399984868, 'd': 0.7827636158617403}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.30s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.78s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_0_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.18
    - Variance: 2791.03

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.62
    - Variance: 1078.58
=== SVM (RBF Kernel) Classification Accuracy: 0.70 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.51 ===
=== Random Forest Accuracy: 0.80 ===
=== Logistic Regression Accuracy: 0.54 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2911, Train Acc: 0.5977
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8959, Train Acc: 0.5938
Validation Acc: 0.5938
Epoch [3/100], Loss: 0.7051, Train Acc: 0.7148
Validation Acc: 0.6094
Epoch [4/100], Loss: 0.6942, Train Acc: 0.7070
Validation Acc: 0.5469
No improvement (1/10).
Epoch [5/100], Loss: 0.5621, Train Acc: 0.7656
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/100], Loss: 0.6325, Train Acc: 0.7344
Validation Acc: 0.5938
No improvement (3/10).
Epoch [7/100], Loss: 0.4440, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (4/10).
Epoch [8/100], Loss: 0.4595, Train Acc: 0.8164
Validation Acc: 0.5625
No improvement (5/10).
Epoch [9/100], Loss: 0.4396, Train Acc: 0.7969
Validation Acc: 0.5625
No improvement (6/10).
Epoch [10/100], Loss: 0.3186, Train Acc: 0.8516
Validation Acc: 0.5938
No improvement (7/10).
Epoch [11/100], Loss: 0.3723, Train Acc: 0.8398
Validation Acc: 0.5781
No improvement (8/10).
Epoch [12/100], Loss: 0.3185, Train Acc: 0.8398
Validation Acc: 0.5156
No improvement (9/10).
Epoch [13/100], Loss: 0.3766, Train Acc: 0.8594
Validation Acc: 0.5000
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6870, Train Acc: 0.6836
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6695, Train Acc: 0.8086
Validation Acc: 0.7812
Epoch [4/50], Loss: 0.6251, Train Acc: 0.8164
Validation Acc: 0.8438
Epoch [5/50], Loss: 0.5877, Train Acc: 0.8711
Validation Acc: 0.8906
Epoch [6/50], Loss: 0.5746, Train Acc: 0.8320
Validation Acc: 0.6094
No improvement (1/10).
Epoch [7/50], Loss: 0.5940, Train Acc: 0.7578
Validation Acc: 0.8281
No improvement (2/10).
Epoch [8/50], Loss: 0.5678, Train Acc: 0.8047
Validation Acc: 0.9062
Epoch [9/50], Loss: 0.5689, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [10/50], Loss: 0.5731, Train Acc: 0.7617
Validation Acc: 0.9062
No improvement (2/10).
Epoch [11/50], Loss: 0.5784, Train Acc: 0.7578
Validation Acc: 0.9531
Epoch [12/50], Loss: 0.5535, Train Acc: 0.7930
Validation Acc: 0.8125
No improvement (1/10).
Epoch [13/50], Loss: 0.5643, Train Acc: 0.7773
Validation Acc: 0.9375
No improvement (2/10).
Epoch [14/50], Loss: 0.5710, Train Acc: 0.7461
Validation Acc: 0.9219
No improvement (3/10).
Epoch [15/50], Loss: 0.5863, Train Acc: 0.7422
Validation Acc: 0.9375
No improvement (4/10).
Epoch [16/50], Loss: 0.5424, Train Acc: 0.7969
Validation Acc: 0.8906
No improvement (5/10).
Epoch [17/50], Loss: 0.5295, Train Acc: 0.8281
Validation Acc: 0.8906
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7734
Validation Acc: 0.9531
No improvement (7/10).
Epoch [19/50], Loss: 0.5421, Train Acc: 0.7773
Validation Acc: 0.9688
Epoch [20/50], Loss: 0.5298, Train Acc: 0.8086
Validation Acc: 0.9062
No improvement (1/10).
Epoch [21/50], Loss: 0.5328, Train Acc: 0.7812
Validation Acc: 0.9531
No improvement (2/10).
Epoch [22/50], Loss: 0.5252, Train Acc: 0.8008
Validation Acc: 0.9531
No improvement (3/10).
Epoch [23/50], Loss: 0.5347, Train Acc: 0.7891
Validation Acc: 0.9219
No improvement (4/10).
Epoch [24/50], Loss: 0.5417, Train Acc: 0.7773
Validation Acc: 0.9531
No improvement (5/10).
Epoch [25/50], Loss: 0.5334, Train Acc: 0.7891
Validation Acc: 0.9531
No improvement (6/10).
Epoch [26/50], Loss: 0.5410, Train Acc: 0.7617
Validation Acc: 0.9531
No improvement (7/10).
Epoch [27/50], Loss: 0.5313, Train Acc: 0.7773
Validation Acc: 0.9531
No improvement (8/10).
Epoch [28/50], Loss: 0.5333, Train Acc: 0.7539
Validation Acc: 0.9531
No improvement (9/10).
Epoch [29/50], Loss: 0.5274, Train Acc: 0.7773
Validation Acc: 0.9531
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.95 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5469
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6367
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6765, Train Acc: 0.6445
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6625, Train Acc: 0.6484
Validation Acc: 0.7344
Epoch [5/50], Loss: 0.6416, Train Acc: 0.7188
Validation Acc: 0.8438
Epoch [6/50], Loss: 0.6184, Train Acc: 0.7422
Validation Acc: 0.6094
No improvement (1/10).
Epoch [7/50], Loss: 0.6122, Train Acc: 0.7344
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.5840, Train Acc: 0.7773
Validation Acc: 0.7969
No improvement (3/10).
Epoch [9/50], Loss: 0.5930, Train Acc: 0.7422
Validation Acc: 0.8438
No improvement (4/10).
Epoch [10/50], Loss: 0.6086, Train Acc: 0.7344
Validation Acc: 0.8125
No improvement (5/10).
Epoch [11/50], Loss: 0.6176, Train Acc: 0.7227
Validation Acc: 0.8438
No improvement (6/10).
Epoch [12/50], Loss: 0.6170, Train Acc: 0.7227
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.6073, Train Acc: 0.7227
Validation Acc: 0.8906
Epoch [14/50], Loss: 0.5912, Train Acc: 0.7578
Validation Acc: 0.8594
No improvement (1/10).
Epoch [15/50], Loss: 0.5712, Train Acc: 0.7773
Validation Acc: 0.6875
No improvement (2/10).
Epoch [16/50], Loss: 0.5797, Train Acc: 0.7656
Validation Acc: 0.9219
Epoch [17/50], Loss: 0.5959, Train Acc: 0.7422
Validation Acc: 0.8438
No improvement (1/10).
Epoch [18/50], Loss: 0.5826, Train Acc: 0.7539
Validation Acc: 0.8750
No improvement (2/10).
Epoch [19/50], Loss: 0.5587, Train Acc: 0.8047
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5553, Train Acc: 0.8086
Validation Acc: 0.8750
No improvement (4/10).
Epoch [21/50], Loss: 0.5548, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (5/10).
Epoch [22/50], Loss: 0.5559, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5552, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5568, Train Acc: 0.7969
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5540, Train Acc: 0.8008
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.78 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.96s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_1_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.84s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_2_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.87s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_3_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_4_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.65s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_5_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.78s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.63s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_6_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.82s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.67s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_7_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.86s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.68s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.71s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_8_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.88s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.022323876905889967, 'rho': 5930.793992296405, 'd': 0.7346350889181051, 'label': 0}

Simulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.79s/it][ASimulating Telegraph Model Systems: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  17%|â–ˆâ–‹        | 7/42 [3:43:28<18:40:56, 1921.61s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:164: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
Running Variance Ratio Simulations:  17%|â–ˆâ–‹        | 7/42 [4:29:28<22:27:24, 2309.84s/it]
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.0601454399984868, 'rho': 1179.1338138056506, 'd': 0.7827636158617403, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3167_1200/steady_state_trajectories/m_traj_3167.9999999999986_1200.0_9_SS.csv

=== Statistical Report ===

ðŸ“Š **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.35
    - Variance: 2827.14

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.75 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.50 ===
=== Random Forest Accuracy: 0.72 ===
=== Logistic Regression Accuracy: 0.49 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/100], Loss: 1.2806, Train Acc: 0.5312
Validation Acc: 0.5625
Epoch [2/100], Loss: 0.8451, Train Acc: 0.6680
Validation Acc: 0.5781
Epoch [3/100], Loss: 0.8365, Train Acc: 0.6875
Validation Acc: 0.5625
No improvement (1/10).
Epoch [4/100], Loss: 0.6565, Train Acc: 0.7383
Validation Acc: 0.5625
No improvement (2/10).
Epoch [5/100], Loss: 0.4828, Train Acc: 0.7852
Validation Acc: 0.5312
No improvement (3/10).
Epoch [6/100], Loss: 0.5575, Train Acc: 0.7734
Validation Acc: 0.5312
No improvement (4/10).
Epoch [7/100], Loss: 0.4486, Train Acc: 0.8086
Validation Acc: 0.5469
No improvement (5/10).
Epoch [8/100], Loss: 0.3955, Train Acc: 0.8164
Validation Acc: 0.5312
No improvement (6/10).
Epoch [9/100], Loss: 0.3697, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (7/10).
Epoch [10/100], Loss: 0.3312, Train Acc: 0.8594
Validation Acc: 0.5312
No improvement (8/10).
Epoch [11/100], Loss: 0.3121, Train Acc: 0.8672
Validation Acc: 0.5625
No improvement (9/10).
Epoch [12/100], Loss: 0.3752, Train Acc: 0.8359
Validation Acc: 0.5156
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.54 ===
=== Random Classifier Accuracy: 0.45 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5078
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6871, Train Acc: 0.6602
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6669, Train Acc: 0.8086
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6166, Train Acc: 0.8281
Validation Acc: 0.7969
Epoch [5/50], Loss: 0.5985, Train Acc: 0.8281
Validation Acc: 0.7812
No improvement (1/10).
Epoch [6/50], Loss: 0.5847, Train Acc: 0.7930
Validation Acc: 0.7031
No improvement (2/10).
Epoch [7/50], Loss: 0.5837, Train Acc: 0.7812
Validation Acc: 0.5000
No improvement (3/10).
Epoch [8/50], Loss: 0.5568, Train Acc: 0.7930
Validation Acc: 0.5000
No improvement (4/10).
Epoch [9/50], Loss: 0.5599, Train Acc: 0.8008
Validation Acc: 0.5000
No improvement (5/10).
Epoch [10/50], Loss: 0.5611, Train Acc: 0.8164
Validation Acc: 0.5469
No improvement (6/10).
Epoch [11/50], Loss: 0.5635, Train Acc: 0.7930
Validation Acc: 0.8438
Epoch [12/50], Loss: 0.5526, Train Acc: 0.8086
Validation Acc: 0.8438
No improvement (1/10).
Epoch [13/50], Loss: 0.5628, Train Acc: 0.7852
Validation Acc: 0.8750
Epoch [14/50], Loss: 0.5533, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (1/10).
Epoch [15/50], Loss: 0.5606, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (2/10).
Epoch [16/50], Loss: 0.5415, Train Acc: 0.8398
Validation Acc: 0.9062
Epoch [17/50], Loss: 0.5352, Train Acc: 0.8672
Validation Acc: 0.8594
No improvement (1/10).
Epoch [18/50], Loss: 0.5436, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (2/10).
Epoch [19/50], Loss: 0.5431, Train Acc: 0.8320
Validation Acc: 0.8594
No improvement (3/10).
Epoch [20/50], Loss: 0.5317, Train Acc: 0.8320
Validation Acc: 0.8438
No improvement (4/10).
Epoch [21/50], Loss: 0.5391, Train Acc: 0.8203
Validation Acc: 0.8594
No improvement (5/10).
Epoch [22/50], Loss: 0.5381, Train Acc: 0.8477
Validation Acc: 0.8750
No improvement (6/10).
Epoch [23/50], Loss: 0.5411, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (7/10).
Epoch [24/50], Loss: 0.5470, Train Acc: 0.8047
Validation Acc: 0.8750
No improvement (8/10).
Epoch [25/50], Loss: 0.5360, Train Acc: 0.8281
Validation Acc: 0.8750
No improvement (9/10).
Epoch [26/50], Loss: 0.5435, Train Acc: 0.7930
Validation Acc: 0.8750
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.86 ===
ðŸ”„ Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
âœ… Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5273
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6880, Train Acc: 0.6406
Validation Acc: 0.5781
Epoch [3/50], Loss: 0.6750, Train Acc: 0.6836
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6568, Train Acc: 0.6953
Validation Acc: 0.6719
No improvement (1/10).
Epoch [5/50], Loss: 0.6132, Train Acc: 0.8125
Validation Acc: 0.5781
No improvement (2/10).
Epoch [6/50], Loss: 0.5922, Train Acc: 0.7969
Validation Acc: 0.7500
Epoch [7/50], Loss: 0.5830, Train Acc: 0.7812
Validation Acc: 0.7500
No improvement (1/10).
Epoch [8/50], Loss: 0.6127, Train Acc: 0.7188
Validation Acc: 0.7188
No improvement (2/10).
Epoch [9/50], Loss: 0.5926, Train Acc: 0.7383
Validation Acc: 0.6875
No improvement (3/10).
Epoch [10/50], Loss: 0.5764, Train Acc: 0.7539
Validation Acc: 0.7344
No improvement (4/10).
Epoch [11/50], Loss: 0.5475, Train Acc: 0.8164
Validation Acc: 0.7656
Epoch [12/50], Loss: 0.5466, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (1/10).
Epoch [13/50], Loss: 0.5452, Train Acc: 0.8086
Validation Acc: 0.7656
No improvement (2/10).
Epoch [14/50], Loss: 0.5435, Train Acc: 0.8086
Validation Acc: 0.7500
No improvement (3/10).
Epoch [15/50], Loss: 0.5480, Train Acc: 0.7969
Validation Acc: 0.7500
No improvement (4/10).
Epoch [16/50], Loss: 0.5435, Train Acc: 0.8164
Validation Acc: 0.7344
No improvement (5/10).
Epoch [17/50], Loss: 0.5381, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (6/10).
Epoch [18/50], Loss: 0.5505, Train Acc: 0.7969
Validation Acc: 0.7031
No improvement (7/10).
Epoch [19/50], Loss: 0.5394, Train Acc: 0.8242
Validation Acc: 0.7500
No improvement (8/10).
Epoch [20/50], Loss: 0.5319, Train Acc: 0.8359
Validation Acc: 0.7656
No improvement (9/10).
Epoch [21/50], Loss: 0.5374, Train Acc: 0.8242
Validation Acc: 0.7656
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Long-Short Term Memory (LSTM) Accuracy: 0.79 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] âŒ No suitable solution found.
Attempt 1/10
[NORMAL] âœ… Found: {'rho': 1179.133813806046, 'sigma_b': 0.060145439998496524, 'd': 0.7827636158617438}
Traceback (most recent call last):
  File "/home/ianyang/stochastic_simulations/experiments/SSA_telegraph_model/var_v_accuracy_plot/var_v_accuracy_13_04_2025.py", line 83, in <module>
    "sigma_b": results["stress"]['sigma_b'], 
               ~~~~~~~^^^^^^^^^^
KeyError: 'stress'
