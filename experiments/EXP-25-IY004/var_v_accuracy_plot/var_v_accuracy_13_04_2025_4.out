Running Variance Ratio Simulations:   0%|          | 0/2 [00:00<?, ?it/s]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
<lambdifygenerated-11578>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-11578>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-17391>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-17391>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
[STRESS] ✅ Found: {'rho': 6425.394353115255, 'sigma_b': 0.020603925441389413, 'd': 0.734649885934854}
Attempt 1/10
[NORMAL] ✅ Found: {'rho': 1179.133813799024, 'sigma_b': 0.060145439998484096, 'd': 0.7827636158617373}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:05<00:05,  5.61s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.56s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.56s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_0_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.52
    - Variance: 3142.01

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 10.60
    - Variance: 1367.07
=== SVM (RBF Kernel) Classification Accuracy: 0.76 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.60 ===
=== Random Forest Accuracy: 0.69 ===
=== Logistic Regression Accuracy: 0.53 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2567, Train Acc: 0.5391
Validation Acc: 0.5781
Epoch [2/100], Loss: 0.8205, Train Acc: 0.6953
Validation Acc: 0.4844
No improvement (1/10).
Epoch [3/100], Loss: 0.6620, Train Acc: 0.7422
Validation Acc: 0.5469
No improvement (2/10).
Epoch [4/100], Loss: 0.5632, Train Acc: 0.7734
Validation Acc: 0.5469
No improvement (3/10).
Epoch [5/100], Loss: 0.4272, Train Acc: 0.7891
Validation Acc: 0.5781
No improvement (4/10).
Epoch [6/100], Loss: 0.4390, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (5/10).
Epoch [7/100], Loss: 0.3662, Train Acc: 0.8320
Validation Acc: 0.5781
No improvement (6/10).
Epoch [8/100], Loss: 0.3212, Train Acc: 0.8672
Validation Acc: 0.5938
Epoch [9/100], Loss: 0.2846, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (1/10).
Epoch [10/100], Loss: 0.2712, Train Acc: 0.8750
Validation Acc: 0.5938
No improvement (2/10).
Epoch [11/100], Loss: 0.2882, Train Acc: 0.8906
Validation Acc: 0.5938
No improvement (3/10).
Epoch [12/100], Loss: 0.3052, Train Acc: 0.8672
Validation Acc: 0.5938
No improvement (4/10).
Epoch [13/100], Loss: 0.2562, Train Acc: 0.8945
Validation Acc: 0.5781
No improvement (5/10).
Epoch [14/100], Loss: 0.2065, Train Acc: 0.8984
Validation Acc: 0.5938
No improvement (6/10).
Epoch [15/100], Loss: 0.2340, Train Acc: 0.8906
Validation Acc: 0.5938
No improvement (7/10).
Epoch [16/100], Loss: 0.2479, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (8/10).
Epoch [17/100], Loss: 0.2147, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (9/10).
Epoch [18/100], Loss: 0.1863, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.62 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5039
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7109
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6630, Train Acc: 0.8242
Validation Acc: 0.7188
Epoch [4/50], Loss: 0.6126, Train Acc: 0.8594
Validation Acc: 0.7500
Epoch [5/50], Loss: 0.5865, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [6/50], Loss: 0.5698, Train Acc: 0.8438
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.5932, Train Acc: 0.7500
Validation Acc: 0.7969
No improvement (1/10).
Epoch [8/50], Loss: 0.5707, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (2/10).
Epoch [9/50], Loss: 0.5675, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (3/10).
Epoch [10/50], Loss: 0.5726, Train Acc: 0.8047
Validation Acc: 0.8750
Epoch [11/50], Loss: 0.5760, Train Acc: 0.7773
Validation Acc: 0.8594
No improvement (1/10).
Epoch [12/50], Loss: 0.5532, Train Acc: 0.8281
Validation Acc: 0.8438
No improvement (2/10).
Epoch [13/50], Loss: 0.5583, Train Acc: 0.7773
Validation Acc: 0.8594
No improvement (3/10).
Epoch [14/50], Loss: 0.5489, Train Acc: 0.8008
Validation Acc: 0.8750
No improvement (4/10).
Epoch [15/50], Loss: 0.5530, Train Acc: 0.7930
Validation Acc: 0.8438
No improvement (5/10).
Epoch [16/50], Loss: 0.5259, Train Acc: 0.8242
Validation Acc: 0.8594
No improvement (6/10).
Epoch [17/50], Loss: 0.5258, Train Acc: 0.8438
Validation Acc: 0.8438
No improvement (7/10).
Epoch [18/50], Loss: 0.5358, Train Acc: 0.7969
Validation Acc: 0.8594
No improvement (8/10).
Epoch [19/50], Loss: 0.5386, Train Acc: 0.7852
Validation Acc: 0.8438
No improvement (9/10).
Epoch [20/50], Loss: 0.5286, Train Acc: 0.8203
Validation Acc: 0.8438
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.88 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6929, Train Acc: 0.5117
Validation Acc: 0.4688
Epoch [2/50], Loss: 0.6901, Train Acc: 0.6016
Validation Acc: 0.4062
No improvement (1/10).
Epoch [3/50], Loss: 0.6819, Train Acc: 0.6602
Validation Acc: 0.5000
Epoch [4/50], Loss: 0.6583, Train Acc: 0.7227
Validation Acc: 0.6562
Epoch [5/50], Loss: 0.6290, Train Acc: 0.7344
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6141, Train Acc: 0.7305
Validation Acc: 0.6250
No improvement (2/10).
Epoch [7/50], Loss: 0.6086, Train Acc: 0.7383
Validation Acc: 0.5781
No improvement (3/10).
Epoch [8/50], Loss: 0.6162, Train Acc: 0.7266
Validation Acc: 0.5625
No improvement (4/10).
Epoch [9/50], Loss: 0.5967, Train Acc: 0.7461
Validation Acc: 0.5625
No improvement (5/10).
Epoch [10/50], Loss: 0.6004, Train Acc: 0.7500
Validation Acc: 0.5625
No improvement (6/10).
Epoch [11/50], Loss: 0.5920, Train Acc: 0.7578
Validation Acc: 0.5625
No improvement (7/10).
Epoch [12/50], Loss: 0.5928, Train Acc: 0.7500
Validation Acc: 0.5781
No improvement (8/10).
Epoch [13/50], Loss: 0.5868, Train Acc: 0.7617
Validation Acc: 0.5781
No improvement (9/10).
Epoch [14/50], Loss: 0.5920, Train Acc: 0.7578
Validation Acc: 0.5625
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.65 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.25s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_1_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.66s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_2_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.32s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.81s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_3_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.21s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.64s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.72s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_4_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.16s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.62s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.70s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_5_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.20s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.70s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.78s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_6_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.35s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.85s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_7_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.60s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.68s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_8_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020603925441389413, 'rho': 6425.394353115255, 'd': 0.734649885934854, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations:  50%|█████     | 1/2 [31:56<31:56, 1916.18s/it]/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:32: RuntimeWarning: invalid value encountered in multiply
  ACmRNA_eq = sp.exp(-d * t) * (
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:33: RuntimeWarning: invalid value encountered in multiply
  d * sp.exp((d - sigma_u - sigma_b) * t) * rho * sigma_u
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last ten iterations.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The number of calls to function has reached maxfev = 400.
  solution = fsolve(
/home/ianyang/stochastic_simulations/src/simulation/mean_var_autocorr.py:166: RuntimeWarning: The iteration is not making good progress, as measured by the 
 improvement from the last five Jacobian evaluations.
  solution = fsolve(
<lambdifygenerated-44178>:2: RuntimeWarning: overflow encountered in exp
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
<lambdifygenerated-44178>:2: RuntimeWarning: invalid value encountered in scalar multiply
  return array([[sigma_b/(d*(sigma_b + 18.0)), -0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -rho*sigma_b/(d**2*(sigma_b + 18.0))], [0.111111111111111*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) + sigma_b/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.00617283950617284*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**3*(d + sigma_b + 18.0)) + 0.0555555555555556*rho**2/(d*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - 0.00308641975308642*rho*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2) + rho/(d*(sigma_b + 18.0)), -0.000171467764060357*rho**2*sigma_b/(d*(0.0555555555555556*sigma_b + 1)**2*(0.0555555555555556*d + 0.0555555555555556*sigma_b + 1)**2) - 0.0555555555555556*rho**2*sigma_b/(d**2*(0.0555555555555556*sigma_b + 1)**2*(d + sigma_b + 18.0)) - rho*sigma_b/(d**2*(sigma_b + 18.0))], [-0.000171467764060357*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + (2.74139635404827e-7*d*exp(d - sigma_b) - 18.0*sigma_b - 324.0)*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*(-d - 2.0*sigma_b - 36.0)*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) + 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (d**2 - 2.74139635404827e-7*d*rho*exp(d - sigma_b) - 18.0*rho - 324.0*(0.0555555555555556*sigma_b + 1)**2 - (sigma_b + 18.0)*(2.0*sigma_b + 36.0))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)), 9.52598689224204e-6*(-sigma_b - 18.0)*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(0.00308641975308642*d*(sigma_b + 18.0) + 0.0555555555555556*rho + (0.0555555555555556*sigma_b + 1)**2)**2) - (2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) - 0.00308641975308642*(2.74139635404827e-7*d*rho*exp(d - sigma_b) - (sigma_b + 18.0)*(-d**2 + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))*exp(-d)/((0.0555555555555556*d - 0.0555555555555556*sigma_b - 1)**2*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2)) + (2.74139635404827e-7*d*rho*exp(d - sigma_b) + 2*d*(sigma_b + 18.0) + 2.74139635404827e-7*rho*exp(d - sigma_b))*exp(-d)/((d - sigma_b - 18.0)*(d*(sigma_b + 18.0) + 18.0*rho + 324.0*(0.0555555555555556*sigma_b + 1)**2))]])
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.060145439998484096, 'rho': 1179.133813799024, 'd': 0.7827636158617373, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3432_1200/steady_state_trajectories/m_traj_3432.0_1200.0_9_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 11.21
    - Variance: 3746.38

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.68 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.71 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2670, Train Acc: 0.5234
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8434, Train Acc: 0.6094
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7788, Train Acc: 0.6719
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/100], Loss: 0.6569, Train Acc: 0.6836
Validation Acc: 0.5156
No improvement (2/10).
Epoch [5/100], Loss: 0.5639, Train Acc: 0.7305
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4729, Train Acc: 0.8086
Validation Acc: 0.5781
No improvement (1/10).
Epoch [7/100], Loss: 0.4550, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3657, Train Acc: 0.8477
Validation Acc: 0.6406
Epoch [9/100], Loss: 0.3415, Train Acc: 0.8477
Validation Acc: 0.6406
No improvement (1/10).
Epoch [10/100], Loss: 0.4156, Train Acc: 0.8242
Validation Acc: 0.6250
No improvement (2/10).
Epoch [11/100], Loss: 0.3012, Train Acc: 0.8555
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/100], Loss: 0.3385, Train Acc: 0.8438
Validation Acc: 0.6406
No improvement (4/10).
Epoch [13/100], Loss: 0.2879, Train Acc: 0.8750
Validation Acc: 0.6250
No improvement (5/10).
Epoch [14/100], Loss: 0.2828, Train Acc: 0.8594
Validation Acc: 0.6250
No improvement (6/10).
Epoch [15/100], Loss: 0.2319, Train Acc: 0.8945
Validation Acc: 0.6094
No improvement (7/10).
Epoch [16/100], Loss: 0.2225, Train Acc: 0.8945
Validation Acc: 0.6406
No improvement (8/10).
Epoch [17/100], Loss: 0.1934, Train Acc: 0.8984
Validation Acc: 0.6719
Epoch [18/100], Loss: 0.2108, Train Acc: 0.9102
Validation Acc: 0.6719
No improvement (1/10).
Epoch [19/100], Loss: 0.2294, Train Acc: 0.9062
Validation Acc: 0.6719
No improvement (2/10).
Epoch [20/100], Loss: 0.1721, Train Acc: 0.9258
Validation Acc: 0.6875
Epoch [21/100], Loss: 0.2531, Train Acc: 0.8750
Validation Acc: 0.6875
No improvement (1/10).
Epoch [22/100], Loss: 0.1774, Train Acc: 0.9180
Validation Acc: 0.6719
No improvement (2/10).
Epoch [23/100], Loss: 0.1755, Train Acc: 0.9375
Validation Acc: 0.7031
Epoch [24/100], Loss: 0.1564, Train Acc: 0.9570
Validation Acc: 0.7344
Epoch [25/100], Loss: 0.1705, Train Acc: 0.9375
Validation Acc: 0.7500
Epoch [26/100], Loss: 0.1397, Train Acc: 0.9375
Validation Acc: 0.7344
No improvement (1/10).
Epoch [27/100], Loss: 0.1521, Train Acc: 0.9297
Validation Acc: 0.7344
No improvement (2/10).
Epoch [28/100], Loss: 0.1600, Train Acc: 0.9375
Validation Acc: 0.7188
No improvement (3/10).
Epoch [29/100], Loss: 0.1350, Train Acc: 0.9492
Validation Acc: 0.7188
No improvement (4/10).
Epoch [30/100], Loss: 0.1338, Train Acc: 0.9570
Validation Acc: 0.6875
No improvement (5/10).
Epoch [31/100], Loss: 0.1170, Train Acc: 0.9453
Validation Acc: 0.6875
No improvement (6/10).
Epoch [32/100], Loss: 0.1441, Train Acc: 0.9492
Validation Acc: 0.6719
No improvement (7/10).
Epoch [33/100], Loss: 0.0946, Train Acc: 0.9531
Validation Acc: 0.6875
No improvement (8/10).
Epoch [34/100], Loss: 0.0931, Train Acc: 0.9727
Validation Acc: 0.6719
No improvement (9/10).
Epoch [35/100], Loss: 0.1560, Train Acc: 0.9375
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.65 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4961
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6873, Train Acc: 0.6797
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6667, Train Acc: 0.8398
Validation Acc: 0.8281
Epoch [4/50], Loss: 0.6174, Train Acc: 0.8516
Validation Acc: 0.7969
No improvement (1/10).
Epoch [5/50], Loss: 0.5858, Train Acc: 0.8828
Validation Acc: 0.8750
Epoch [6/50], Loss: 0.5700, Train Acc: 0.8281
Validation Acc: 0.5938
No improvement (1/10).
Epoch [7/50], Loss: 0.5711, Train Acc: 0.7852
Validation Acc: 0.5625
No improvement (2/10).
Epoch [8/50], Loss: 0.5581, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5603, Train Acc: 0.8086
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5447, Train Acc: 0.8438
Validation Acc: 0.5469
No improvement (5/10).
Epoch [11/50], Loss: 0.5557, Train Acc: 0.8203
Validation Acc: 0.5781
No improvement (6/10).
Epoch [12/50], Loss: 0.5427, Train Acc: 0.8477
Validation Acc: 0.7656
No improvement (7/10).
Epoch [13/50], Loss: 0.5485, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5484, Train Acc: 0.8164
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5293, Train Acc: 0.8516
Validation Acc: 0.8594
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.90 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6932, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6890, Train Acc: 0.6289
Validation Acc: 0.6094
Epoch [3/50], Loss: 0.6764, Train Acc: 0.6562
Validation Acc: 0.6406
Epoch [4/50], Loss: 0.6544, Train Acc: 0.6797
Validation Acc: 0.7031
Epoch [5/50], Loss: 0.6262, Train Acc: 0.7930
Validation Acc: 0.6094
No improvement (1/10).
Epoch [6/50], Loss: 0.6176, Train Acc: 0.7734
Validation Acc: 0.4844
No improvement (2/10).
Epoch [7/50], Loss: 0.6770, Train Acc: 0.6094
Validation Acc: 0.7031
No improvement (3/10).
Epoch [8/50], Loss: 0.5935, Train Acc: 0.7695
Validation Acc: 0.6719
No improvement (4/10).
Epoch [9/50], Loss: 0.6026, Train Acc: 0.7500
Validation Acc: 0.6875
No improvement (5/10).
Epoch [10/50], Loss: 0.6036, Train Acc: 0.7422
Validation Acc: 0.7031
No improvement (6/10).
Epoch [11/50], Loss: 0.5984, Train Acc: 0.7656
Validation Acc: 0.7188
Epoch [12/50], Loss: 0.5941, Train Acc: 0.7578
Validation Acc: 0.7344
Epoch [13/50], Loss: 0.5859, Train Acc: 0.7773
Validation Acc: 0.7188
No improvement (1/10).
Epoch [14/50], Loss: 0.5727, Train Acc: 0.7930
Validation Acc: 0.7188
No improvement (2/10).
Epoch [15/50], Loss: 0.5745, Train Acc: 0.7891
Validation Acc: 0.7031
No improvement (3/10).
Epoch [16/50], Loss: 0.5963, Train Acc: 0.7500
Validation Acc: 0.6719
No improvement (4/10).
Epoch [17/50], Loss: 0.6024, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (5/10).
Epoch [18/50], Loss: 0.5923, Train Acc: 0.7422
Validation Acc: 0.6406
No improvement (6/10).
Epoch [19/50], Loss: 0.5864, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (7/10).
Epoch [20/50], Loss: 0.5870, Train Acc: 0.7656
Validation Acc: 0.6406
No improvement (8/10).
Epoch [21/50], Loss: 0.5848, Train Acc: 0.7617
Validation Acc: 0.6406
No improvement (9/10).
Epoch [22/50], Loss: 0.5917, Train Acc: 0.7578
Validation Acc: 0.6406
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.69 ===
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
Attempt 9/10
Attempt 10/10
No suitable solution found after multiple attempts. Try increasing num_guesses or widening the ranges.
[STRESS] ❌ No suitable solution found.
Attempt 1/10
Attempt 2/10
Attempt 3/10
Attempt 4/10
Attempt 5/10
Attempt 6/10
Attempt 7/10
Attempt 8/10
[STRESS] ✅ Found: {'rho': 6515.3216765888155, 'sigma_b': 0.020319287834215237, 'd': 0.734652335310692}
Attempt 1/10
[NORMAL] ✅ Found: {'rho': 1179.1338138059539, 'sigma_b': 0.06014543999849533, 'd': 0.7827636158617439}
Updated Parameter Sets: [{'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}, {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}]

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:05<00:05,  5.99s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.72s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_0_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 9.65
    - Variance: 2995.46

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.59
    - Variance: 1068.47
=== SVM (RBF Kernel) Classification Accuracy: 0.72 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.54 ===
=== Random Forest Accuracy: 0.79 ===
=== Logistic Regression Accuracy: 0.55 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.2976, Train Acc: 0.5273
Validation Acc: 0.5156
Epoch [2/100], Loss: 0.8373, Train Acc: 0.6523
Validation Acc: 0.5312
Epoch [3/100], Loss: 0.8474, Train Acc: 0.6445
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6189, Train Acc: 0.7344
Validation Acc: 0.5625
No improvement (1/10).
Epoch [5/100], Loss: 0.5326, Train Acc: 0.7539
Validation Acc: 0.5781
Epoch [6/100], Loss: 0.4614, Train Acc: 0.7891
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/100], Loss: 0.5481, Train Acc: 0.8008
Validation Acc: 0.5938
Epoch [8/100], Loss: 0.3597, Train Acc: 0.8477
Validation Acc: 0.6250
Epoch [9/100], Loss: 0.4784, Train Acc: 0.8008
Validation Acc: 0.5938
No improvement (1/10).
Epoch [10/100], Loss: 0.2694, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (2/10).
Epoch [11/100], Loss: 0.2924, Train Acc: 0.8711
Validation Acc: 0.6875
Epoch [12/100], Loss: 0.2968, Train Acc: 0.8672
Validation Acc: 0.6562
No improvement (1/10).
Epoch [13/100], Loss: 0.3034, Train Acc: 0.8633
Validation Acc: 0.6562
No improvement (2/10).
Epoch [14/100], Loss: 0.2682, Train Acc: 0.8789
Validation Acc: 0.7031
Epoch [15/100], Loss: 0.2480, Train Acc: 0.8867
Validation Acc: 0.7031
No improvement (1/10).
Epoch [16/100], Loss: 0.2771, Train Acc: 0.8867
Validation Acc: 0.6562
No improvement (2/10).
Epoch [17/100], Loss: 0.2058, Train Acc: 0.9102
Validation Acc: 0.6250
No improvement (3/10).
Epoch [18/100], Loss: 0.2876, Train Acc: 0.8984
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2302, Train Acc: 0.9062
Validation Acc: 0.6406
No improvement (5/10).
Epoch [20/100], Loss: 0.1915, Train Acc: 0.9297
Validation Acc: 0.6250
No improvement (6/10).
Epoch [21/100], Loss: 0.2171, Train Acc: 0.9141
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1950, Train Acc: 0.9062
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2226, Train Acc: 0.9023
Validation Acc: 0.6094
No improvement (9/10).
Epoch [24/100], Loss: 0.1965, Train Acc: 0.9180
Validation Acc: 0.6250
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6930, Train Acc: 0.4922
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6874, Train Acc: 0.7031
Validation Acc: 0.5000
No improvement (1/10).
Epoch [3/50], Loss: 0.6680, Train Acc: 0.8008
Validation Acc: 0.6719
Epoch [4/50], Loss: 0.6268, Train Acc: 0.8242
Validation Acc: 0.6406
No improvement (1/10).
Epoch [5/50], Loss: 0.5891, Train Acc: 0.8516
Validation Acc: 0.7812
Epoch [6/50], Loss: 0.5814, Train Acc: 0.8125
Validation Acc: 0.8594
Epoch [7/50], Loss: 0.5922, Train Acc: 0.7578
Validation Acc: 0.9375
Epoch [8/50], Loss: 0.5727, Train Acc: 0.8047
Validation Acc: 0.9062
No improvement (1/10).
Epoch [9/50], Loss: 0.5639, Train Acc: 0.8242
Validation Acc: 0.8438
No improvement (2/10).
Epoch [10/50], Loss: 0.5548, Train Acc: 0.8320
Validation Acc: 0.9375
No improvement (3/10).
Epoch [11/50], Loss: 0.5636, Train Acc: 0.8242
Validation Acc: 0.9219
No improvement (4/10).
Epoch [12/50], Loss: 0.5554, Train Acc: 0.8086
Validation Acc: 0.8906
No improvement (5/10).
Epoch [13/50], Loss: 0.5603, Train Acc: 0.7852
Validation Acc: 0.9375
No improvement (6/10).
Epoch [14/50], Loss: 0.5577, Train Acc: 0.7734
Validation Acc: 0.9375
No improvement (7/10).
Epoch [15/50], Loss: 0.5430, Train Acc: 0.8242
Validation Acc: 0.8906
No improvement (8/10).
Epoch [16/50], Loss: 0.5303, Train Acc: 0.8359
Validation Acc: 0.8750
No improvement (9/10).
Epoch [17/50], Loss: 0.5269, Train Acc: 0.8477
Validation Acc: 0.8906
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.94 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6924, Train Acc: 0.5547
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6850, Train Acc: 0.6523
Validation Acc: 0.5312
Epoch [3/50], Loss: 0.6683, Train Acc: 0.6602
Validation Acc: 0.6094
Epoch [4/50], Loss: 0.6543, Train Acc: 0.6758
Validation Acc: 0.6250
Epoch [5/50], Loss: 0.6450, Train Acc: 0.6797
Validation Acc: 0.5781
No improvement (1/10).
Epoch [6/50], Loss: 0.6307, Train Acc: 0.7109
Validation Acc: 0.6406
Epoch [7/50], Loss: 0.6186, Train Acc: 0.7227
Validation Acc: 0.6719
Epoch [8/50], Loss: 0.6089, Train Acc: 0.7383
Validation Acc: 0.6562
No improvement (1/10).
Epoch [9/50], Loss: 0.6295, Train Acc: 0.6914
Validation Acc: 0.5938
No improvement (2/10).
Epoch [10/50], Loss: 0.6295, Train Acc: 0.6953
Validation Acc: 0.5781
No improvement (3/10).
Epoch [11/50], Loss: 0.6291, Train Acc: 0.6953
Validation Acc: 0.6094
No improvement (4/10).
Epoch [12/50], Loss: 0.6178, Train Acc: 0.7109
Validation Acc: 0.6406
No improvement (5/10).
Epoch [13/50], Loss: 0.6166, Train Acc: 0.7188
Validation Acc: 0.6406
No improvement (6/10).
Epoch [14/50], Loss: 0.6147, Train Acc: 0.7188
Validation Acc: 0.6406
No improvement (7/10).
Epoch [15/50], Loss: 0.6097, Train Acc: 0.7227
Validation Acc: 0.6562
No improvement (8/10).
Epoch [16/50], Loss: 0.6082, Train Acc: 0.7188
Validation Acc: 0.6562
No improvement (9/10).
Epoch [17/50], Loss: 0.6058, Train Acc: 0.7305
Validation Acc: 0.6719
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.56 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.15s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_1_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.22s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_2_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.23s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.77s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.83s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_3_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.08s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.75s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.80s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_4_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.14s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.81s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.86s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_5_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_6_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.11s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.71s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.77s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_7_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.29s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.80s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.88s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_8_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

Simulating Telegraph Model Systems:   0%|          | 0/2 [00:00<?, ?it/s][A
Simulating Telegraph Model Systems:  50%|█████     | 1/2 [00:06<00:06,  6.10s/it][ARunning simulations on 12 cores...
System 1 parameters: {'sigma_u': 18.0, 'sigma_b': 0.020319287834215237, 'rho': 6515.3216765888155, 'd': 0.734652335310692, 'label': 0}

Simulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.69s/it][ASimulating Telegraph Model Systems: 100%|██████████| 2/2 [00:11<00:00,  5.76s/it]
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return self._call_impl(*args, **kwargs)
Running Variance Ratio Simulations: 100%|██████████| 2/2 [1:48:07<00:00, 3477.92s/it]Running Variance Ratio Simulations: 100%|██████████| 2/2 [1:48:07<00:00, 3243.66s/it]
Running simulations on 12 cores...
System 2 parameters: {'sigma_u': 9.0, 'sigma_b': 0.06014543999849533, 'rho': 1179.1338138059539, 'd': 0.7827636158617439, 'label': 1}
Steady state series saved to data_12_04_2025/mRNA_trajectories_variance_3480_1200/steady_state_trajectories/m_traj_3480.0_1200.0_9_SS.csv

=== Statistical Report ===

📊 **Steady-State Statistics:**
  Stressed Condition (after 13.6 min):
    - Mean mRNA Count: 10.09
    - Variance: 3234.57

  Normal Condition (after 12.8 min):
    - Mean mRNA Count: 9.72
    - Variance: 1100.31
=== SVM (RBF Kernel) Classification Accuracy: 0.74 ===
=== SVM (Linear Kernel) Classification Accuracy: 0.55 ===
=== Random Forest Accuracy: 0.68 ===
=== Logistic Regression Accuracy: 0.51 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/100], Loss: 1.4836, Train Acc: 0.4766
Validation Acc: 0.5000
Epoch [2/100], Loss: 0.8505, Train Acc: 0.6484
Validation Acc: 0.5469
Epoch [3/100], Loss: 0.7594, Train Acc: 0.6758
Validation Acc: 0.5625
Epoch [4/100], Loss: 0.6750, Train Acc: 0.6719
Validation Acc: 0.6094
Epoch [5/100], Loss: 0.6131, Train Acc: 0.7461
Validation Acc: 0.5469
No improvement (1/10).
Epoch [6/100], Loss: 0.5204, Train Acc: 0.7812
Validation Acc: 0.6250
Epoch [7/100], Loss: 0.4601, Train Acc: 0.7930
Validation Acc: 0.5781
No improvement (1/10).
Epoch [8/100], Loss: 0.4406, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (2/10).
Epoch [9/100], Loss: 0.4037, Train Acc: 0.8242
Validation Acc: 0.5781
No improvement (3/10).
Epoch [10/100], Loss: 0.4177, Train Acc: 0.7969
Validation Acc: 0.5469
No improvement (4/10).
Epoch [11/100], Loss: 0.3524, Train Acc: 0.8398
Validation Acc: 0.6094
No improvement (5/10).
Epoch [12/100], Loss: 0.3681, Train Acc: 0.8320
Validation Acc: 0.5938
No improvement (6/10).
Epoch [13/100], Loss: 0.2954, Train Acc: 0.8789
Validation Acc: 0.5781
No improvement (7/10).
Epoch [14/100], Loss: 0.2765, Train Acc: 0.8750
Validation Acc: 0.6406
Epoch [15/100], Loss: 0.3485, Train Acc: 0.8398
Validation Acc: 0.5938
No improvement (1/10).
Epoch [16/100], Loss: 0.3453, Train Acc: 0.8633
Validation Acc: 0.5781
No improvement (2/10).
Epoch [17/100], Loss: 0.2228, Train Acc: 0.8789
Validation Acc: 0.5938
No improvement (3/10).
Epoch [18/100], Loss: 0.2159, Train Acc: 0.9141
Validation Acc: 0.5938
No improvement (4/10).
Epoch [19/100], Loss: 0.2732, Train Acc: 0.8828
Validation Acc: 0.5938
No improvement (5/10).
Epoch [20/100], Loss: 0.2204, Train Acc: 0.9219
Validation Acc: 0.5938
No improvement (6/10).
Epoch [21/100], Loss: 0.1842, Train Acc: 0.9180
Validation Acc: 0.6094
No improvement (7/10).
Epoch [22/100], Loss: 0.1847, Train Acc: 0.9297
Validation Acc: 0.6094
No improvement (8/10).
Epoch [23/100], Loss: 0.2255, Train Acc: 0.9062
Validation Acc: 0.5938
No improvement (9/10).
Epoch [24/100], Loss: 0.1819, Train Acc: 0.9375
Validation Acc: 0.5938
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== Multilayer Perceptron (MLP) Accuracy: 0.59 ===
=== Random Classifier Accuracy: 0.45 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5117
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6860, Train Acc: 0.7148
Validation Acc: 0.5156
Epoch [3/50], Loss: 0.6633, Train Acc: 0.8477
Validation Acc: 0.7031
Epoch [4/50], Loss: 0.6079, Train Acc: 0.8750
Validation Acc: 0.8281
Epoch [5/50], Loss: 0.5831, Train Acc: 0.8984
Validation Acc: 0.9062
Epoch [6/50], Loss: 0.5692, Train Acc: 0.8398
Validation Acc: 0.5312
No improvement (1/10).
Epoch [7/50], Loss: 0.5720, Train Acc: 0.8320
Validation Acc: 0.5156
No improvement (2/10).
Epoch [8/50], Loss: 0.5489, Train Acc: 0.8320
Validation Acc: 0.5000
No improvement (3/10).
Epoch [9/50], Loss: 0.5411, Train Acc: 0.8555
Validation Acc: 0.5000
No improvement (4/10).
Epoch [10/50], Loss: 0.5464, Train Acc: 0.8672
Validation Acc: 0.5156
No improvement (5/10).
Epoch [11/50], Loss: 0.5504, Train Acc: 0.8438
Validation Acc: 0.5312
No improvement (6/10).
Epoch [12/50], Loss: 0.5360, Train Acc: 0.8516
Validation Acc: 0.8125
No improvement (7/10).
Epoch [13/50], Loss: 0.5484, Train Acc: 0.8086
Validation Acc: 0.8594
No improvement (8/10).
Epoch [14/50], Loss: 0.5388, Train Acc: 0.8359
Validation Acc: 0.8594
No improvement (9/10).
Epoch [15/50], Loss: 0.5373, Train Acc: 0.8477
Validation Acc: 0.9062
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D and 4-Head Attention Accuracy: 0.82 ===
🔄 Using device: cuda (1 GPUs available)
DEBUG: Optimizer initialized? True
✅ Running on CUDA!
Epoch [1/50], Loss: 0.6928, Train Acc: 0.5195
Validation Acc: 0.5000
Epoch [2/50], Loss: 0.6863, Train Acc: 0.6680
Validation Acc: 0.6250
Epoch [3/50], Loss: 0.6685, Train Acc: 0.6836
Validation Acc: 0.5469
No improvement (1/10).
Epoch [4/50], Loss: 0.6506, Train Acc: 0.7070
Validation Acc: 0.5781
No improvement (2/10).
Epoch [5/50], Loss: 0.6294, Train Acc: 0.7422
Validation Acc: 0.7969
Epoch [6/50], Loss: 0.6164, Train Acc: 0.7305
Validation Acc: 0.7344
No improvement (1/10).
Epoch [7/50], Loss: 0.6213, Train Acc: 0.7109
Validation Acc: 0.7656
No improvement (2/10).
Epoch [8/50], Loss: 0.6109, Train Acc: 0.7305
Validation Acc: 0.8125
Epoch [9/50], Loss: 0.5878, Train Acc: 0.7734
Validation Acc: 0.7500
No improvement (1/10).
Epoch [10/50], Loss: 0.6597, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (2/10).
Epoch [11/50], Loss: 0.6596, Train Acc: 0.6406
Validation Acc: 0.6250
No improvement (3/10).
Epoch [12/50], Loss: 0.6634, Train Acc: 0.6289
Validation Acc: 0.6875
No improvement (4/10).
Epoch [13/50], Loss: 0.6510, Train Acc: 0.6484
Validation Acc: 0.7344
No improvement (5/10).
Epoch [14/50], Loss: 0.6472, Train Acc: 0.6523
Validation Acc: 0.7188
No improvement (6/10).
Epoch [15/50], Loss: 0.6555, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (7/10).
Epoch [16/50], Loss: 0.6540, Train Acc: 0.6406
Validation Acc: 0.7031
No improvement (8/10).
Epoch [17/50], Loss: 0.6521, Train Acc: 0.6367
Validation Acc: 0.6875
No improvement (9/10).
Epoch [18/50], Loss: 0.6437, Train Acc: 0.6445
Validation Acc: 0.6875
No improvement (10/10).
Stopping early! No improvement for 10 epochs.
Training complete!
=== LSTM with Conv1D Accuracy: 0.66 ===

⚠️ Variance ratios where STRESS solution failed:
  Index 1, Ratio = 2.9000
