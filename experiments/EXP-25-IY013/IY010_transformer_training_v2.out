ğŸš€ TF Transformer Training Pipeline
==================================================
ğŸ“Š Loading 1577 synthetic CSV files...
ğŸ“ˆ Loaded 315400 trajectories from synthetic data
ğŸ“Š Loading experimental data from 19316_2020_10_26_steadystate_glucose_144m_2w2_00_post_media_switch.tsv...
ğŸ“ˆ Loaded 233 trajectories from experimental data
ğŸ·ï¸  Classes: ['1344_6', '1346_4', '1347'] â†’ [0, 1, 2]
âœ… CUDA detected, using GPU: NVIDIA GeForce RTX 2080 SUPER
ğŸ”§ Initializing TFTransformer with config: ModelCfg(n_classes=3, d_model=128, n_heads=4, n_layers=2, d_ff=128, dropout=0.1, max_len=2048, verbose=True, learning_rate=0.01, optimizer='AdamW', gradient_clip=1.0, label_smoothing=0.0)
ğŸ–¥ï¸  Using device: cuda
ğŸš€ CUDA available with 1 GPU(s)
   GPU 0: NVIDIA GeForce RTX 2080 SUPER
â„¹ï¸  Single GPU detected, using single GPU training
ğŸ”§ Training setup complete with AdamW optimizer
ğŸ“Š Model initialized with 199,939 total parameters (199,939 trainable)
ğŸ—ï¸  Model created with 3 classes

ğŸ­ === PRE-TRAINING ON SYNTHETIC DATA ===
ğŸ“Š Training set: 252320 samples
ğŸ“Š Validation set: 63080 samples
ğŸ”§ Training setup complete with AdamW optimizer
âœ… Running on CUDA!
ğŸ”„ Starting forward pass (batch size: 64, seq length: 2000)
ğŸ“¤ Forward pass complete, output shape: torch.Size([64, 3])
ğŸ“¤ Forward pass complete, output shape: torch.Size([64, 3])
ğŸ“¤ Forward pass complete, output shape: torch.Size([64, 3])
Epoch [1/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
ğŸ’¾ Saving model to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY010/IY010_pretrained.pt
âœ… Model saved successfully
ğŸ’¾ Best model saved (Val Acc: 0.5011)
Epoch [2/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
No improvement (1/5)
Epoch [3/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
No improvement (2/5)
Epoch [4/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
No improvement (3/5)
Epoch [5/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
No improvement (4/5)
Epoch [6/50], Loss: nan, Train Acc: 0.5001
Validation Acc: 0.5011
No improvement (5/5)
ğŸ›‘ Early stopping after 5 epochs without improvement
ğŸ‰ Training complete!
âœ… Pretraining complete! Best validation accuracy: 0.5011

ğŸ”§ === FINE-TUNING ON EXPERIMENTAL DATA ===
ğŸ”’ Freezing encoder components for transfer learning
ğŸ“Š 27/29 parameters frozen
ğŸ”„ Resetting classifier head weights
âœ… Classifier head reset complete
ğŸ“Š Training set: 187 samples
ğŸ“Š Validation set: 46 samples
ğŸ”§ Training setup complete with AdamW optimizer
âœ… Running on CUDA!
Epoch [1/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
ğŸ’¾ Saving model to /home/ianyang/stochastic_simulations/experiments/EXP-25-IY010/IY010_finetuned.pt
âœ… Model saved successfully
ğŸ’¾ Best model saved (Val Acc: 0.2826)
Epoch [2/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
No improvement (1/5)
Epoch [3/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
No improvement (2/5)
Epoch [4/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
No improvement (3/5)
Epoch [5/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
No improvement (4/5)
Epoch [6/10], Loss: nan, Train Acc: 0.3102
Validation Acc: 0.2826
No improvement (5/5)
ğŸ›‘ Early stopping after 5 epochs without improvement
ğŸ‰ Training complete!
âœ… Fine-tuning complete! Best validation accuracy: 0.2826

ğŸ“‹ === TRAINING SUMMARY ===
ğŸ­ Pretraining: 6 epochs
   Best training accuracy: 0.5001
   Best validation accuracy: 0.5011
ğŸ”§ Fine-tuning: 6 epochs
   Best training accuracy: 0.3102
   Best validation accuracy: 0.2826

ğŸ’¾ Models saved in: /home/ianyang/stochastic_simulations/experiments/EXP-25-IY010
ğŸ‰ Training pipeline complete!
