{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711ac4d6",
   "metadata": {},
   "source": [
    "# IY011 Contrastive Learning Model Training (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504a2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from visualisation.plots import plot_mRNA_dist, plot_mRNA_trajectory\n",
    "# ml\n",
    "import torch, itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from models.siamese_transformer import SiameseTransformer\n",
    "from training.eval import evaluate_model\n",
    "from training.train import train_model \n",
    "\n",
    "# data handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build groups\n",
    "from utils.data_processing import build_groups\n",
    "import wandb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72efedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/home/ianyang/stochastic_simulations/experiments/EXP-25-IY011/data\")\n",
    "RESULTS_PATH = DATA_ROOT / \"IY011_simulation_parameters_sobol.csv\" #  this csv file stores all the simulation parameters used\n",
    "df_params = pd.read_csv(RESULTS_PATH) \n",
    "# TRAJ_PATH = [DATA_ROOT / f\"mRNA_trajectories_mu{row['mu_target']:.3f}_cv{row['cv_target']:.3f}_tac{row['t_ac_target']:.3f}.csv\" for idx, row in df_params.iterrows()] # the trajectories \n",
    "TRAJ_PATH = [DATA_ROOT / df_params['trajectory_filename'].values[i] for i in range(len(df_params))]\n",
    "TRAJ_NPZ_PATH = [traj_file.with_suffix('.npz') for traj_file in TRAJ_PATH]\n",
    "\n",
    "# extract meta data\n",
    "parameter_sets = [{\n",
    "    'sigma_b': row['sigma_b'],\n",
    "    'sigma_u': row['sigma_u'],\n",
    "    'rho': row['rho'],\n",
    "    'd': row['d'],\n",
    "    'label': 0\n",
    "} for idx, row in df_params.iterrows()]\n",
    "time_points = np.arange(0, 3000, 1.0)\n",
    "size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a036fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.data_processing import build_groups  # Assumes your file is accessible\n",
    "\n",
    "class SiameseGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps the output of build_groups (list of (X, y)) into the \n",
    "    (x1, x2, y) format required by the SiameseTransformer.\n",
    "    \"\"\"\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # X has shape (seq_len, 2) because num_traj=2\n",
    "        # y is scalar (0 or 1)\n",
    "        X, y = self.groups[idx]\n",
    "        \n",
    "        # Split the stacked trajectories into two separate inputs\n",
    "        # Slicing keeps the last dimension: (seq_len, 1)\n",
    "        x1 = X[:, 0:1]\n",
    "        x2 = X[:, 1:2]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(x1, dtype=torch.float32),\n",
    "            torch.tensor(x2, dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.float32).unsqueeze(0) # Target must be (1,) for BCE\n",
    "        )\n",
    "\n",
    "def siamese_data_prep(\n",
    "    all_file_paths, \n",
    "    batch_size=64, \n",
    "    num_groups_train=1000, \n",
    "    num_groups_val=200,\n",
    "    num_groups_test=200,\n",
    "    num_traj=2,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares DataLoaders for Siamese training using Instance Discrimination.\n",
    "    \n",
    "    1. Splits FILES (not samples) into Train/Val/Test.\n",
    "    2. Calls build_groups on disjoint file sets to create Positive/Negative pairs.\n",
    "    3. Fits a Global Scaler on Training data only (preserves mu/cv differences).\n",
    "    4. Wraps in SiameseGroupDataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Split Files (Simulations) to prevent leakage\n",
    "    #    We want the model to generalize to *new* simulations, not just new crops of known ones.\n",
    "    train_files, test_files = train_test_split(all_file_paths, test_size=0.2, random_state=seed)\n",
    "    train_files, val_files  = train_test_split(train_files, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    print(f\"Files split: {len(train_files)} Train, {len(val_files)} Val, {len(test_files)} Test\")\n",
    "\n",
    "    # 2. Build Groups (Pairs) using your existing logic\n",
    "    #    Force num_traj=2 to generate PAIRS (x1, x2)\n",
    "    print(\"Building training pairs...\")\n",
    "    train_groups = build_groups(train_files, num_groups=num_groups_train, num_traj=num_traj, seed=seed)\n",
    "    \n",
    "    print(\"Building validation pairs...\")\n",
    "    val_groups   = build_groups(val_files,   num_groups=num_groups_val,   num_traj=num_traj, seed=seed)\n",
    "    \n",
    "    print(\"Building test pairs...\")\n",
    "    test_groups  = build_groups(test_files,  num_groups=num_groups_test,  num_traj=num_traj, seed=seed)\n",
    "\n",
    "    # 3. Global Scaling (Fit on Train, Transform All)\n",
    "    #    This preserves relative differences (e.g., low mu vs high mu) while standardizing range.\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Collect all training data to fit scaler\n",
    "    # train_groups is [(X, y), ...]. X is (seq_len, 2)\n",
    "    # We flatten everything to (Total_Samples * 2, 1) to fit the scaler to the 'value' distribution\n",
    "    all_train_values = []\n",
    "    for X, y in train_groups:\n",
    "        all_train_values.append(X) # Append (seq_len, 2)\n",
    "    \n",
    "    # Concatenate and reshape to (-1, 1) for scaling\n",
    "    if len(all_train_values) > 0:\n",
    "        train_stack = np.vstack(all_train_values)\n",
    "        # Reshape to (N*seq_len*2, 1) - treating every timepoint as a sample for scaling\n",
    "        scaler.fit(train_stack.reshape(-1, 1))\n",
    "        print(\"Global scaler fitted on training data.\")\n",
    "    \n",
    "    # Apply Transform helper\n",
    "    def scale_groups(group_list):\n",
    "        scaled_list = []\n",
    "        for X, y in group_list:\n",
    "            # X is (seq_len, 2). Reshape -> Scale -> Reshape back\n",
    "            shape = X.shape\n",
    "            X_scaled = scaler.transform(X.reshape(-1, 1)).reshape(shape)\n",
    "            scaled_list.append((X_scaled, y))\n",
    "        return scaled_list\n",
    "\n",
    "    train_groups = scale_groups(train_groups)\n",
    "    val_groups   = scale_groups(val_groups)\n",
    "    test_groups  = scale_groups(test_groups)\n",
    "\n",
    "    # 4. Wrap in Datasets and Loaders\n",
    "    train_ds = SiameseGroupDataset(train_groups)\n",
    "    val_ds   = SiameseGroupDataset(val_groups)\n",
    "    test_ds  = SiameseGroupDataset(test_groups)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataloader hyperparams & data prep ===\n",
    "batch_size = 64\n",
    "num_groups_train=4000  \n",
    "num_groups_val=800\n",
    "num_groups_test=800\n",
    "num_traj=2\n",
    "train_loader, val_loader, test_loader = siamese_data_prep(\n",
    "    TRAJ_NPZ_PATH,\n",
    "    batch_size=batch_size,\n",
    "    num_groups_train=num_groups_train,  # Generate 100 pairs for training\n",
    "    num_groups_val=num_groups_val,\n",
    "    num_groups_test=num_groups_test,\n",
    "    num_traj=num_traj,\n",
    ")\n",
    "# === Dataloader hyperparams & data prep ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e59ca",
   "metadata": {},
   "source": [
    "V2: Sequence cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e70748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseGroupDataset(Dataset):\n",
    "    def __init__(self, groups, crop_len=200, training=True):\n",
    "        \"\"\"\n",
    "        groups: List of (X, y)\n",
    "        crop_len: Length of the time window to slice\n",
    "        training: If True, crops randomly. If False, takes the center crop (deterministic).\n",
    "        \"\"\"\n",
    "        self.groups = groups\n",
    "        self.crop_len = crop_len\n",
    "        self.training = training\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # X has shape (Original_Seq_Len, 2)\n",
    "        X, y = self.groups[idx]\n",
    "        seq_len = X.shape[0]\n",
    "        \n",
    "        if seq_len > self.crop_len:\n",
    "            if self.training:\n",
    "                # Random crop for training\n",
    "                start = np.random.randint(0, seq_len - self.crop_len)\n",
    "            else:\n",
    "                # Center crop for validation/testing (deterministic)\n",
    "                start = (seq_len - self.crop_len) // 2\n",
    "            \n",
    "            X_crop = X[start : start + self.crop_len, :]\n",
    "        else:\n",
    "            # If sequence is shorter than crop_len, pad it (or just return as is if acceptable)\n",
    "            # Simple padding logic:\n",
    "            pad_len = self.crop_len - seq_len\n",
    "            # Pad with zeros at the end\n",
    "            X_crop = np.pad(X, ((0, pad_len), (0, 0)), mode='constant')\n",
    "\n",
    "        # Split into x1 and x2\n",
    "        return (\n",
    "            torch.tensor(X_crop[:, 0:1], dtype=torch.float32),\n",
    "            torch.tensor(X_crop[:, 1:2], dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "def siamese_data_prep(all_file_paths, \n",
    "                      batch_size=64,     \n",
    "                      num_groups_train=1000, \n",
    "                      num_groups_val=200,\n",
    "                      num_groups_test=200, \n",
    "                      seed=42\n",
    "                      ):\n",
    "    # 1. Split Files\n",
    "    train_files, test_files = train_test_split(all_file_paths, test_size=0.2, random_state=seed)\n",
    "    train_files, val_files  = train_test_split(train_files, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # 2. Build Groups (Raw length)\n",
    "    # Note: We generate MANY pairs now (20,000)\n",
    "    print(\"Building pairs...\")\n",
    "    train_groups = build_groups(train_files, num_groups=num_groups_train, num_traj=2, seed=seed)\n",
    "    val_groups   = build_groups(val_files,   num_groups=num_groups_val, num_traj=2, seed=seed)\n",
    "    test_groups  = build_groups(test_files,  num_groups=num_groups_test, num_traj=2, seed=seed)\n",
    "\n",
    "    # 3. Global Scaling (Fit on Train)\n",
    "    scaler = StandardScaler()\n",
    "    all_train_values = [X for X, y in train_groups]\n",
    "    if len(all_train_values) > 0:\n",
    "        train_stack = np.vstack(all_train_values)\n",
    "        scaler.fit(train_stack.reshape(-1, 1))\n",
    "    \n",
    "    def scale_groups(group_list):\n",
    "        scaled = []\n",
    "        for X, y in group_list:\n",
    "            shape = X.shape\n",
    "            X_sc = scaler.transform(X.reshape(-1, 1)).reshape(shape)\n",
    "            scaled.append((X_sc, y))\n",
    "        return scaled\n",
    "\n",
    "    train_groups = scale_groups(train_groups)\n",
    "    val_groups   = scale_groups(val_groups)\n",
    "    test_groups  = scale_groups(test_groups)\n",
    "\n",
    "    # 4. Create Datasets with CROPPING\n",
    "    # Use crop_len=200 (or 300) depending on your signal dynamics\n",
    "    train_ds = SiameseGroupDataset(train_groups, crop_len=200, training=True)\n",
    "    val_ds   = SiameseGroupDataset(val_groups,   crop_len=200, training=False)\n",
    "    test_ds  = SiameseGroupDataset(test_groups,  crop_len=200, training=False)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db7480",
   "metadata": {},
   "source": [
    "V3: log transform global scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7139f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from modularised code\n",
    "from utils.data_loader import SiameseGroupDataset, siamese_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7b4da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files split: 655 Train, 164 Val, 205 Test\n",
      "Generating 20000 training pairs...\n",
      "Warning: Requested 10000 positive groups but only 655 files available. Sampling files with replacement.\n",
      "Warning: Requested 10000 negative groups (needs 20000 unique files) but only 655 files available. Sampling pairs with replacement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building positive groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 24483.25it/s]\n",
      "Building negative groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:00<00:00, 21469.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation/test pairs...\n",
      "Warning: Requested 1000 positive groups but only 164 files available. Sampling files with replacement.\n",
      "Warning: Requested 1000 negative groups (needs 2000 unique files) but only 164 files available. Sampling pairs with replacement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building positive groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 25987.34it/s]\n",
      "Building negative groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 20268.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Requested 1000 positive groups but only 205 files available. Sampling files with replacement.\n",
      "Warning: Requested 1000 negative groups (needs 2000 unique files) but only 205 files available. Sampling pairs with replacement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building positive groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 26093.72it/s]\n",
      "Building negative groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 20918.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting scaler on Log-Transformed training data...\n",
      "Applying Log-Scaling to all groups...\n"
     ]
    }
   ],
   "source": [
    "# === Dataloader hyperparams & data prep ===\n",
    "batch_size = 64\n",
    "num_groups_train=20000  \n",
    "num_groups_val=num_groups_train // 10\n",
    "num_groups_test=num_groups_train // 10\n",
    "num_traj=2\n",
    "train_loader, val_loader, test_loader = siamese_data_prep(\n",
    "    TRAJ_NPZ_PATH,\n",
    "    batch_size=batch_size,\n",
    "    num_groups_train=num_groups_train,\n",
    "    num_groups_val=num_groups_val,\n",
    "    num_groups_test=num_groups_test,\n",
    ")\n",
    "# === Dataloader hyperparams & data prep ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b852fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataloader hyperparams & data prep ===\n",
    "# batch_size = 64\n",
    "# train_loader, val_loader, test_loader = siamese_data_prep(groups, batch_size)\n",
    "# === Dataloader hyperparams & data prep ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5eebf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 200, 1]) torch.Size([64, 200, 1]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "X1_b, X2_b, y_b = next(iter(train_loader))\n",
    "print(X1_b.shape, X2_b.shape, y_b.shape)\n",
    "# want: [B, T, 1], [B, T, 1], [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bc3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseTransformer(\n",
       "  (backbone): TransformerClassifier(\n",
       "    (input_proj): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (pe): PositionalEncoding()\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.001, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.001, inplace=False)\n",
       "          (dropout2): Dropout(p=0.001, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.001, inplace=False)\n",
       "    (head): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=192, out_features=64, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Model hyperparams ===\n",
    "input_size = 1\n",
    "num_classes = 2\n",
    "d_model=64\n",
    "nhead=4\n",
    "num_layers=2\n",
    "dropout=0.001\n",
    "use_conv1d=False \n",
    "\n",
    "# model = TransformerClassifier(\n",
    "#     input_size=input_size,\n",
    "#     d_model=d_model,\n",
    "#     nhead=nhead,\n",
    "#     num_layers=num_layers,\n",
    "#     num_classes=num_classes,\n",
    "#     dropout=dropout, \n",
    "#     use_conv1d=use_conv1d \n",
    "# )\n",
    "\n",
    "model = SiameseTransformer(\n",
    "    input_size=input_size,   # each trajectory is (T,1)\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    use_conv1d=use_conv1d,\n",
    ")\n",
    "# === Model hyperparams ===\n",
    "\n",
    "# === Training hyperparams ===\n",
    "epochs = 100\n",
    "patience = 10\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "### schedulers ### \n",
    "# 1. simple scheduler choice\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5) \n",
    "\n",
    "# 2. cosine scheduler with warmup, most commonly used for transformer\n",
    "# total_steps = epochs * len(train_loader)\n",
    "# warmup_steps = int(0.1 * total_steps)   # 10% warmup (good default)\n",
    "# #  (from huggingface)\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "# scheduler = get_cosine_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=warmup_steps,\n",
    "#     num_training_steps=total_steps,\n",
    "# ) \n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_clip = 1.0\n",
    "save_path = None\n",
    "verbose = True\n",
    "\n",
    "model.to(device)\n",
    "# === Training hyperparams ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0e4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === wandb config (required for tracking within train_model) ===\n",
    "wandb_config = {\n",
    "    \"entity\": \"grignard-reagent\",\n",
    "    \"project\": \"IY011-contrastive-learning\",\n",
    "    \"name\": f\"siamese_logtransform-feature-diff_num_train_groups_{num_groups_train}\", # change this to what you want\n",
    "    \"dataset\": DATA_ROOT.name,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"input_size\": input_size,\n",
    "    \"d_model\": d_model,\n",
    "    \"nhead\": nhead,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"dropout\": dropout,\n",
    "    \"use_conv1d\": use_conv1d,\n",
    "    \"epochs\": epochs,\n",
    "    \"patience\": patience,\n",
    "    \"lr\": lr,\n",
    "    \"optimizer\": type(optimizer).__name__,\n",
    "    \"scheduler\": type(scheduler).__name__,\n",
    "    \"loss_fn\": type(loss_fn).__name__,\n",
    "    \"model\": type(model).__name__,\n",
    "    \"batch_size\": train_loader.batch_size,\n",
    "    \"num_traj_per_group\": num_traj,\n",
    "    \"num_groups_train\": num_groups_train,\n",
    "    \"num_groups_val\": num_groups_val,\n",
    "    \"num_groups_test\": num_groups_test,\n",
    "}\n",
    "# === wandb config === "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0845e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrignardreagent\u001b[0m (\u001b[33mgrignard-reagent\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ianyang/stochastic_simulations/experiments/EXP-25-IY011/wandb/run-20251123_155304-vstol72z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/vstol72z' target=\"_blank\">siamese_logtransform-feature-diff_num_train_groups_20000</a></strong> to <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/vstol72z' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/vstol72z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting siamese training...\n",
      "[Siamese] Epoch [1/100] | train_loss 0.6533 | train_acc 0.6273 | val_loss 0.6009 | val_acc 0.6540\n",
      "[Siamese] Epoch [2/100] | train_loss 0.5957 | train_acc 0.6818 | val_loss 0.5841 | val_acc 0.7005\n",
      "[Siamese] Epoch [3/100] | train_loss 0.5613 | train_acc 0.7043 | val_loss 0.5263 | val_acc 0.7305\n",
      "[Siamese] Epoch [4/100] | train_loss 0.5327 | train_acc 0.7313 | val_loss 0.5339 | val_acc 0.7345\n",
      "[Siamese] Epoch [5/100] | train_loss 0.5119 | train_acc 0.7441 | val_loss 0.5118 | val_acc 0.7390\n",
      "[Siamese] Epoch [6/100] | train_loss 0.4489 | train_acc 0.7864 | val_loss 0.4371 | val_acc 0.7900\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [7/100] | train_loss 0.4273 | train_acc 0.7992 | val_loss 0.4504 | val_acc 0.7785\n",
      "[Siamese] Epoch [8/100] | train_loss 0.4171 | train_acc 0.8054 | val_loss 0.3807 | val_acc 0.8235\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [9/100] | train_loss 0.4006 | train_acc 0.8165 | val_loss 0.4123 | val_acc 0.8205\n",
      "[Siamese] Epoch [10/100] | train_loss 0.3642 | train_acc 0.8406 | val_loss 0.3554 | val_acc 0.8440\n",
      "[Siamese] Epoch [11/100] | train_loss 0.3469 | train_acc 0.8460 | val_loss 0.3460 | val_acc 0.8470\n",
      "[Siamese] Epoch [12/100] | train_loss 0.3428 | train_acc 0.8528 | val_loss 0.3330 | val_acc 0.8575\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [13/100] | train_loss 0.3290 | train_acc 0.8585 | val_loss 0.3350 | val_acc 0.8500\n",
      "[Siamese] Epoch [14/100] | train_loss 0.3194 | train_acc 0.8638 | val_loss 0.3156 | val_acc 0.8675\n",
      "[Siamese] Epoch [15/100] | train_loss 0.3145 | train_acc 0.8662 | val_loss 0.2968 | val_acc 0.8745\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [16/100] | train_loss 0.3060 | train_acc 0.8716 | val_loss 0.3099 | val_acc 0.8730\n",
      "No improvement (2/10).\n",
      "[Siamese] Epoch [17/100] | train_loss 0.3054 | train_acc 0.8741 | val_loss 0.3076 | val_acc 0.8665\n",
      "[Siamese] Epoch [18/100] | train_loss 0.2960 | train_acc 0.8771 | val_loss 0.2857 | val_acc 0.8855\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [19/100] | train_loss 0.2889 | train_acc 0.8799 | val_loss 0.2821 | val_acc 0.8855\n",
      "No improvement (2/10).\n",
      "[Siamese] Epoch [20/100] | train_loss 0.2894 | train_acc 0.8789 | val_loss 0.2833 | val_acc 0.8830\n",
      "No improvement (3/10).\n",
      "[Siamese] Epoch [21/100] | train_loss 0.2854 | train_acc 0.8812 | val_loss 0.2825 | val_acc 0.8855\n",
      "No improvement (4/10).\n",
      "[Siamese] Epoch [22/100] | train_loss 0.2840 | train_acc 0.8822 | val_loss 0.2773 | val_acc 0.8840\n",
      "[Siamese] Epoch [23/100] | train_loss 0.2805 | train_acc 0.8849 | val_loss 0.2735 | val_acc 0.8885\n",
      "[Siamese] Epoch [24/100] | train_loss 0.2764 | train_acc 0.8866 | val_loss 0.2761 | val_acc 0.8895\n",
      "[Siamese] Epoch [25/100] | train_loss 0.2746 | train_acc 0.8887 | val_loss 0.2772 | val_acc 0.8935\n",
      "[Siamese] Epoch [26/100] | train_loss 0.2748 | train_acc 0.8880 | val_loss 0.2714 | val_acc 0.8945\n",
      "[Siamese] Epoch [27/100] | train_loss 0.2716 | train_acc 0.8874 | val_loss 0.2720 | val_acc 0.8950\n",
      "No improvement (1/10).\n",
      "[Siamese] Epoch [28/100] | train_loss 0.2690 | train_acc 0.8879 | val_loss 0.2747 | val_acc 0.8945\n",
      "No improvement (2/10).\n",
      "[Siamese] Epoch [29/100] | train_loss 0.2736 | train_acc 0.8889 | val_loss 0.2758 | val_acc 0.8900\n",
      "No improvement (3/10).\n",
      "[Siamese] Epoch [30/100] | train_loss 0.2664 | train_acc 0.8904 | val_loss 0.2742 | val_acc 0.8915\n",
      "No improvement (4/10).\n",
      "[Siamese] Epoch [31/100] | train_loss 0.2694 | train_acc 0.8907 | val_loss 0.2735 | val_acc 0.8900\n",
      "No improvement (5/10).\n",
      "[Siamese] Epoch [32/100] | train_loss 0.2671 | train_acc 0.8899 | val_loss 0.2761 | val_acc 0.8935\n",
      "No improvement (6/10).\n",
      "[Siamese] Epoch [33/100] | train_loss 0.2673 | train_acc 0.8917 | val_loss 0.2715 | val_acc 0.8915\n",
      "No improvement (7/10).\n",
      "[Siamese] Epoch [34/100] | train_loss 0.2690 | train_acc 0.8888 | val_loss 0.2700 | val_acc 0.8925\n",
      "No improvement (8/10).\n",
      "[Siamese] Epoch [35/100] | train_loss 0.2687 | train_acc 0.8887 | val_loss 0.2700 | val_acc 0.8910\n",
      "No improvement (9/10).\n",
      "[Siamese] Epoch [36/100] | train_loss 0.2653 | train_acc 0.8908 | val_loss 0.2695 | val_acc 0.8935\n",
      "No improvement (10/10).\n",
      "üõë Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>grad/norm</td><td>‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÅ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>lr</td><td>‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/acc</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val/loss</td><td>‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.895</td></tr><tr><td>epoch</td><td>36</td></tr><tr><td>grad/norm</td><td>1.0</td></tr><tr><td>lr</td><td>4e-05</td></tr><tr><td>train/acc</td><td>0.89075</td></tr><tr><td>train/loss</td><td>0.26534</td></tr><tr><td>training_time_sec</td><td>268.21944</td></tr><tr><td>val/acc</td><td>0.8935</td></tr><tr><td>val/loss</td><td>0.26952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">siamese_logtransform-feature-diff_num_train_groups_20000</strong> at: <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/vstol72z' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/vstol72z</a><br> View project at: <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251123_155304-vstol72z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese training complete.\n"
     ]
    }
   ],
   "source": [
    "from training.train import train_siamese_model\n",
    "history = train_siamese_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=epochs,\n",
    "    patience=patience,\n",
    "    lr=lr,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    grad_clip=grad_clip,\n",
    "    save_path=save_path,\n",
    "    verbose=verbose,\n",
    "    wandb_logging=True, # this enables wandb logging within train_model\n",
    "    wandb_config=wandb_config, # pass the config dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d2ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO train test split, scaling up \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d1f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
