{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea9088f",
   "metadata": {},
   "source": [
    "# IY011 Contrastive Learning: Model Training\n",
    "Randomly pick pairs of samples from the dataset, randomly assign labels to each, and train a model to distinguish them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8ed081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from visualisation.plots import plot_mRNA_dist, plot_mRNA_trajectory\n",
    "# ml\n",
    "import torch, itertools\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from models.transformer import TransformerClassifier\n",
    "from training.eval import evaluate_model\n",
    "from training.train import train_model \n",
    "\n",
    "# data handling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build groups\n",
    "from utils.data_processing import build_groups\n",
    "\n",
    "import wandb\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71487214",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/home/ianyang/stochastic_simulations/experiments/EXP-25-IY011/data\")\n",
    "RESULTS_PATH = DATA_ROOT / \"IY011_simulation_parameters_sobol.csv\" #  this csv file stores all the simulation parameters used\n",
    "df_params = pd.read_csv(RESULTS_PATH) \n",
    "# TRAJ_PATH = [DATA_ROOT / f\"mRNA_trajectories_mu{row['mu_target']:.3f}_cv{row['cv_target']:.3f}_tac{row['t_ac_target']:.3f}.csv\" for idx, row in df_params.iterrows()] # the trajectories \n",
    "TRAJ_PATH = [DATA_ROOT / df_params['trajectory_filename'].values[i] for i in range(len(df_params))]\n",
    "TRAJ_NPZ_PATH = [traj_file.with_suffix('.npz') for traj_file in TRAJ_PATH]\n",
    "\n",
    "# extract meta data\n",
    "parameter_sets = [{\n",
    "    'sigma_b': row['sigma_b'],\n",
    "    'sigma_u': row['sigma_u'],\n",
    "    'rho': row['rho'],\n",
    "    'd': row['d'],\n",
    "    'label': 0\n",
    "} for idx, row in df_params.iterrows()]\n",
    "time_points = np.arange(0, 3000, 1.0)\n",
    "size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8409a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building positive groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 194.35it/s]\n",
      "Building negative groups: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 177.05it/s]\n"
     ]
    }
   ],
   "source": [
    "num_traj = 500\n",
    "NUM_GROUPS = 8 # a pair: 1 pos, 1 neg\n",
    "groups = build_groups(TRAJ_NPZ_PATH, num_groups=NUM_GROUPS, num_traj=num_traj) # list of tuples (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3172cb",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38807e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_samples shape: (4000, 1811, 1), y_samples shape: (4000,)\n",
      "Data preparation:\n",
      "  Train groups: 2560, Val groups: 640, Test groups: 800\n",
      "X_train shape: (2560, 1811, 1)\n",
      "X_val shape: (640, 1811, 1)\n",
      "X_test shape: (800, 1811, 1)\n",
      "torch.Size([8, 1811, 1]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "def data_prep(groups, NUM_GROUPS):\n",
    "    # Stacked groups -> individual trajectory samples\n",
    "    X_samples = []\n",
    "    y_samples = []\n",
    "    for Xg, yg in groups:          # Xg shape (seq_len, K)\n",
    "        L, K = Xg.shape\n",
    "        for k in range(K):\n",
    "            X_samples.append(Xg[:, k:k+1])  # (seq_len, 1)\n",
    "            y_samples.append(yg)            # or some other per-trajectory label\n",
    "    X_samples = np.stack(X_samples, 0)      # (N_samples, seq_len, 1)\n",
    "    y_samples = np.array(y_samples)\n",
    "    print(f'X_samples shape: {X_samples.shape}, y_samples shape: {y_samples.shape}')\n",
    "\n",
    "    # with the stacked samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_samples, y_samples, test_size=0.2, random_state=42, stratify=y_samples\n",
    "    )\n",
    "    X_train, X_val,  y_train, y_val  = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "\n",
    "    print(\"Data preparation:\")\n",
    "    print(f\"  Train groups: {len(y_train)}, Val groups: {len(y_val)}, Test groups: {len(y_test)}\")\n",
    "    # === Standardise features (across time*batch, per-channel) ===\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Reshape 3D data to 2D for scaling\n",
    "    original_shape_train = X_train.shape\n",
    "    original_shape_val = X_val.shape\n",
    "    original_shape_test = X_test.shape\n",
    "\n",
    "    # Reshape to 2D: (batch * seq_len, features)\n",
    "    X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "    X_val_2d = X_val.reshape(-1, X_val.shape[-1])\n",
    "    X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_2d = scaler.fit_transform(X_train_2d)\n",
    "    X_val_2d = scaler.transform(X_val_2d)\n",
    "    X_test_2d = scaler.transform(X_test_2d)\n",
    "\n",
    "    # Reshape back to 3D\n",
    "    X_train = X_train_2d.reshape(original_shape_train)\n",
    "    X_val = X_val_2d.reshape(original_shape_val)\n",
    "    X_test = X_test_2d.reshape(original_shape_test)\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    \n",
    "    # Torch loaders\n",
    "    batch_size = NUM_GROUPS # TODO: Need to re-adjust this\n",
    "\n",
    "    # === Convert to tensors and loaders ===\n",
    "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
    "    y_val_t   = torch.tensor(y_val,   dtype=torch.long)\n",
    "    X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "    y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val_t,   y_val_t),   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader  = DataLoader(TensorDataset(X_test_t,  y_test_t),  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # check the data loaders\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        print(X_batch.shape, y_batch.shape)\n",
    "        break \n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "    \n",
    "train_loader, val_loader, test_loader = data_prep(groups, NUM_GROUPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f277332",
   "metadata": {},
   "source": [
    "## Transformer Model Eval\n",
    "start by defining some model & training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianyang/micromamba/envs/stochastic_sim/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerClassifier(\n",
       "  (input_proj): Linear(in_features=1, out_features=64, bias=True)\n",
       "  (pe): PositionalEncoding()\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.001, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.001, inplace=False)\n",
       "        (dropout2): Dropout(p=0.001, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.001, inplace=False)\n",
       "  (head): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Model hyperparams ===\n",
    "input_size = 1\n",
    "num_classes = 2\n",
    "d_model=64\n",
    "nhead=4\n",
    "num_layers=2\n",
    "dropout=0.001\n",
    "use_conv1d=False \n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_size=input_size,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=num_classes,\n",
    "    dropout=dropout, \n",
    "    use_conv1d=use_conv1d \n",
    ")\n",
    "# === Model hyperparams ===\n",
    "\n",
    "# === Training hyperparams ===\n",
    "epochs = 50\n",
    "patience = 10\n",
    "lr = 1e-2\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "### schedulers ### \n",
    "# 1. simple scheduler choice\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5) \n",
    "\n",
    "# 2. cosine scheduler with warmup, most commonly used for transformer\n",
    "total_steps = epochs * len(train_loader)\n",
    "warmup_steps = int(0.1 * total_steps)   # 10% warmup (good default)\n",
    "#  (from huggingface)\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps,\n",
    ") \n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "grad_clip = 1.0\n",
    "save_path = None\n",
    "verbose = True\n",
    "\n",
    "model.to(device)\n",
    "# === Training hyperparams ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01569ceb",
   "metadata": {},
   "source": [
    "wandb logging setup: \n",
    "1. set `wandb_logging=True` in `train_model` function call to enable logging\n",
    "2. pass `wandb_config` dictionary to log hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d6a416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === wandb config (required for tracking within train_model) ===\n",
    "wandb_config = {\n",
    "    \"entity\": \"grignard-reagent\",\n",
    "    \"project\": \"IY011-contrastive-learning\",\n",
    "    \"name\": f\"groups_{NUM_GROUPS}_traj_{num_traj}_random_neg_split\", # change this to what you want\n",
    "    \"dataset\": DATA_ROOT.name,\n",
    "    \"input_size\": input_size,\n",
    "    \"d_model\": d_model,\n",
    "    \"nhead\": nhead,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"dropout\": dropout,\n",
    "    \"use_conv1d\": use_conv1d,\n",
    "    \"epochs\": epochs,\n",
    "    \"patience\": patience,\n",
    "    \"lr\": lr,\n",
    "    \"optimizer\": type(optimizer).__name__,\n",
    "    \"scheduler\": type(scheduler).__name__,\n",
    "    \"loss_fn\": type(loss_fn).__name__,\n",
    "    \"model\": type(model).__name__,\n",
    "    \"batch_size\": train_loader.batch_size,\n",
    "    \"num_traj_per_group\": num_traj,\n",
    "    \"num_groups\": NUM_GROUPS,\n",
    "}\n",
    "# === wandb config === "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d6246",
   "metadata": {},
   "source": [
    "Using modularised code for training and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd9802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgrignardreagent\u001b[0m (\u001b[33mgrignard-reagent\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ianyang/stochastic_simulations/experiments/EXP-25-IY011/wandb/run-20251118_162938-hoo5gm9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/hoo5gm9g' target=\"_blank\">groups_8_traj_500_random_neg_split</a></strong> to <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/hoo5gm9g' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/hoo5gm9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/50] | train_loss 0.9244 | train_acc 0.3418 | val_loss 0.9189 | val_acc 0.3547\n",
      "Epoch [2/50] | train_loss 0.8029 | train_acc 0.3145 | val_loss 0.6956 | val_acc 0.5672\n",
      "Epoch [3/50] | train_loss 0.5424 | train_acc 0.7895 | val_loss 0.4728 | val_acc 0.8172\n",
      "Epoch [4/50] | train_loss 0.4280 | train_acc 0.8352 | val_loss 0.4170 | val_acc 0.8344\n",
      "Epoch [5/50] | train_loss 0.3886 | train_acc 0.8520 | val_loss 0.3820 | val_acc 0.8484\n",
      "Epoch [6/50] | train_loss 0.3700 | train_acc 0.8609 | val_loss 0.3647 | val_acc 0.8547\n",
      "No improvement (1/10).\n",
      "Epoch [7/50] | train_loss 0.3563 | train_acc 0.8598 | val_loss 0.3427 | val_acc 0.8500\n",
      "No improvement (2/10).\n",
      "Epoch [8/50] | train_loss 0.3395 | train_acc 0.8602 | val_loss 0.3123 | val_acc 0.8484\n",
      "No improvement (3/10).\n",
      "Epoch [9/50] | train_loss 0.3191 | train_acc 0.8582 | val_loss 0.2800 | val_acc 0.8422\n",
      "Epoch [10/50] | train_loss 0.2884 | train_acc 0.8656 | val_loss 0.2523 | val_acc 0.8734\n",
      "Epoch [11/50] | train_loss 0.2695 | train_acc 0.8758 | val_loss 0.2313 | val_acc 0.9156\n",
      "No improvement (1/10).\n",
      "Epoch [12/50] | train_loss 0.2506 | train_acc 0.8891 | val_loss 0.2395 | val_acc 0.9156\n",
      "No improvement (2/10).\n",
      "Epoch [13/50] | train_loss 0.2472 | train_acc 0.9023 | val_loss 0.2282 | val_acc 0.9109\n",
      "No improvement (3/10).\n",
      "Epoch [14/50] | train_loss 0.2383 | train_acc 0.9047 | val_loss 0.2513 | val_acc 0.9016\n",
      "No improvement (4/10).\n",
      "Epoch [15/50] | train_loss 0.2495 | train_acc 0.9043 | val_loss 0.3526 | val_acc 0.8844\n",
      "No improvement (5/10).\n",
      "Epoch [16/50] | train_loss 0.2368 | train_acc 0.9117 | val_loss 0.2205 | val_acc 0.9141\n",
      "Epoch [17/50] | train_loss 0.2270 | train_acc 0.9145 | val_loss 0.2287 | val_acc 0.9172\n",
      "No improvement (1/10).\n",
      "Epoch [18/50] | train_loss 0.2153 | train_acc 0.9254 | val_loss 0.2410 | val_acc 0.9078\n",
      "No improvement (2/10).\n",
      "Epoch [19/50] | train_loss 0.2075 | train_acc 0.9305 | val_loss 0.2072 | val_acc 0.9172\n",
      "Epoch [20/50] | train_loss 0.1905 | train_acc 0.9371 | val_loss 0.2278 | val_acc 0.9203\n",
      "Epoch [21/50] | train_loss 0.1788 | train_acc 0.9406 | val_loss 0.1918 | val_acc 0.9281\n",
      "Epoch [22/50] | train_loss 0.1548 | train_acc 0.9477 | val_loss 0.1970 | val_acc 0.9359\n",
      "Epoch [23/50] | train_loss 0.1452 | train_acc 0.9539 | val_loss 0.1489 | val_acc 0.9516\n",
      "No improvement (1/10).\n",
      "Epoch [24/50] | train_loss 0.1418 | train_acc 0.9609 | val_loss 0.1614 | val_acc 0.9453\n",
      "No improvement (2/10).\n",
      "Epoch [25/50] | train_loss 0.1219 | train_acc 0.9602 | val_loss 0.2027 | val_acc 0.9516\n",
      "Epoch [26/50] | train_loss 0.1183 | train_acc 0.9629 | val_loss 0.1251 | val_acc 0.9672\n",
      "No improvement (1/10).\n",
      "Epoch [27/50] | train_loss 0.1094 | train_acc 0.9688 | val_loss 0.1801 | val_acc 0.9625\n",
      "Epoch [28/50] | train_loss 0.1057 | train_acc 0.9695 | val_loss 0.1363 | val_acc 0.9766\n",
      "No improvement (1/10).\n",
      "Epoch [29/50] | train_loss 0.1146 | train_acc 0.9684 | val_loss 0.1388 | val_acc 0.9641\n",
      "No improvement (2/10).\n",
      "Epoch [30/50] | train_loss 0.0957 | train_acc 0.9766 | val_loss 0.1355 | val_acc 0.9672\n",
      "No improvement (3/10).\n",
      "Epoch [31/50] | train_loss 0.1158 | train_acc 0.9719 | val_loss 0.1413 | val_acc 0.9625\n",
      "No improvement (4/10).\n",
      "Epoch [32/50] | train_loss 0.0861 | train_acc 0.9781 | val_loss 0.1416 | val_acc 0.9734\n",
      "No improvement (5/10).\n",
      "Epoch [33/50] | train_loss 0.0947 | train_acc 0.9777 | val_loss 0.1618 | val_acc 0.9656\n",
      "No improvement (6/10).\n",
      "Epoch [34/50] | train_loss 0.1051 | train_acc 0.9738 | val_loss 0.1372 | val_acc 0.9719\n",
      "No improvement (7/10).\n",
      "Epoch [35/50] | train_loss 0.0884 | train_acc 0.9781 | val_loss 0.1477 | val_acc 0.9688\n",
      "No improvement (8/10).\n",
      "Epoch [36/50] | train_loss 0.0838 | train_acc 0.9816 | val_loss 0.1254 | val_acc 0.9766\n",
      "No improvement (9/10).\n",
      "Epoch [37/50] | train_loss 0.0864 | train_acc 0.9801 | val_loss 0.1313 | val_acc 0.9656\n",
      "No improvement (10/10).\n",
      "üõë Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>grad/norm</td><td>‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ</td></tr><tr><td>lr</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/acc</td><td>‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/loss</td><td>‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/acc</td><td>‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val/loss</td><td>‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>0.97656</td></tr><tr><td>epoch</td><td>37</td></tr><tr><td>grad/norm</td><td>0.0055</td></tr><tr><td>lr</td><td>0.00023</td></tr><tr><td>train/acc</td><td>0.98008</td></tr><tr><td>train/loss</td><td>0.08645</td></tr><tr><td>training_time_sec</td><td>618.73222</td></tr><tr><td>val/acc</td><td>0.96562</td></tr><tr><td>val/loss</td><td>0.13127</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">groups_8_traj_500_random_neg_split</strong> at: <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/hoo5gm9g' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning/runs/hoo5gm9g</a><br> View project at: <a href='https://wandb.ai/grignard-reagent/IY011-contrastive-learning' target=\"_blank\">https://wandb.ai/grignard-reagent/IY011-contrastive-learning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251118_162938-hoo5gm9g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=epochs,\n",
    "    patience=patience,\n",
    "    lr=lr,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    grad_clip=grad_clip,\n",
    "    save_path=save_path,\n",
    "    verbose=verbose,\n",
    "    wandb_logging=True, # this enables wandb logging within train_model\n",
    "    wandb_config=wandb_config, # pass the config dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3c06773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ‚Äî loss: 0.23 | acc: 0.95\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "test_loss, test_acc = evaluate_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4dc248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities on test set\n",
    "from training.eval import predict_proba, _compute_probabilities\n",
    "probs, targets = predict_proba(model, test_loader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9048377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 9.9945e-01, 4.2008e-08, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        3.5824e-31, 9.9995e-01, 8.6801e-01, 9.9996e-01])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_probs = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(X)                               # raw logits\n",
    "        probs = _compute_probabilities(logits, loss_fn) # (0,1)\n",
    "\n",
    "        all_probs.append(probs.cpu())\n",
    "        all_targets.append(y.cpu())\n",
    "\n",
    "all_probs = torch.cat(all_probs)\n",
    "all_targets = torch.cat(all_targets)\n",
    "\n",
    "print(all_probs[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac7fd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = all_probs.numpy()\n",
    "targets = all_targets.numpy()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(targets, probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d3751",
   "metadata": {},
   "source": [
    "## SVM Model Benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8933f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_samples shape: (4000, 1811, 1), y_samples shape: (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Stacked groups -> individual trajectory samples\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "for Xg, yg in groups:          # Xg shape (seq_len, K)\n",
    "    L, K = Xg.shape\n",
    "    for k in range(K):\n",
    "        X_samples.append(Xg[:, k:k+1])  # (seq_len, 1)\n",
    "        y_samples.append(yg)            # or some other per-trajectory label\n",
    "X_samples = np.stack(X_samples, 0)      # (N_samples, seq_len, 1)\n",
    "y_samples = np.array(y_samples)\n",
    "print(f'X_samples shape: {X_samples.shape}, y_samples shape: {y_samples.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "345e059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation:\n",
      "  Train groups: 2560, Val groups: 640, Test groups: 800\n"
     ]
    }
   ],
   "source": [
    "# # Train/val/test with stratify on group label\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_samples, y_samples, test_size=0.2, random_state=42, stratify=y_samples\n",
    ")\n",
    "X_train, X_val,  y_train, y_val  = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Data preparation:\")\n",
    "print(f\"  Train groups: {len(y_train)}, Val groups: {len(y_val)}, Test groups: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33fcab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2560, 1811, 1)\n",
      "X_val shape: (640, 1811, 1)\n",
      "X_test shape: (800, 1811, 1)\n"
     ]
    }
   ],
   "source": [
    "# === Standardise features (across time*batch, per-channel) ===\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape 3D data to 2D for scaling\n",
    "original_shape_train = X_train.shape\n",
    "original_shape_val = X_val.shape\n",
    "original_shape_test = X_test.shape\n",
    "\n",
    "# Reshape to 2D: (batch * seq_len, features)\n",
    "X_train_2d = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_val_2d = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_2d = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "# Scale the data\n",
    "X_train_2d = scaler.fit_transform(X_train_2d)\n",
    "X_val_2d = scaler.transform(X_val_2d)\n",
    "X_test_2d = scaler.transform(X_test_2d)\n",
    "\n",
    "# Reshape back to 3D\n",
    "X_train = X_train_2d.reshape(original_shape_train)\n",
    "X_val = X_val_2d.reshape(original_shape_val)\n",
    "X_test = X_test_2d.reshape(original_shape_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce7d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1811, 1]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Torch loaders\n",
    "batch_size = 64\n",
    "\n",
    "# === Convert to tensors and loaders ===\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
    "y_val_t   = torch.tensor(y_val,   dtype=torch.long)\n",
    "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_t,   y_val_t),   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_t,  y_test_t),  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# check the data loaders\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d561e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM (RBF Kernel) Classification Accuracy: 0.84 ===\n"
     ]
    }
   ],
   "source": [
    "from classifiers.svm_classifier import svm_classifier\n",
    "\n",
    "# Flatten the time series data for SVM (reshape from (n_samples, seq_len, features) to (n_samples, seq_len * features))\n",
    "X_train_svm = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_svm = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "svm_accuracy = svm_classifier(\n",
    "    X_train_svm,\n",
    "    X_test_svm,\n",
    "    y_train,\n",
    "    y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51adb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stochastic_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
