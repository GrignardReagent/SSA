{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)\n",
    "This notebook builts an MLP for classification, same way as described in [Cepeda Humerez et al. (2019)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007290)\n",
    "\n",
    "Hyperparameters to use:\n",
    "\n",
    "````python\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200] # 300 and 200 LTUs\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5 # This wasn't specified in the paper, but choose any\n",
    "learning_rate = 0.001 # Not specified in the paper\n",
    "epochs = 100 # Not specified in the paper\n",
    "batch_size = 16 # Not specified in the paper\n",
    "````\n",
    "\n",
    "The model architecture is in ``MLP.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MLP model codes from ``src``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from sympy import sqrt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Import all the functions from the 'src' directory, we import all the functions from each module so we can use them straight away\n",
    "from ssa_simulation import *\n",
    "from ssa_analysis import *\n",
    "from ssa_classification import *\n",
    "from models.MLP import MLP \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage to train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "Epoch [1/100], Loss: 120.1081, Train Acc: 0.4880\n",
      "Validation Acc: 0.4750\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.4750)\n",
      "Epoch [2/100], Loss: 91.0734, Train Acc: 0.5300\n",
      "Validation Acc: 0.4900\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.4900)\n",
      "Epoch [3/100], Loss: 70.9949, Train Acc: 0.5820\n",
      "Validation Acc: 0.4800\n",
      "Epoch [4/100], Loss: 61.3360, Train Acc: 0.6030\n",
      "Validation Acc: 0.4900\n",
      "Epoch [5/100], Loss: 55.5279, Train Acc: 0.6010\n",
      "Validation Acc: 0.4700\n",
      "Epoch [6/100], Loss: 50.5672, Train Acc: 0.6280\n",
      "Validation Acc: 0.4700\n",
      "Epoch [7/100], Loss: 43.7857, Train Acc: 0.6680\n",
      "Validation Acc: 0.4350\n",
      "Epoch [8/100], Loss: 42.5112, Train Acc: 0.6630\n",
      "Validation Acc: 0.4550\n",
      "Epoch [9/100], Loss: 41.4593, Train Acc: 0.6610\n",
      "Validation Acc: 0.4400\n",
      "Epoch [10/100], Loss: 39.5752, Train Acc: 0.6740\n",
      "Validation Acc: 0.4400\n",
      "Epoch [11/100], Loss: 39.6374, Train Acc: 0.6700\n",
      "Validation Acc: 0.4650\n",
      "Epoch [12/100], Loss: 33.6410, Train Acc: 0.7180\n",
      "Validation Acc: 0.4500\n",
      "Epoch [13/100], Loss: 33.3584, Train Acc: 0.7250\n",
      "Validation Acc: 0.4750\n",
      "Epoch [14/100], Loss: 33.4414, Train Acc: 0.7270\n",
      "Validation Acc: 0.4950\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.4950)\n",
      "Epoch [15/100], Loss: 32.2799, Train Acc: 0.7490\n",
      "Validation Acc: 0.4800\n",
      "Epoch [16/100], Loss: 31.2291, Train Acc: 0.7640\n",
      "Validation Acc: 0.4450\n",
      "Epoch [17/100], Loss: 31.4721, Train Acc: 0.7350\n",
      "Validation Acc: 0.4300\n",
      "Epoch [18/100], Loss: 29.5860, Train Acc: 0.7680\n",
      "Validation Acc: 0.4450\n",
      "Epoch [19/100], Loss: 29.1701, Train Acc: 0.7870\n",
      "Validation Acc: 0.5000\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5000)\n",
      "Epoch [20/100], Loss: 27.0313, Train Acc: 0.8000\n",
      "Validation Acc: 0.4600\n",
      "Epoch [21/100], Loss: 26.5672, Train Acc: 0.8050\n",
      "Validation Acc: 0.4750\n",
      "Epoch [22/100], Loss: 24.8654, Train Acc: 0.8260\n",
      "Validation Acc: 0.4800\n",
      "Epoch [23/100], Loss: 25.7323, Train Acc: 0.8080\n",
      "Validation Acc: 0.4900\n",
      "Epoch [24/100], Loss: 24.5302, Train Acc: 0.8300\n",
      "Validation Acc: 0.4500\n",
      "Epoch [25/100], Loss: 22.2310, Train Acc: 0.8420\n",
      "Validation Acc: 0.4800\n",
      "Epoch [26/100], Loss: 22.1294, Train Acc: 0.8520\n",
      "Validation Acc: 0.4700\n",
      "Epoch [27/100], Loss: 23.2010, Train Acc: 0.8350\n",
      "Validation Acc: 0.4900\n",
      "Epoch [28/100], Loss: 20.6906, Train Acc: 0.8540\n",
      "Validation Acc: 0.5000\n",
      "Epoch [29/100], Loss: 19.5231, Train Acc: 0.8660\n",
      "Validation Acc: 0.4850\n",
      "Epoch [30/100], Loss: 17.5723, Train Acc: 0.8800\n",
      "Validation Acc: 0.4800\n",
      "Epoch [31/100], Loss: 18.1182, Train Acc: 0.8670\n",
      "Validation Acc: 0.4850\n",
      "Epoch [32/100], Loss: 18.6468, Train Acc: 0.8700\n",
      "Validation Acc: 0.5300\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5300)\n",
      "Epoch [33/100], Loss: 16.4638, Train Acc: 0.8920\n",
      "Validation Acc: 0.4900\n",
      "Epoch [34/100], Loss: 13.8931, Train Acc: 0.9100\n",
      "Validation Acc: 0.4800\n",
      "Epoch [35/100], Loss: 14.6812, Train Acc: 0.9050\n",
      "Validation Acc: 0.4900\n",
      "Epoch [36/100], Loss: 14.0987, Train Acc: 0.9140\n",
      "Validation Acc: 0.4750\n",
      "Epoch [37/100], Loss: 14.5288, Train Acc: 0.9060\n",
      "Validation Acc: 0.4950\n",
      "Epoch [38/100], Loss: 11.0583, Train Acc: 0.9250\n",
      "Validation Acc: 0.4800\n",
      "Epoch [39/100], Loss: 12.9572, Train Acc: 0.9230\n",
      "Validation Acc: 0.4850\n",
      "Epoch [40/100], Loss: 13.5105, Train Acc: 0.9050\n",
      "Validation Acc: 0.5150\n",
      "Epoch [41/100], Loss: 10.4448, Train Acc: 0.9280\n",
      "Validation Acc: 0.4900\n",
      "Epoch [42/100], Loss: 10.3846, Train Acc: 0.9380\n",
      "Validation Acc: 0.5100\n",
      "Epoch [43/100], Loss: 8.8621, Train Acc: 0.9430\n",
      "Validation Acc: 0.4950\n",
      "Epoch [44/100], Loss: 9.3902, Train Acc: 0.9430\n",
      "Validation Acc: 0.4900\n",
      "Epoch [45/100], Loss: 8.3175, Train Acc: 0.9490\n",
      "Validation Acc: 0.5050\n",
      "Epoch [46/100], Loss: 9.5478, Train Acc: 0.9430\n",
      "Validation Acc: 0.5150\n",
      "Epoch [47/100], Loss: 8.5635, Train Acc: 0.9470\n",
      "Validation Acc: 0.4900\n",
      "Epoch [48/100], Loss: 9.2325, Train Acc: 0.9410\n",
      "Validation Acc: 0.5150\n",
      "Epoch [49/100], Loss: 10.3328, Train Acc: 0.9360\n",
      "Validation Acc: 0.4900\n",
      "Epoch [50/100], Loss: 9.2445, Train Acc: 0.9350\n",
      "Validation Acc: 0.4850\n",
      "Epoch [51/100], Loss: 7.4084, Train Acc: 0.9610\n",
      "Validation Acc: 0.5350\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5350)\n",
      "Epoch [52/100], Loss: 8.3412, Train Acc: 0.9430\n",
      "Validation Acc: 0.5200\n",
      "Epoch [53/100], Loss: 5.9329, Train Acc: 0.9610\n",
      "Validation Acc: 0.5100\n",
      "Epoch [54/100], Loss: 6.8007, Train Acc: 0.9560\n",
      "Validation Acc: 0.5300\n",
      "Epoch [55/100], Loss: 7.1709, Train Acc: 0.9550\n",
      "Validation Acc: 0.5350\n",
      "Epoch [56/100], Loss: 6.4975, Train Acc: 0.9640\n",
      "Validation Acc: 0.5550\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5550)\n",
      "Epoch [57/100], Loss: 7.6041, Train Acc: 0.9540\n",
      "Validation Acc: 0.5300\n",
      "Epoch [58/100], Loss: 5.9428, Train Acc: 0.9630\n",
      "Validation Acc: 0.5150\n",
      "Epoch [59/100], Loss: 7.1098, Train Acc: 0.9570\n",
      "Validation Acc: 0.5200\n",
      "Epoch [60/100], Loss: 5.0476, Train Acc: 0.9640\n",
      "Validation Acc: 0.5200\n",
      "Epoch [61/100], Loss: 5.8639, Train Acc: 0.9670\n",
      "Validation Acc: 0.5150\n",
      "Epoch [62/100], Loss: 5.5485, Train Acc: 0.9670\n",
      "Validation Acc: 0.5500\n",
      "Epoch [63/100], Loss: 6.2986, Train Acc: 0.9600\n",
      "Validation Acc: 0.5300\n",
      "Epoch [64/100], Loss: 5.2575, Train Acc: 0.9630\n",
      "Validation Acc: 0.5300\n",
      "Epoch [65/100], Loss: 6.8245, Train Acc: 0.9590\n",
      "Validation Acc: 0.5150\n",
      "Epoch [66/100], Loss: 4.6331, Train Acc: 0.9730\n",
      "Validation Acc: 0.4950\n",
      "Epoch [67/100], Loss: 6.1198, Train Acc: 0.9670\n",
      "Validation Acc: 0.5100\n",
      "Epoch [68/100], Loss: 4.4725, Train Acc: 0.9750\n",
      "Validation Acc: 0.5100\n",
      "Epoch [69/100], Loss: 4.5363, Train Acc: 0.9750\n",
      "Validation Acc: 0.5300\n",
      "Epoch [70/100], Loss: 3.7144, Train Acc: 0.9790\n",
      "Validation Acc: 0.5050\n",
      "Epoch [71/100], Loss: 5.6050, Train Acc: 0.9600\n",
      "Validation Acc: 0.5200\n",
      "Epoch [72/100], Loss: 4.1315, Train Acc: 0.9780\n",
      "Validation Acc: 0.5050\n",
      "Epoch [73/100], Loss: 4.2841, Train Acc: 0.9750\n",
      "Validation Acc: 0.5200\n",
      "Epoch [74/100], Loss: 4.5979, Train Acc: 0.9760\n",
      "Validation Acc: 0.5150\n",
      "Epoch [75/100], Loss: 5.2659, Train Acc: 0.9680\n",
      "Validation Acc: 0.5100\n",
      "Epoch [76/100], Loss: 5.0943, Train Acc: 0.9680\n",
      "Validation Acc: 0.5150\n",
      "Epoch [77/100], Loss: 4.6881, Train Acc: 0.9750\n",
      "Validation Acc: 0.4950\n",
      "Epoch [78/100], Loss: 2.9590, Train Acc: 0.9840\n",
      "Validation Acc: 0.5150\n",
      "Epoch [79/100], Loss: 3.5802, Train Acc: 0.9790\n",
      "Validation Acc: 0.5100\n",
      "Epoch [80/100], Loss: 4.6813, Train Acc: 0.9730\n",
      "Validation Acc: 0.4850\n",
      "Epoch [81/100], Loss: 3.5066, Train Acc: 0.9870\n",
      "Validation Acc: 0.5100\n",
      "Epoch [82/100], Loss: 3.8999, Train Acc: 0.9760\n",
      "Validation Acc: 0.5100\n",
      "Epoch [83/100], Loss: 4.2279, Train Acc: 0.9770\n",
      "Validation Acc: 0.4900\n",
      "Epoch [84/100], Loss: 3.7654, Train Acc: 0.9740\n",
      "Validation Acc: 0.5200\n",
      "Epoch [85/100], Loss: 2.3673, Train Acc: 0.9870\n",
      "Validation Acc: 0.5050\n",
      "Epoch [86/100], Loss: 1.7468, Train Acc: 0.9880\n",
      "Validation Acc: 0.5100\n",
      "Epoch [87/100], Loss: 4.6756, Train Acc: 0.9740\n",
      "Validation Acc: 0.5150\n",
      "Epoch [88/100], Loss: 2.7428, Train Acc: 0.9820\n",
      "Validation Acc: 0.5200\n",
      "Epoch [89/100], Loss: 3.0473, Train Acc: 0.9850\n",
      "Validation Acc: 0.5050\n",
      "Epoch [90/100], Loss: 2.7468, Train Acc: 0.9870\n",
      "Validation Acc: 0.5150\n",
      "Epoch [91/100], Loss: 4.3436, Train Acc: 0.9790\n",
      "Validation Acc: 0.5100\n",
      "Epoch [92/100], Loss: 3.9805, Train Acc: 0.9820\n",
      "Validation Acc: 0.5100\n",
      "Epoch [93/100], Loss: 2.8583, Train Acc: 0.9810\n",
      "Validation Acc: 0.4950\n",
      "Epoch [94/100], Loss: 3.1549, Train Acc: 0.9840\n",
      "Validation Acc: 0.4950\n",
      "Epoch [95/100], Loss: 2.0941, Train Acc: 0.9860\n",
      "Validation Acc: 0.5050\n",
      "Epoch [96/100], Loss: 2.6860, Train Acc: 0.9900\n",
      "Validation Acc: 0.5150\n",
      "Epoch [97/100], Loss: 2.9158, Train Acc: 0.9840\n",
      "Validation Acc: 0.5100\n",
      "Epoch [98/100], Loss: 2.0181, Train Acc: 0.9870\n",
      "Validation Acc: 0.4900\n",
      "Epoch [99/100], Loss: 3.0089, Train Acc: 0.9880\n",
      "Validation Acc: 0.5150\n",
      "Epoch [100/100], Loss: 2.6891, Train Acc: 0.9850\n",
      "Validation Acc: 0.5050\n",
      "Training complete!\n",
      "ðŸ”„ Model loaded from mlp_model.pth\n",
      "Final Test Accuracy: 0.5550\n",
      "Predicted classes: tensor([1, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200]\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Generate synthetic data\n",
    "X_train = torch.randn(1000, input_size)\n",
    "y_train = torch.randint(0, output_size, (1000,))\n",
    "X_val = torch.randn(200, input_size)\n",
    "y_val = torch.randint(0, output_size, (200,))\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize and train model\n",
    "file_path = \"mlp_model.pth\"\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, val_loader, epochs, save_path=file_path)\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_model(file_path)\n",
    "test_acc = model.evaluate(val_loader)\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "X_test = torch.randn(5, input_size)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predicted classes:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the MLP using SSA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "Epoch [1/100], Loss: 6.7796, Train Acc: 0.6719\n",
      "Epoch [2/100], Loss: 5.7806, Train Acc: 0.7156\n",
      "Epoch [3/100], Loss: 5.6211, Train Acc: 0.7312\n",
      "Epoch [4/100], Loss: 5.0766, Train Acc: 0.7594\n",
      "Epoch [5/100], Loss: 4.8404, Train Acc: 0.7656\n",
      "Epoch [6/100], Loss: 4.8021, Train Acc: 0.7625\n",
      "Epoch [7/100], Loss: 4.6222, Train Acc: 0.7875\n",
      "Epoch [8/100], Loss: 4.7001, Train Acc: 0.7812\n",
      "Epoch [9/100], Loss: 4.7044, Train Acc: 0.7750\n",
      "Epoch [10/100], Loss: 4.4635, Train Acc: 0.8000\n",
      "Epoch [11/100], Loss: 4.4858, Train Acc: 0.7812\n",
      "Epoch [12/100], Loss: 4.2082, Train Acc: 0.8063\n",
      "Epoch [13/100], Loss: 4.3141, Train Acc: 0.8031\n",
      "Epoch [14/100], Loss: 4.2332, Train Acc: 0.7906\n",
      "Epoch [15/100], Loss: 4.3645, Train Acc: 0.7906\n",
      "Epoch [16/100], Loss: 4.1452, Train Acc: 0.8000\n",
      "Epoch [17/100], Loss: 4.2009, Train Acc: 0.8000\n",
      "Epoch [18/100], Loss: 4.2486, Train Acc: 0.7969\n",
      "Epoch [19/100], Loss: 4.1704, Train Acc: 0.7969\n",
      "Epoch [20/100], Loss: 4.3815, Train Acc: 0.7969\n",
      "Epoch [21/100], Loss: 4.1203, Train Acc: 0.8094\n",
      "Epoch [22/100], Loss: 4.3088, Train Acc: 0.7906\n",
      "Epoch [23/100], Loss: 4.1367, Train Acc: 0.8063\n",
      "Epoch [24/100], Loss: 4.0372, Train Acc: 0.8156\n",
      "Epoch [25/100], Loss: 4.0666, Train Acc: 0.7937\n",
      "Epoch [26/100], Loss: 4.1098, Train Acc: 0.8031\n",
      "Epoch [27/100], Loss: 3.8992, Train Acc: 0.8187\n",
      "Epoch [28/100], Loss: 4.1851, Train Acc: 0.8000\n",
      "Epoch [29/100], Loss: 4.0906, Train Acc: 0.8094\n",
      "Epoch [30/100], Loss: 3.9598, Train Acc: 0.8187\n",
      "Epoch [31/100], Loss: 4.1004, Train Acc: 0.8094\n",
      "Epoch [32/100], Loss: 4.0979, Train Acc: 0.8094\n",
      "Epoch [33/100], Loss: 4.1940, Train Acc: 0.8000\n",
      "Epoch [34/100], Loss: 4.0841, Train Acc: 0.8031\n",
      "Epoch [35/100], Loss: 4.1010, Train Acc: 0.8031\n",
      "Epoch [36/100], Loss: 3.9808, Train Acc: 0.8125\n",
      "Epoch [37/100], Loss: 4.1512, Train Acc: 0.8031\n",
      "Epoch [38/100], Loss: 3.9769, Train Acc: 0.8094\n",
      "Epoch [39/100], Loss: 4.2082, Train Acc: 0.7969\n",
      "Epoch [40/100], Loss: 4.1747, Train Acc: 0.8063\n",
      "Epoch [41/100], Loss: 4.0826, Train Acc: 0.8094\n",
      "Epoch [42/100], Loss: 4.0322, Train Acc: 0.8125\n",
      "Epoch [43/100], Loss: 3.7787, Train Acc: 0.8219\n",
      "Epoch [44/100], Loss: 4.2014, Train Acc: 0.7937\n",
      "Epoch [45/100], Loss: 3.9185, Train Acc: 0.8063\n",
      "Epoch [46/100], Loss: 4.0885, Train Acc: 0.8094\n",
      "Epoch [47/100], Loss: 4.0306, Train Acc: 0.8094\n",
      "Epoch [48/100], Loss: 3.9094, Train Acc: 0.8125\n",
      "Epoch [49/100], Loss: 3.9566, Train Acc: 0.8187\n",
      "Epoch [50/100], Loss: 4.0106, Train Acc: 0.7969\n",
      "Epoch [51/100], Loss: 3.9692, Train Acc: 0.8031\n",
      "Epoch [52/100], Loss: 3.7663, Train Acc: 0.8281\n",
      "Epoch [53/100], Loss: 3.8702, Train Acc: 0.8094\n",
      "Epoch [54/100], Loss: 3.9323, Train Acc: 0.8063\n",
      "Epoch [55/100], Loss: 3.8621, Train Acc: 0.8031\n",
      "Epoch [56/100], Loss: 3.8675, Train Acc: 0.8250\n",
      "Epoch [57/100], Loss: 3.9458, Train Acc: 0.8063\n",
      "Epoch [58/100], Loss: 3.8459, Train Acc: 0.8156\n",
      "Epoch [59/100], Loss: 4.0519, Train Acc: 0.7906\n",
      "Epoch [60/100], Loss: 3.9039, Train Acc: 0.8125\n",
      "Epoch [61/100], Loss: 3.8470, Train Acc: 0.8094\n",
      "Epoch [62/100], Loss: 4.1229, Train Acc: 0.8031\n",
      "Epoch [63/100], Loss: 3.8250, Train Acc: 0.8219\n",
      "Epoch [64/100], Loss: 3.8147, Train Acc: 0.8156\n",
      "Epoch [65/100], Loss: 3.8491, Train Acc: 0.8094\n",
      "Epoch [66/100], Loss: 3.9190, Train Acc: 0.8125\n",
      "Epoch [67/100], Loss: 3.8759, Train Acc: 0.8250\n",
      "Epoch [68/100], Loss: 4.0752, Train Acc: 0.7937\n",
      "Epoch [69/100], Loss: 3.8295, Train Acc: 0.8187\n",
      "Epoch [70/100], Loss: 3.8245, Train Acc: 0.8156\n",
      "Epoch [71/100], Loss: 3.9924, Train Acc: 0.8063\n",
      "Epoch [72/100], Loss: 4.0500, Train Acc: 0.8094\n",
      "Epoch [73/100], Loss: 4.0061, Train Acc: 0.8031\n",
      "Epoch [74/100], Loss: 3.9888, Train Acc: 0.8094\n",
      "Epoch [75/100], Loss: 4.0504, Train Acc: 0.8000\n",
      "Epoch [76/100], Loss: 4.0103, Train Acc: 0.8063\n",
      "Epoch [77/100], Loss: 3.8072, Train Acc: 0.8187\n",
      "Epoch [78/100], Loss: 4.0806, Train Acc: 0.8094\n",
      "Epoch [79/100], Loss: 3.8047, Train Acc: 0.8281\n",
      "Epoch [80/100], Loss: 3.7716, Train Acc: 0.8125\n",
      "Epoch [81/100], Loss: 3.8377, Train Acc: 0.8156\n",
      "Epoch [82/100], Loss: 3.9094, Train Acc: 0.8094\n",
      "Epoch [83/100], Loss: 3.9634, Train Acc: 0.8000\n",
      "Epoch [84/100], Loss: 3.7621, Train Acc: 0.8187\n",
      "Epoch [85/100], Loss: 4.0269, Train Acc: 0.8000\n",
      "Epoch [86/100], Loss: 3.8708, Train Acc: 0.8063\n",
      "Epoch [87/100], Loss: 3.8128, Train Acc: 0.8219\n",
      "Epoch [88/100], Loss: 4.0976, Train Acc: 0.7969\n",
      "Epoch [89/100], Loss: 3.7273, Train Acc: 0.8187\n",
      "Epoch [90/100], Loss: 3.9195, Train Acc: 0.8000\n",
      "Epoch [91/100], Loss: 3.9103, Train Acc: 0.8063\n",
      "Epoch [92/100], Loss: 3.7930, Train Acc: 0.8187\n",
      "Epoch [93/100], Loss: 3.9793, Train Acc: 0.8031\n",
      "Epoch [94/100], Loss: 3.8639, Train Acc: 0.8094\n",
      "Epoch [95/100], Loss: 3.8934, Train Acc: 0.8094\n",
      "Epoch [96/100], Loss: 3.7350, Train Acc: 0.8281\n",
      "Epoch [97/100], Loss: 3.8143, Train Acc: 0.8281\n",
      "Epoch [98/100], Loss: 3.8749, Train Acc: 0.8094\n",
      "Epoch [99/100], Loss: 3.8634, Train Acc: 0.8031\n",
      "Epoch [100/100], Loss: 3.8557, Train Acc: 0.8031\n",
      "Training complete!\n",
      "MLP Test Accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "\n",
    "# Define model parameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(set(y_train))  # Number of classes\n",
    "hidden_size = [300, 200]\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, epochs=epochs)\n",
    "\n",
    "# Evaluate MLP model\n",
    "mlp_accuracy = model.evaluate(test_loader)\n",
    "print(f\"MLP Test Accuracy: {mlp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above, but in a one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "Epoch [1/100], Loss: 6.8887, Train Acc: 0.6188\n",
      "Epoch [2/100], Loss: 5.5465, Train Acc: 0.7406\n",
      "Epoch [3/100], Loss: 5.0381, Train Acc: 0.7656\n",
      "Epoch [4/100], Loss: 4.8078, Train Acc: 0.7812\n",
      "Epoch [5/100], Loss: 4.6351, Train Acc: 0.7719\n",
      "Epoch [6/100], Loss: 4.5014, Train Acc: 0.8031\n",
      "Epoch [7/100], Loss: 4.3527, Train Acc: 0.8031\n",
      "Epoch [8/100], Loss: 4.2208, Train Acc: 0.8031\n",
      "Epoch [9/100], Loss: 4.1826, Train Acc: 0.8094\n",
      "Epoch [10/100], Loss: 4.2329, Train Acc: 0.8031\n",
      "Epoch [11/100], Loss: 4.1091, Train Acc: 0.8031\n",
      "Epoch [12/100], Loss: 4.1589, Train Acc: 0.7906\n",
      "Epoch [13/100], Loss: 3.9525, Train Acc: 0.8094\n",
      "Epoch [14/100], Loss: 4.0407, Train Acc: 0.8031\n",
      "Epoch [15/100], Loss: 4.0987, Train Acc: 0.8063\n",
      "Epoch [16/100], Loss: 3.9645, Train Acc: 0.8031\n",
      "Epoch [17/100], Loss: 3.9095, Train Acc: 0.8094\n",
      "Epoch [18/100], Loss: 3.9992, Train Acc: 0.7969\n",
      "Epoch [19/100], Loss: 3.8833, Train Acc: 0.8281\n",
      "Epoch [20/100], Loss: 4.0402, Train Acc: 0.7969\n",
      "Epoch [21/100], Loss: 3.8722, Train Acc: 0.8250\n",
      "Epoch [22/100], Loss: 3.9095, Train Acc: 0.8187\n",
      "Epoch [23/100], Loss: 3.9102, Train Acc: 0.8125\n",
      "Epoch [24/100], Loss: 3.8470, Train Acc: 0.8156\n",
      "Epoch [25/100], Loss: 4.0524, Train Acc: 0.8000\n",
      "Epoch [26/100], Loss: 3.8964, Train Acc: 0.8125\n",
      "Epoch [27/100], Loss: 3.9414, Train Acc: 0.8094\n",
      "Epoch [28/100], Loss: 3.7583, Train Acc: 0.8031\n",
      "Epoch [29/100], Loss: 3.8081, Train Acc: 0.8219\n",
      "Epoch [30/100], Loss: 3.8441, Train Acc: 0.8156\n",
      "Epoch [31/100], Loss: 3.8511, Train Acc: 0.8094\n",
      "Epoch [32/100], Loss: 3.9546, Train Acc: 0.8125\n",
      "Epoch [33/100], Loss: 3.9796, Train Acc: 0.7969\n",
      "Epoch [34/100], Loss: 3.8122, Train Acc: 0.8156\n",
      "Epoch [35/100], Loss: 3.8641, Train Acc: 0.8000\n",
      "Epoch [36/100], Loss: 3.8722, Train Acc: 0.8156\n",
      "Epoch [37/100], Loss: 3.8544, Train Acc: 0.8156\n",
      "Epoch [38/100], Loss: 3.9685, Train Acc: 0.8125\n",
      "Epoch [39/100], Loss: 3.9302, Train Acc: 0.8063\n",
      "Epoch [40/100], Loss: 3.9367, Train Acc: 0.8125\n",
      "Epoch [41/100], Loss: 3.8105, Train Acc: 0.8187\n",
      "Epoch [42/100], Loss: 3.9205, Train Acc: 0.8187\n",
      "Epoch [43/100], Loss: 3.8424, Train Acc: 0.8156\n",
      "Epoch [44/100], Loss: 3.8815, Train Acc: 0.8031\n",
      "Epoch [45/100], Loss: 3.8304, Train Acc: 0.8125\n",
      "Epoch [46/100], Loss: 3.8544, Train Acc: 0.8031\n",
      "Epoch [47/100], Loss: 3.7783, Train Acc: 0.8250\n",
      "Epoch [48/100], Loss: 3.7261, Train Acc: 0.8250\n",
      "Epoch [49/100], Loss: 3.9553, Train Acc: 0.8125\n",
      "Epoch [50/100], Loss: 3.9389, Train Acc: 0.8125\n",
      "Epoch [51/100], Loss: 3.9667, Train Acc: 0.8063\n",
      "Epoch [52/100], Loss: 3.8667, Train Acc: 0.8125\n",
      "Epoch [53/100], Loss: 3.7925, Train Acc: 0.8156\n",
      "Epoch [54/100], Loss: 3.8190, Train Acc: 0.8125\n",
      "Epoch [55/100], Loss: 3.7729, Train Acc: 0.8125\n",
      "Epoch [56/100], Loss: 3.8004, Train Acc: 0.8187\n",
      "Epoch [57/100], Loss: 3.8555, Train Acc: 0.8156\n",
      "Epoch [58/100], Loss: 3.8036, Train Acc: 0.8156\n",
      "Epoch [59/100], Loss: 3.9361, Train Acc: 0.7969\n",
      "Epoch [60/100], Loss: 3.7685, Train Acc: 0.8187\n",
      "Epoch [61/100], Loss: 3.7829, Train Acc: 0.8125\n",
      "Epoch [62/100], Loss: 3.6678, Train Acc: 0.8219\n",
      "Epoch [63/100], Loss: 3.7689, Train Acc: 0.8031\n",
      "Epoch [64/100], Loss: 3.8740, Train Acc: 0.8031\n",
      "Epoch [65/100], Loss: 3.9608, Train Acc: 0.8094\n",
      "Epoch [66/100], Loss: 3.8014, Train Acc: 0.8094\n",
      "Epoch [67/100], Loss: 3.7911, Train Acc: 0.8187\n",
      "Epoch [68/100], Loss: 3.8575, Train Acc: 0.8313\n",
      "Epoch [69/100], Loss: 3.7427, Train Acc: 0.8187\n",
      "Epoch [70/100], Loss: 3.8557, Train Acc: 0.8063\n",
      "Epoch [71/100], Loss: 3.7201, Train Acc: 0.8250\n",
      "Epoch [72/100], Loss: 3.9148, Train Acc: 0.8063\n",
      "Epoch [73/100], Loss: 3.7897, Train Acc: 0.8125\n",
      "Epoch [74/100], Loss: 3.7839, Train Acc: 0.8094\n",
      "Epoch [75/100], Loss: 3.6267, Train Acc: 0.8187\n",
      "Epoch [76/100], Loss: 3.6349, Train Acc: 0.8344\n",
      "Epoch [77/100], Loss: 3.7126, Train Acc: 0.8187\n",
      "Epoch [78/100], Loss: 3.7870, Train Acc: 0.8063\n",
      "Epoch [79/100], Loss: 3.7209, Train Acc: 0.8187\n",
      "Epoch [80/100], Loss: 3.8836, Train Acc: 0.8219\n",
      "Epoch [81/100], Loss: 3.7677, Train Acc: 0.8156\n",
      "Epoch [82/100], Loss: 3.8207, Train Acc: 0.8219\n",
      "Epoch [83/100], Loss: 3.8557, Train Acc: 0.8094\n",
      "Epoch [84/100], Loss: 3.7750, Train Acc: 0.8063\n",
      "Epoch [85/100], Loss: 3.8297, Train Acc: 0.7937\n",
      "Epoch [86/100], Loss: 3.7059, Train Acc: 0.8187\n",
      "Epoch [87/100], Loss: 3.8290, Train Acc: 0.8156\n",
      "Epoch [88/100], Loss: 3.8084, Train Acc: 0.8156\n",
      "Epoch [89/100], Loss: 3.7918, Train Acc: 0.8156\n",
      "Epoch [90/100], Loss: 3.7249, Train Acc: 0.8250\n",
      "Epoch [91/100], Loss: 3.8741, Train Acc: 0.8156\n",
      "Epoch [92/100], Loss: 3.6994, Train Acc: 0.8313\n",
      "Epoch [93/100], Loss: 3.8146, Train Acc: 0.8094\n",
      "Epoch [94/100], Loss: 3.7669, Train Acc: 0.8250\n",
      "Epoch [95/100], Loss: 3.8197, Train Acc: 0.8000\n",
      "Epoch [96/100], Loss: 3.6090, Train Acc: 0.8344\n",
      "Epoch [97/100], Loss: 3.6127, Train Acc: 0.8250\n",
      "Epoch [98/100], Loss: 3.6752, Train Acc: 0.8063\n",
      "Epoch [99/100], Loss: 3.7758, Train Acc: 0.8156\n",
      "Epoch [100/100], Loss: 3.8772, Train Acc: 0.8000\n",
      "Training complete!\n",
      "=== Multilayer Perceptron (MLP) Accuracy: 0.75 ===\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "mlp_accuracy = mlp_classifier(X_train, X_test, y_train, y_test, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
