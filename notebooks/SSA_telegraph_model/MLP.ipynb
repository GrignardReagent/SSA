{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)\n",
    "This notebook builts an MLP for classification, same way as described in [Cepeda Humerez et al. (2019)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007290)\n",
    "\n",
    "Hyperparameters to use:\n",
    "\n",
    "````python\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200] # 300 and 200 LTUs\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5 # This wasn't specified in the paper, but choose any\n",
    "learning_rate = 0.001 # Not specified in the paper\n",
    "epochs = 100 # Not specified in the paper\n",
    "batch_size = 16 # Not specified in the paper\n",
    "````\n",
    "\n",
    "The model architecture is in ``MLP.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MLP model codes from ``src``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from sympy import sqrt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import all the functions from the 'src' directory, we import all the functions from each module so we can use them straight away\n",
    "from ssa_simulation import *\n",
    "from ssa_analysis import *\n",
    "from ssa_classification import *\n",
    "from models.MLP import MLP \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage to train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 119.2893, Train Acc: 0.5050\n",
      "Validation Acc: 0.5150\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5150)\n",
      "Epoch [2/100], Loss: 86.0712, Train Acc: 0.5620\n",
      "Validation Acc: 0.4700\n",
      "Epoch [3/100], Loss: 69.8308, Train Acc: 0.5800\n",
      "Validation Acc: 0.4700\n",
      "Epoch [4/100], Loss: 56.4978, Train Acc: 0.6110\n",
      "Validation Acc: 0.5000\n",
      "Epoch [5/100], Loss: 55.4314, Train Acc: 0.6290\n",
      "Validation Acc: 0.5100\n",
      "Epoch [6/100], Loss: 49.2156, Train Acc: 0.6370\n",
      "Validation Acc: 0.4700\n",
      "Epoch [7/100], Loss: 45.8456, Train Acc: 0.6470\n",
      "Validation Acc: 0.4600\n",
      "Epoch [8/100], Loss: 38.8641, Train Acc: 0.6860\n",
      "Validation Acc: 0.4600\n",
      "Epoch [9/100], Loss: 37.8630, Train Acc: 0.6940\n",
      "Validation Acc: 0.4900\n",
      "Epoch [10/100], Loss: 37.2601, Train Acc: 0.6940\n",
      "Validation Acc: 0.5150\n",
      "Epoch [11/100], Loss: 37.2800, Train Acc: 0.6990\n",
      "Validation Acc: 0.4850\n",
      "Epoch [12/100], Loss: 32.3891, Train Acc: 0.7630\n",
      "Validation Acc: 0.5100\n",
      "Epoch [13/100], Loss: 32.6891, Train Acc: 0.7420\n",
      "Validation Acc: 0.4750\n",
      "Epoch [14/100], Loss: 32.0056, Train Acc: 0.7680\n",
      "Validation Acc: 0.4650\n",
      "Epoch [15/100], Loss: 29.8902, Train Acc: 0.7550\n",
      "Validation Acc: 0.4900\n",
      "Epoch [16/100], Loss: 30.3194, Train Acc: 0.7770\n",
      "Validation Acc: 0.5000\n",
      "Epoch [17/100], Loss: 29.7214, Train Acc: 0.7720\n",
      "Validation Acc: 0.5050\n",
      "Epoch [18/100], Loss: 26.6489, Train Acc: 0.8060\n",
      "Validation Acc: 0.4850\n",
      "Epoch [19/100], Loss: 26.7869, Train Acc: 0.8050\n",
      "Validation Acc: 0.5000\n",
      "Epoch [20/100], Loss: 25.4955, Train Acc: 0.8140\n",
      "Validation Acc: 0.4950\n",
      "Epoch [21/100], Loss: 25.7390, Train Acc: 0.8110\n",
      "Validation Acc: 0.4800\n",
      "Epoch [22/100], Loss: 24.3014, Train Acc: 0.8290\n",
      "Validation Acc: 0.4900\n",
      "Epoch [23/100], Loss: 22.3426, Train Acc: 0.8480\n",
      "Validation Acc: 0.5000\n",
      "Epoch [24/100], Loss: 20.3678, Train Acc: 0.8640\n",
      "Validation Acc: 0.5150\n",
      "Epoch [25/100], Loss: 21.3031, Train Acc: 0.8550\n",
      "Validation Acc: 0.5300\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5300)\n",
      "Epoch [26/100], Loss: 19.8022, Train Acc: 0.8670\n",
      "Validation Acc: 0.4950\n",
      "Epoch [27/100], Loss: 19.9133, Train Acc: 0.8600\n",
      "Validation Acc: 0.4800\n",
      "Epoch [28/100], Loss: 17.3295, Train Acc: 0.8920\n",
      "Validation Acc: 0.5050\n",
      "Epoch [29/100], Loss: 16.9926, Train Acc: 0.8830\n",
      "Validation Acc: 0.4800\n",
      "Epoch [30/100], Loss: 16.9012, Train Acc: 0.8900\n",
      "Validation Acc: 0.4600\n",
      "Epoch [31/100], Loss: 17.5180, Train Acc: 0.8760\n",
      "Validation Acc: 0.4650\n",
      "Epoch [32/100], Loss: 14.2916, Train Acc: 0.9080\n",
      "Validation Acc: 0.4900\n",
      "Epoch [33/100], Loss: 13.0812, Train Acc: 0.9270\n",
      "Validation Acc: 0.4550\n",
      "Epoch [34/100], Loss: 15.1514, Train Acc: 0.8890\n",
      "Validation Acc: 0.4850\n",
      "Epoch [35/100], Loss: 14.0795, Train Acc: 0.8970\n",
      "Validation Acc: 0.4550\n",
      "Epoch [36/100], Loss: 12.8107, Train Acc: 0.9170\n",
      "Validation Acc: 0.4650\n",
      "Epoch [37/100], Loss: 12.8110, Train Acc: 0.9100\n",
      "Validation Acc: 0.4650\n",
      "Epoch [38/100], Loss: 10.9551, Train Acc: 0.9340\n",
      "Validation Acc: 0.4850\n",
      "Epoch [39/100], Loss: 12.8731, Train Acc: 0.9160\n",
      "Validation Acc: 0.4900\n",
      "Epoch [40/100], Loss: 9.3841, Train Acc: 0.9490\n",
      "Validation Acc: 0.5000\n",
      "Epoch [41/100], Loss: 9.1771, Train Acc: 0.9420\n",
      "Validation Acc: 0.4950\n",
      "Epoch [42/100], Loss: 10.3393, Train Acc: 0.9330\n",
      "Validation Acc: 0.5050\n",
      "Epoch [43/100], Loss: 9.0921, Train Acc: 0.9480\n",
      "Validation Acc: 0.5250\n",
      "Epoch [44/100], Loss: 8.9673, Train Acc: 0.9380\n",
      "Validation Acc: 0.5100\n",
      "Epoch [45/100], Loss: 6.7905, Train Acc: 0.9560\n",
      "Validation Acc: 0.5000\n",
      "Epoch [46/100], Loss: 6.6476, Train Acc: 0.9560\n",
      "Validation Acc: 0.4800\n",
      "Epoch [47/100], Loss: 7.4612, Train Acc: 0.9450\n",
      "Validation Acc: 0.4700\n",
      "Epoch [48/100], Loss: 7.1623, Train Acc: 0.9590\n",
      "Validation Acc: 0.4900\n",
      "Epoch [49/100], Loss: 4.8718, Train Acc: 0.9660\n",
      "Validation Acc: 0.4800\n",
      "Epoch [50/100], Loss: 7.5356, Train Acc: 0.9570\n",
      "Validation Acc: 0.4950\n",
      "Epoch [51/100], Loss: 7.0664, Train Acc: 0.9610\n",
      "Validation Acc: 0.4950\n",
      "Epoch [52/100], Loss: 7.4667, Train Acc: 0.9550\n",
      "Validation Acc: 0.5050\n",
      "Epoch [53/100], Loss: 5.9245, Train Acc: 0.9610\n",
      "Validation Acc: 0.4850\n",
      "Epoch [54/100], Loss: 5.8436, Train Acc: 0.9640\n",
      "Validation Acc: 0.5200\n",
      "Epoch [55/100], Loss: 4.9864, Train Acc: 0.9730\n",
      "Validation Acc: 0.5050\n",
      "Epoch [56/100], Loss: 5.1287, Train Acc: 0.9700\n",
      "Validation Acc: 0.4950\n",
      "Epoch [57/100], Loss: 5.7468, Train Acc: 0.9650\n",
      "Validation Acc: 0.4900\n",
      "Epoch [58/100], Loss: 5.4751, Train Acc: 0.9640\n",
      "Validation Acc: 0.5000\n",
      "Epoch [59/100], Loss: 4.9766, Train Acc: 0.9720\n",
      "Validation Acc: 0.5000\n",
      "Epoch [60/100], Loss: 5.2310, Train Acc: 0.9640\n",
      "Validation Acc: 0.4900\n",
      "Epoch [61/100], Loss: 4.1580, Train Acc: 0.9770\n",
      "Validation Acc: 0.4750\n",
      "Epoch [62/100], Loss: 4.7844, Train Acc: 0.9700\n",
      "Validation Acc: 0.5100\n",
      "Epoch [63/100], Loss: 5.1623, Train Acc: 0.9690\n",
      "Validation Acc: 0.5000\n",
      "Epoch [64/100], Loss: 4.7335, Train Acc: 0.9750\n",
      "Validation Acc: 0.4900\n",
      "Epoch [65/100], Loss: 3.6493, Train Acc: 0.9790\n",
      "Validation Acc: 0.4750\n",
      "Epoch [66/100], Loss: 4.1174, Train Acc: 0.9700\n",
      "Validation Acc: 0.4550\n",
      "Epoch [67/100], Loss: 4.7804, Train Acc: 0.9800\n",
      "Validation Acc: 0.4550\n",
      "Epoch [68/100], Loss: 4.5393, Train Acc: 0.9730\n",
      "Validation Acc: 0.4450\n",
      "Epoch [69/100], Loss: 3.5367, Train Acc: 0.9790\n",
      "Validation Acc: 0.4700\n",
      "Epoch [70/100], Loss: 3.6314, Train Acc: 0.9800\n",
      "Validation Acc: 0.5050\n",
      "Epoch [71/100], Loss: 3.3003, Train Acc: 0.9770\n",
      "Validation Acc: 0.4850\n",
      "Epoch [72/100], Loss: 3.7764, Train Acc: 0.9760\n",
      "Validation Acc: 0.4550\n",
      "Epoch [73/100], Loss: 3.2474, Train Acc: 0.9780\n",
      "Validation Acc: 0.5000\n",
      "Epoch [74/100], Loss: 2.8187, Train Acc: 0.9870\n",
      "Validation Acc: 0.4850\n",
      "Epoch [75/100], Loss: 2.7881, Train Acc: 0.9850\n",
      "Validation Acc: 0.4700\n",
      "Epoch [76/100], Loss: 3.9279, Train Acc: 0.9780\n",
      "Validation Acc: 0.4950\n",
      "Epoch [77/100], Loss: 3.9921, Train Acc: 0.9820\n",
      "Validation Acc: 0.4900\n",
      "Epoch [78/100], Loss: 2.1926, Train Acc: 0.9840\n",
      "Validation Acc: 0.4650\n",
      "Epoch [79/100], Loss: 2.6732, Train Acc: 0.9890\n",
      "Validation Acc: 0.4650\n",
      "Epoch [80/100], Loss: 3.7202, Train Acc: 0.9790\n",
      "Validation Acc: 0.4850\n",
      "Epoch [81/100], Loss: 3.0214, Train Acc: 0.9830\n",
      "Validation Acc: 0.4750\n",
      "Epoch [82/100], Loss: 2.8593, Train Acc: 0.9800\n",
      "Validation Acc: 0.4800\n",
      "Epoch [83/100], Loss: 3.2649, Train Acc: 0.9760\n",
      "Validation Acc: 0.4900\n",
      "Epoch [84/100], Loss: 2.9260, Train Acc: 0.9870\n",
      "Validation Acc: 0.4950\n",
      "Epoch [85/100], Loss: 4.3210, Train Acc: 0.9780\n",
      "Validation Acc: 0.4550\n",
      "Epoch [86/100], Loss: 2.7686, Train Acc: 0.9840\n",
      "Validation Acc: 0.4550\n",
      "Epoch [87/100], Loss: 3.4776, Train Acc: 0.9800\n",
      "Validation Acc: 0.4700\n",
      "Epoch [88/100], Loss: 2.4161, Train Acc: 0.9860\n",
      "Validation Acc: 0.4700\n",
      "Epoch [89/100], Loss: 2.7786, Train Acc: 0.9870\n",
      "Validation Acc: 0.4700\n",
      "Epoch [90/100], Loss: 2.9627, Train Acc: 0.9800\n",
      "Validation Acc: 0.4550\n",
      "Epoch [91/100], Loss: 1.4757, Train Acc: 0.9910\n",
      "Validation Acc: 0.4700\n",
      "Epoch [92/100], Loss: 5.2326, Train Acc: 0.9770\n",
      "Validation Acc: 0.4550\n",
      "Epoch [93/100], Loss: 3.0328, Train Acc: 0.9800\n",
      "Validation Acc: 0.4600\n",
      "Epoch [94/100], Loss: 3.6466, Train Acc: 0.9840\n",
      "Validation Acc: 0.4800\n",
      "Epoch [95/100], Loss: 3.1275, Train Acc: 0.9810\n",
      "Validation Acc: 0.4700\n",
      "Epoch [96/100], Loss: 2.6121, Train Acc: 0.9860\n",
      "Validation Acc: 0.4350\n",
      "Epoch [97/100], Loss: 3.8707, Train Acc: 0.9830\n",
      "Validation Acc: 0.4250\n",
      "Epoch [98/100], Loss: 2.4240, Train Acc: 0.9860\n",
      "Validation Acc: 0.4300\n",
      "Epoch [99/100], Loss: 1.4515, Train Acc: 0.9900\n",
      "Validation Acc: 0.4800\n",
      "Epoch [100/100], Loss: 3.1431, Train Acc: 0.9830\n",
      "Validation Acc: 0.4900\n",
      "Training complete!\n",
      "ðŸ”„ Model loaded from mlp_model.pth\n",
      "Final Test Accuracy: 0.5300\n",
      "Predicted classes: tensor([1, 0, 1, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200]\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Generate synthetic data\n",
    "X_train = torch.randn(1000, input_size)\n",
    "y_train = torch.randint(0, output_size, (1000,))\n",
    "X_val = torch.randn(200, input_size)\n",
    "y_val = torch.randint(0, output_size, (200,))\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize and train model\n",
    "file_path = \"mlp_model.pth\"\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, val_loader, epochs, save_path=file_path)\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_model(file_path)\n",
    "test_acc = model.evaluate(val_loader)\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "X_test = torch.randn(5, input_size)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predicted classes:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the MLP using SSA data, we need to first standardise the data. If we don't, the loss will be showing as nan, which is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " ...\n",
      " [ 0.          1.00514142 -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.          2.44105774 -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data \n",
    "# If your input features are too large (e.g., >1000) or too small (<0.0001), it can cause unstable training, so it's better to standardize the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 11.6425, Train Acc: 0.6469\n",
      "Epoch [2/100], Loss: 7.2031, Train Acc: 0.7094\n",
      "Epoch [3/100], Loss: 7.4694, Train Acc: 0.7063\n",
      "Epoch [4/100], Loss: 7.5236, Train Acc: 0.7531\n",
      "Epoch [5/100], Loss: 5.8111, Train Acc: 0.7750\n",
      "Epoch [6/100], Loss: 5.4871, Train Acc: 0.7844\n",
      "Epoch [7/100], Loss: 5.2564, Train Acc: 0.7969\n",
      "Epoch [8/100], Loss: 5.1997, Train Acc: 0.7781\n",
      "Epoch [9/100], Loss: 5.7426, Train Acc: 0.7719\n",
      "Epoch [10/100], Loss: 5.1096, Train Acc: 0.7531\n",
      "Epoch [11/100], Loss: 4.6505, Train Acc: 0.7969\n",
      "Epoch [12/100], Loss: 4.7923, Train Acc: 0.7906\n",
      "Epoch [13/100], Loss: 5.5862, Train Acc: 0.7812\n",
      "Epoch [14/100], Loss: 5.3528, Train Acc: 0.7656\n",
      "Epoch [15/100], Loss: 5.0964, Train Acc: 0.7625\n",
      "Epoch [16/100], Loss: 5.2844, Train Acc: 0.7906\n",
      "Epoch [17/100], Loss: 4.4309, Train Acc: 0.8031\n",
      "Epoch [18/100], Loss: 4.9868, Train Acc: 0.7937\n",
      "Epoch [19/100], Loss: 4.7583, Train Acc: 0.7875\n",
      "Epoch [20/100], Loss: 4.4636, Train Acc: 0.7969\n",
      "Epoch [21/100], Loss: 4.7790, Train Acc: 0.7937\n",
      "Epoch [22/100], Loss: 5.0482, Train Acc: 0.7812\n",
      "Epoch [23/100], Loss: 4.3898, Train Acc: 0.7937\n",
      "Epoch [24/100], Loss: 4.8631, Train Acc: 0.7875\n",
      "Epoch [25/100], Loss: 5.1110, Train Acc: 0.7844\n",
      "Epoch [26/100], Loss: 4.4892, Train Acc: 0.7906\n",
      "Epoch [27/100], Loss: 4.4445, Train Acc: 0.8094\n",
      "Epoch [28/100], Loss: 4.6930, Train Acc: 0.7969\n",
      "Epoch [29/100], Loss: 4.5969, Train Acc: 0.8000\n",
      "Epoch [30/100], Loss: 4.5158, Train Acc: 0.7969\n",
      "Epoch [31/100], Loss: 4.4646, Train Acc: 0.7906\n",
      "Epoch [32/100], Loss: 4.1441, Train Acc: 0.8000\n",
      "Epoch [33/100], Loss: 4.2136, Train Acc: 0.8219\n",
      "Epoch [34/100], Loss: 4.3572, Train Acc: 0.8031\n",
      "Epoch [35/100], Loss: 3.7201, Train Acc: 0.8375\n",
      "Epoch [36/100], Loss: 4.2903, Train Acc: 0.8031\n",
      "Epoch [37/100], Loss: 4.2252, Train Acc: 0.7969\n",
      "Epoch [38/100], Loss: 4.3781, Train Acc: 0.8125\n",
      "Epoch [39/100], Loss: 4.3972, Train Acc: 0.8063\n",
      "Epoch [40/100], Loss: 3.9104, Train Acc: 0.8281\n",
      "Epoch [41/100], Loss: 4.1544, Train Acc: 0.8187\n",
      "Epoch [42/100], Loss: 4.1369, Train Acc: 0.8125\n",
      "Epoch [43/100], Loss: 4.2364, Train Acc: 0.8125\n",
      "Epoch [44/100], Loss: 4.3179, Train Acc: 0.8156\n",
      "Epoch [45/100], Loss: 3.9281, Train Acc: 0.8250\n",
      "Epoch [46/100], Loss: 4.1468, Train Acc: 0.8031\n",
      "Epoch [47/100], Loss: 4.4550, Train Acc: 0.8031\n",
      "Epoch [48/100], Loss: 4.3860, Train Acc: 0.7937\n",
      "Epoch [49/100], Loss: 4.0771, Train Acc: 0.7969\n",
      "Epoch [50/100], Loss: 4.3688, Train Acc: 0.8094\n",
      "Epoch [51/100], Loss: 4.3971, Train Acc: 0.7906\n",
      "Epoch [52/100], Loss: 4.0171, Train Acc: 0.8000\n",
      "Epoch [53/100], Loss: 4.0691, Train Acc: 0.8187\n",
      "Epoch [54/100], Loss: 4.1179, Train Acc: 0.8000\n",
      "Epoch [55/100], Loss: 4.0460, Train Acc: 0.8031\n",
      "Epoch [56/100], Loss: 3.9995, Train Acc: 0.8187\n",
      "Epoch [57/100], Loss: 3.9611, Train Acc: 0.8063\n",
      "Epoch [58/100], Loss: 4.1531, Train Acc: 0.8187\n",
      "Epoch [59/100], Loss: 3.9770, Train Acc: 0.8031\n",
      "Epoch [60/100], Loss: 4.0857, Train Acc: 0.8063\n",
      "Epoch [61/100], Loss: 3.8726, Train Acc: 0.8156\n",
      "Epoch [62/100], Loss: 4.4766, Train Acc: 0.8000\n",
      "Epoch [63/100], Loss: 4.2586, Train Acc: 0.8125\n",
      "Epoch [64/100], Loss: 4.4231, Train Acc: 0.8000\n",
      "Epoch [65/100], Loss: 3.9077, Train Acc: 0.8187\n",
      "Epoch [66/100], Loss: 4.0866, Train Acc: 0.8063\n",
      "Epoch [67/100], Loss: 3.9331, Train Acc: 0.8313\n",
      "Epoch [68/100], Loss: 3.7279, Train Acc: 0.8250\n",
      "Epoch [69/100], Loss: 3.9776, Train Acc: 0.8281\n",
      "Epoch [70/100], Loss: 3.9475, Train Acc: 0.7969\n",
      "Epoch [71/100], Loss: 3.9189, Train Acc: 0.8156\n",
      "Epoch [72/100], Loss: 3.8935, Train Acc: 0.8187\n",
      "Epoch [73/100], Loss: 3.8517, Train Acc: 0.8281\n",
      "Epoch [74/100], Loss: 4.0677, Train Acc: 0.8156\n",
      "Epoch [75/100], Loss: 3.7814, Train Acc: 0.8250\n",
      "Epoch [76/100], Loss: 3.9098, Train Acc: 0.8156\n",
      "Epoch [77/100], Loss: 3.7923, Train Acc: 0.8406\n",
      "Epoch [78/100], Loss: 3.8448, Train Acc: 0.8281\n",
      "Epoch [79/100], Loss: 4.1197, Train Acc: 0.8187\n",
      "Epoch [80/100], Loss: 3.9714, Train Acc: 0.8063\n",
      "Epoch [81/100], Loss: 3.7848, Train Acc: 0.8219\n",
      "Epoch [82/100], Loss: 3.8533, Train Acc: 0.8219\n",
      "Epoch [83/100], Loss: 3.8285, Train Acc: 0.8250\n",
      "Epoch [84/100], Loss: 3.8776, Train Acc: 0.8187\n",
      "Epoch [85/100], Loss: 3.7553, Train Acc: 0.8250\n",
      "Epoch [86/100], Loss: 4.1523, Train Acc: 0.7969\n",
      "Epoch [87/100], Loss: 4.0146, Train Acc: 0.8094\n",
      "Epoch [88/100], Loss: 4.0090, Train Acc: 0.8187\n",
      "Epoch [89/100], Loss: 3.8891, Train Acc: 0.8156\n",
      "Epoch [90/100], Loss: 4.0036, Train Acc: 0.8187\n",
      "Epoch [91/100], Loss: 3.9486, Train Acc: 0.8156\n",
      "Epoch [92/100], Loss: 3.6321, Train Acc: 0.8281\n",
      "Epoch [93/100], Loss: 3.7377, Train Acc: 0.8125\n",
      "Epoch [94/100], Loss: 3.8989, Train Acc: 0.8219\n",
      "Epoch [95/100], Loss: 3.8175, Train Acc: 0.8313\n",
      "Epoch [96/100], Loss: 3.8850, Train Acc: 0.8187\n",
      "Epoch [97/100], Loss: 3.7634, Train Acc: 0.8187\n",
      "Epoch [98/100], Loss: 4.0664, Train Acc: 0.8094\n",
      "Epoch [99/100], Loss: 3.7845, Train Acc: 0.8156\n",
      "Epoch [100/100], Loss: 3.9072, Train Acc: 0.7969\n",
      "Training complete!\n",
      "MLP Test Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(set(y_train))  # Number of classes\n",
    "hidden_size = [300, 200]\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, epochs=epochs)\n",
    "\n",
    "# Evaluate MLP model\n",
    "mlp_accuracy = model.evaluate(test_loader)\n",
    "print(f\"MLP Test Accuracy: {mlp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above, but getting the accuracy in a one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 8.6367, Train Acc: 0.6500\n",
      "Epoch [2/100], Loss: 5.9576, Train Acc: 0.7406\n",
      "Epoch [3/100], Loss: 5.5829, Train Acc: 0.7688\n",
      "Epoch [4/100], Loss: 4.6564, Train Acc: 0.7969\n",
      "Epoch [5/100], Loss: 4.6200, Train Acc: 0.7875\n",
      "Epoch [6/100], Loss: 4.4650, Train Acc: 0.8031\n",
      "Epoch [7/100], Loss: 4.6749, Train Acc: 0.7875\n",
      "Epoch [8/100], Loss: 4.5802, Train Acc: 0.7906\n",
      "Epoch [9/100], Loss: 4.6727, Train Acc: 0.7969\n",
      "Epoch [10/100], Loss: 4.3787, Train Acc: 0.7875\n",
      "Epoch [11/100], Loss: 4.4203, Train Acc: 0.8219\n",
      "Epoch [12/100], Loss: 4.4238, Train Acc: 0.7969\n",
      "Epoch [13/100], Loss: 4.1009, Train Acc: 0.8031\n",
      "Epoch [14/100], Loss: 4.4463, Train Acc: 0.7937\n",
      "Epoch [15/100], Loss: 4.2769, Train Acc: 0.8000\n",
      "Epoch [16/100], Loss: 4.0623, Train Acc: 0.8031\n",
      "Epoch [17/100], Loss: 4.1207, Train Acc: 0.8000\n",
      "Epoch [18/100], Loss: 4.1053, Train Acc: 0.8031\n",
      "Epoch [19/100], Loss: 3.8896, Train Acc: 0.8063\n",
      "Epoch [20/100], Loss: 4.0101, Train Acc: 0.8094\n",
      "Epoch [21/100], Loss: 4.1411, Train Acc: 0.8094\n",
      "Epoch [22/100], Loss: 4.3703, Train Acc: 0.7937\n",
      "Epoch [23/100], Loss: 3.8697, Train Acc: 0.8250\n",
      "Epoch [24/100], Loss: 3.9211, Train Acc: 0.8187\n",
      "Epoch [25/100], Loss: 3.9891, Train Acc: 0.8094\n",
      "Epoch [26/100], Loss: 3.9300, Train Acc: 0.8125\n",
      "Epoch [27/100], Loss: 4.0275, Train Acc: 0.8125\n",
      "Epoch [28/100], Loss: 4.2196, Train Acc: 0.8125\n",
      "Epoch [29/100], Loss: 4.2121, Train Acc: 0.8031\n",
      "Epoch [30/100], Loss: 3.9329, Train Acc: 0.8125\n",
      "Epoch [31/100], Loss: 4.0775, Train Acc: 0.8125\n",
      "Epoch [32/100], Loss: 3.8656, Train Acc: 0.8156\n",
      "Epoch [33/100], Loss: 3.6105, Train Acc: 0.8250\n",
      "Epoch [34/100], Loss: 3.9523, Train Acc: 0.8250\n",
      "Epoch [35/100], Loss: 3.8984, Train Acc: 0.8219\n",
      "Epoch [36/100], Loss: 3.8879, Train Acc: 0.8344\n",
      "Epoch [37/100], Loss: 3.9603, Train Acc: 0.8094\n",
      "Epoch [38/100], Loss: 4.0300, Train Acc: 0.7906\n",
      "Epoch [39/100], Loss: 4.3266, Train Acc: 0.8094\n",
      "Epoch [40/100], Loss: 3.9622, Train Acc: 0.8187\n",
      "Epoch [41/100], Loss: 3.7484, Train Acc: 0.8219\n",
      "Epoch [42/100], Loss: 3.8861, Train Acc: 0.8250\n",
      "Epoch [43/100], Loss: 4.0644, Train Acc: 0.8125\n",
      "Epoch [44/100], Loss: 3.8976, Train Acc: 0.8250\n",
      "Epoch [45/100], Loss: 3.8432, Train Acc: 0.8313\n",
      "Epoch [46/100], Loss: 3.8119, Train Acc: 0.8313\n",
      "Epoch [47/100], Loss: 3.8474, Train Acc: 0.8219\n",
      "Epoch [48/100], Loss: 3.8653, Train Acc: 0.8031\n",
      "Epoch [49/100], Loss: 3.8926, Train Acc: 0.8313\n",
      "Epoch [50/100], Loss: 3.8521, Train Acc: 0.8219\n",
      "Epoch [51/100], Loss: 3.8480, Train Acc: 0.8313\n",
      "Epoch [52/100], Loss: 3.6350, Train Acc: 0.8344\n",
      "Epoch [53/100], Loss: 3.8917, Train Acc: 0.8281\n",
      "Epoch [54/100], Loss: 3.6969, Train Acc: 0.8344\n",
      "Epoch [55/100], Loss: 3.8199, Train Acc: 0.8187\n",
      "Epoch [56/100], Loss: 3.6610, Train Acc: 0.8219\n",
      "Epoch [57/100], Loss: 3.9466, Train Acc: 0.8187\n",
      "Epoch [58/100], Loss: 3.7164, Train Acc: 0.8156\n",
      "Epoch [59/100], Loss: 3.8941, Train Acc: 0.8219\n",
      "Epoch [60/100], Loss: 3.6959, Train Acc: 0.8250\n",
      "Epoch [61/100], Loss: 3.7610, Train Acc: 0.8094\n",
      "Epoch [62/100], Loss: 3.6681, Train Acc: 0.8281\n",
      "Epoch [63/100], Loss: 3.6514, Train Acc: 0.8281\n",
      "Epoch [64/100], Loss: 3.9855, Train Acc: 0.8187\n",
      "Epoch [65/100], Loss: 3.9621, Train Acc: 0.8156\n",
      "Epoch [66/100], Loss: 3.8066, Train Acc: 0.8219\n",
      "Epoch [67/100], Loss: 3.7945, Train Acc: 0.8219\n",
      "Epoch [68/100], Loss: 3.9301, Train Acc: 0.8094\n",
      "Epoch [69/100], Loss: 3.8646, Train Acc: 0.8156\n",
      "Epoch [70/100], Loss: 3.7256, Train Acc: 0.8281\n",
      "Epoch [71/100], Loss: 3.6785, Train Acc: 0.8187\n",
      "Epoch [72/100], Loss: 3.6829, Train Acc: 0.8375\n",
      "Epoch [73/100], Loss: 3.6943, Train Acc: 0.8344\n",
      "Epoch [74/100], Loss: 3.7537, Train Acc: 0.8375\n",
      "Epoch [75/100], Loss: 3.8603, Train Acc: 0.8250\n",
      "Epoch [76/100], Loss: 3.8165, Train Acc: 0.8250\n",
      "Epoch [77/100], Loss: 3.7486, Train Acc: 0.8187\n",
      "Epoch [78/100], Loss: 3.8618, Train Acc: 0.8094\n",
      "Epoch [79/100], Loss: 3.7538, Train Acc: 0.8219\n",
      "Epoch [80/100], Loss: 3.6459, Train Acc: 0.8250\n",
      "Epoch [81/100], Loss: 3.5401, Train Acc: 0.8344\n",
      "Epoch [82/100], Loss: 3.9342, Train Acc: 0.8219\n",
      "Epoch [83/100], Loss: 3.7475, Train Acc: 0.8250\n",
      "Epoch [84/100], Loss: 3.6251, Train Acc: 0.8219\n",
      "Epoch [85/100], Loss: 3.7778, Train Acc: 0.8156\n",
      "Epoch [86/100], Loss: 3.7113, Train Acc: 0.8313\n",
      "Epoch [87/100], Loss: 3.9002, Train Acc: 0.8250\n",
      "Epoch [88/100], Loss: 3.8340, Train Acc: 0.8219\n",
      "Epoch [89/100], Loss: 3.7738, Train Acc: 0.8156\n",
      "Epoch [90/100], Loss: 3.5710, Train Acc: 0.8344\n",
      "Epoch [91/100], Loss: 3.6178, Train Acc: 0.8219\n",
      "Epoch [92/100], Loss: 3.8343, Train Acc: 0.8094\n",
      "Epoch [93/100], Loss: 3.6097, Train Acc: 0.8344\n",
      "Epoch [94/100], Loss: 3.8849, Train Acc: 0.8156\n",
      "Epoch [95/100], Loss: 3.7421, Train Acc: 0.8375\n",
      "Epoch [96/100], Loss: 3.6708, Train Acc: 0.8250\n",
      "Epoch [97/100], Loss: 3.8111, Train Acc: 0.8250\n",
      "Epoch [98/100], Loss: 3.7489, Train Acc: 0.8156\n",
      "Epoch [99/100], Loss: 3.6983, Train Acc: 0.8313\n",
      "Epoch [100/100], Loss: 3.6855, Train Acc: 0.8250\n",
      "Training complete!\n",
      "=== Multilayer Perceptron (MLP) Accuracy: 0.74 ===\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "mlp_accuracy = mlp_classifier(X_train, X_test, y_train, y_test, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
