{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP)\n",
    "This notebook builts an MLP for classification, same way as described in [Cepeda Humerez et al. (2019)](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007290)\n",
    "\n",
    "Hyperparameters to use:\n",
    "\n",
    "````python\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200] # 300 and 200 LTUs\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5 # This wasn't specified in the paper, but choose any\n",
    "learning_rate = 0.001 # Not specified in the paper\n",
    "epochs = 100 # Not specified in the paper\n",
    "batch_size = 16 # Not specified in the paper\n",
    "````\n",
    "\n",
    "The model architecture is in ``MLP.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MLP model codes from ``src``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "from sympy import sqrt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import all the functions from the 'src' directory, we import all the functions from each module so we can use them straight away\n",
    "from ssa_simulation import *\n",
    "from ssa_analysis import *\n",
    "from ssa_classification import *\n",
    "from models.MLP import MLP \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage to train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 107.0392, Train Acc: 0.5150\n",
      "Validation Acc: 0.4900\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.4900)\n",
      "Epoch [2/100], Loss: 73.6615, Train Acc: 0.5730\n",
      "Validation Acc: 0.4450\n",
      "Epoch [3/100], Loss: 64.6390, Train Acc: 0.5790\n",
      "Validation Acc: 0.4850\n",
      "Epoch [4/100], Loss: 55.5709, Train Acc: 0.6180\n",
      "Validation Acc: 0.5000\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5000)\n",
      "Epoch [5/100], Loss: 51.5685, Train Acc: 0.6100\n",
      "Validation Acc: 0.5050\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5050)\n",
      "Epoch [6/100], Loss: 46.3775, Train Acc: 0.6460\n",
      "Validation Acc: 0.5050\n",
      "Epoch [7/100], Loss: 42.6653, Train Acc: 0.6640\n",
      "Validation Acc: 0.5200\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5200)\n",
      "Epoch [8/100], Loss: 39.5790, Train Acc: 0.6890\n",
      "Validation Acc: 0.5150\n",
      "Epoch [9/100], Loss: 37.8717, Train Acc: 0.7020\n",
      "Validation Acc: 0.5250\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5250)\n",
      "Epoch [10/100], Loss: 39.0586, Train Acc: 0.6750\n",
      "Validation Acc: 0.5300\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5300)\n",
      "Epoch [11/100], Loss: 36.4473, Train Acc: 0.7020\n",
      "Validation Acc: 0.5150\n",
      "Epoch [12/100], Loss: 34.6931, Train Acc: 0.7250\n",
      "Validation Acc: 0.5000\n",
      "Epoch [13/100], Loss: 33.3116, Train Acc: 0.7480\n",
      "Validation Acc: 0.5150\n",
      "Epoch [14/100], Loss: 32.0265, Train Acc: 0.7470\n",
      "Validation Acc: 0.5050\n",
      "Epoch [15/100], Loss: 30.9832, Train Acc: 0.7640\n",
      "Validation Acc: 0.4800\n",
      "Epoch [16/100], Loss: 30.7144, Train Acc: 0.7600\n",
      "Validation Acc: 0.4800\n",
      "Epoch [17/100], Loss: 29.4015, Train Acc: 0.7730\n",
      "Validation Acc: 0.4800\n",
      "Epoch [18/100], Loss: 30.0931, Train Acc: 0.7680\n",
      "Validation Acc: 0.5150\n",
      "Epoch [19/100], Loss: 26.9268, Train Acc: 0.7970\n",
      "Validation Acc: 0.4700\n",
      "Epoch [20/100], Loss: 24.4480, Train Acc: 0.8330\n",
      "Validation Acc: 0.4650\n",
      "Epoch [21/100], Loss: 24.4932, Train Acc: 0.8150\n",
      "Validation Acc: 0.4950\n",
      "Epoch [22/100], Loss: 25.1413, Train Acc: 0.8090\n",
      "Validation Acc: 0.5000\n",
      "Epoch [23/100], Loss: 24.2090, Train Acc: 0.8270\n",
      "Validation Acc: 0.4750\n",
      "Epoch [24/100], Loss: 21.0383, Train Acc: 0.8440\n",
      "Validation Acc: 0.5050\n",
      "Epoch [25/100], Loss: 20.9737, Train Acc: 0.8460\n",
      "Validation Acc: 0.5300\n",
      "Epoch [26/100], Loss: 18.8622, Train Acc: 0.8670\n",
      "Validation Acc: 0.5350\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5350)\n",
      "Epoch [27/100], Loss: 19.8796, Train Acc: 0.8590\n",
      "Validation Acc: 0.5050\n",
      "Epoch [28/100], Loss: 18.6057, Train Acc: 0.8710\n",
      "Validation Acc: 0.5200\n",
      "Epoch [29/100], Loss: 16.7614, Train Acc: 0.8890\n",
      "Validation Acc: 0.5300\n",
      "Epoch [30/100], Loss: 16.9807, Train Acc: 0.8870\n",
      "Validation Acc: 0.5050\n",
      "Epoch [31/100], Loss: 14.6251, Train Acc: 0.9110\n",
      "Validation Acc: 0.5100\n",
      "Epoch [32/100], Loss: 14.4448, Train Acc: 0.8960\n",
      "Validation Acc: 0.5150\n",
      "Epoch [33/100], Loss: 14.2927, Train Acc: 0.9100\n",
      "Validation Acc: 0.5200\n",
      "Epoch [34/100], Loss: 14.4845, Train Acc: 0.9020\n",
      "Validation Acc: 0.5050\n",
      "Epoch [35/100], Loss: 12.4742, Train Acc: 0.9200\n",
      "Validation Acc: 0.5150\n",
      "Epoch [36/100], Loss: 10.8482, Train Acc: 0.9320\n",
      "Validation Acc: 0.5200\n",
      "Epoch [37/100], Loss: 12.0533, Train Acc: 0.9270\n",
      "Validation Acc: 0.5150\n",
      "Epoch [38/100], Loss: 12.5470, Train Acc: 0.9220\n",
      "Validation Acc: 0.4950\n",
      "Epoch [39/100], Loss: 8.7010, Train Acc: 0.9490\n",
      "Validation Acc: 0.5050\n",
      "Epoch [40/100], Loss: 10.9794, Train Acc: 0.9350\n",
      "Validation Acc: 0.4750\n",
      "Epoch [41/100], Loss: 10.2493, Train Acc: 0.9380\n",
      "Validation Acc: 0.5200\n",
      "Epoch [42/100], Loss: 11.1448, Train Acc: 0.9350\n",
      "Validation Acc: 0.5000\n",
      "Epoch [43/100], Loss: 10.0140, Train Acc: 0.9400\n",
      "Validation Acc: 0.5300\n",
      "Epoch [44/100], Loss: 10.1827, Train Acc: 0.9370\n",
      "Validation Acc: 0.5250\n",
      "Epoch [45/100], Loss: 7.4697, Train Acc: 0.9510\n",
      "Validation Acc: 0.5250\n",
      "Epoch [46/100], Loss: 7.3183, Train Acc: 0.9610\n",
      "Validation Acc: 0.5250\n",
      "Epoch [47/100], Loss: 6.5670, Train Acc: 0.9610\n",
      "Validation Acc: 0.5100\n",
      "Epoch [48/100], Loss: 6.8341, Train Acc: 0.9580\n",
      "Validation Acc: 0.5050\n",
      "Epoch [49/100], Loss: 5.0633, Train Acc: 0.9700\n",
      "Validation Acc: 0.5100\n",
      "Epoch [50/100], Loss: 7.4021, Train Acc: 0.9490\n",
      "Validation Acc: 0.5050\n",
      "Epoch [51/100], Loss: 7.0981, Train Acc: 0.9590\n",
      "Validation Acc: 0.4950\n",
      "Epoch [52/100], Loss: 5.8042, Train Acc: 0.9660\n",
      "Validation Acc: 0.4750\n",
      "Epoch [53/100], Loss: 5.0748, Train Acc: 0.9710\n",
      "Validation Acc: 0.5250\n",
      "Epoch [54/100], Loss: 6.9696, Train Acc: 0.9530\n",
      "Validation Acc: 0.5200\n",
      "Epoch [55/100], Loss: 5.5672, Train Acc: 0.9700\n",
      "Validation Acc: 0.5200\n",
      "Epoch [56/100], Loss: 5.2852, Train Acc: 0.9670\n",
      "Validation Acc: 0.5050\n",
      "Epoch [57/100], Loss: 6.7451, Train Acc: 0.9630\n",
      "Validation Acc: 0.5150\n",
      "Epoch [58/100], Loss: 3.9699, Train Acc: 0.9750\n",
      "Validation Acc: 0.5050\n",
      "Epoch [59/100], Loss: 5.0183, Train Acc: 0.9710\n",
      "Validation Acc: 0.4950\n",
      "Epoch [60/100], Loss: 7.3786, Train Acc: 0.9490\n",
      "Validation Acc: 0.5150\n",
      "Epoch [61/100], Loss: 5.4685, Train Acc: 0.9620\n",
      "Validation Acc: 0.5200\n",
      "Epoch [62/100], Loss: 4.6255, Train Acc: 0.9720\n",
      "Validation Acc: 0.5200\n",
      "Epoch [63/100], Loss: 3.6262, Train Acc: 0.9790\n",
      "Validation Acc: 0.4950\n",
      "Epoch [64/100], Loss: 3.9739, Train Acc: 0.9740\n",
      "Validation Acc: 0.5200\n",
      "Epoch [65/100], Loss: 4.1906, Train Acc: 0.9770\n",
      "Validation Acc: 0.5050\n",
      "Epoch [66/100], Loss: 3.4607, Train Acc: 0.9810\n",
      "Validation Acc: 0.5050\n",
      "Epoch [67/100], Loss: 4.2205, Train Acc: 0.9750\n",
      "Validation Acc: 0.5350\n",
      "Epoch [68/100], Loss: 5.1773, Train Acc: 0.9700\n",
      "Validation Acc: 0.5400\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5400)\n",
      "Epoch [69/100], Loss: 4.2349, Train Acc: 0.9720\n",
      "Validation Acc: 0.5300\n",
      "Epoch [70/100], Loss: 3.8255, Train Acc: 0.9760\n",
      "Validation Acc: 0.5000\n",
      "Epoch [71/100], Loss: 4.6926, Train Acc: 0.9750\n",
      "Validation Acc: 0.5100\n",
      "Epoch [72/100], Loss: 3.6377, Train Acc: 0.9760\n",
      "Validation Acc: 0.5050\n",
      "Epoch [73/100], Loss: 3.7004, Train Acc: 0.9750\n",
      "Validation Acc: 0.5100\n",
      "Epoch [74/100], Loss: 4.3944, Train Acc: 0.9750\n",
      "Validation Acc: 0.5150\n",
      "Epoch [75/100], Loss: 3.3407, Train Acc: 0.9790\n",
      "Validation Acc: 0.5150\n",
      "Epoch [76/100], Loss: 4.4395, Train Acc: 0.9690\n",
      "Validation Acc: 0.5200\n",
      "Epoch [77/100], Loss: 3.7270, Train Acc: 0.9750\n",
      "Validation Acc: 0.5100\n",
      "Epoch [78/100], Loss: 4.4881, Train Acc: 0.9670\n",
      "Validation Acc: 0.5150\n",
      "Epoch [79/100], Loss: 3.4778, Train Acc: 0.9800\n",
      "Validation Acc: 0.5250\n",
      "Epoch [80/100], Loss: 4.9737, Train Acc: 0.9740\n",
      "Validation Acc: 0.4950\n",
      "Epoch [81/100], Loss: 3.9902, Train Acc: 0.9820\n",
      "Validation Acc: 0.5150\n",
      "Epoch [82/100], Loss: 4.2097, Train Acc: 0.9790\n",
      "Validation Acc: 0.5250\n",
      "Epoch [83/100], Loss: 2.6032, Train Acc: 0.9860\n",
      "Validation Acc: 0.5200\n",
      "Epoch [84/100], Loss: 3.8238, Train Acc: 0.9830\n",
      "Validation Acc: 0.5050\n",
      "Epoch [85/100], Loss: 3.1995, Train Acc: 0.9830\n",
      "Validation Acc: 0.5300\n",
      "Epoch [86/100], Loss: 2.5207, Train Acc: 0.9880\n",
      "Validation Acc: 0.5500\n",
      "âœ… Model saved at mlp_model.pth (Best Validation Acc: 0.5500)\n",
      "Epoch [87/100], Loss: 2.4619, Train Acc: 0.9830\n",
      "Validation Acc: 0.5500\n",
      "Epoch [88/100], Loss: 3.0557, Train Acc: 0.9860\n",
      "Validation Acc: 0.5400\n",
      "Epoch [89/100], Loss: 2.0025, Train Acc: 0.9890\n",
      "Validation Acc: 0.5450\n",
      "Epoch [90/100], Loss: 2.9807, Train Acc: 0.9830\n",
      "Validation Acc: 0.5300\n",
      "Epoch [91/100], Loss: 2.4889, Train Acc: 0.9790\n",
      "Validation Acc: 0.5300\n",
      "Epoch [92/100], Loss: 3.5552, Train Acc: 0.9820\n",
      "Validation Acc: 0.5150\n",
      "Epoch [93/100], Loss: 2.8103, Train Acc: 0.9850\n",
      "Validation Acc: 0.5500\n",
      "Epoch [94/100], Loss: 2.7147, Train Acc: 0.9880\n",
      "Validation Acc: 0.5400\n",
      "Epoch [95/100], Loss: 3.2479, Train Acc: 0.9840\n",
      "Validation Acc: 0.5200\n",
      "Epoch [96/100], Loss: 2.6289, Train Acc: 0.9870\n",
      "Validation Acc: 0.5400\n",
      "Epoch [97/100], Loss: 5.1999, Train Acc: 0.9690\n",
      "Validation Acc: 0.5250\n",
      "Epoch [98/100], Loss: 2.9839, Train Acc: 0.9810\n",
      "Validation Acc: 0.4950\n",
      "Epoch [99/100], Loss: 3.5411, Train Acc: 0.9760\n",
      "Validation Acc: 0.5150\n",
      "Epoch [100/100], Loss: 2.0575, Train Acc: 0.9890\n",
      "Validation Acc: 0.5200\n",
      "Training complete!\n",
      "ðŸ”„ Model loaded from mlp_model.pth\n",
      "Final Test Accuracy: 0.5500\n",
      "Predicted classes: tensor([1, 1, 1, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 200  # Adjust based on dataset\n",
    "hidden_size = [300, 200]\n",
    "output_size = 2  # Number of classes\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Generate synthetic data\n",
    "X_train = torch.randn(1000, input_size)\n",
    "y_train = torch.randint(0, output_size, (1000,))\n",
    "X_val = torch.randn(200, input_size)\n",
    "y_val = torch.randint(0, output_size, (200,))\n",
    "\n",
    "# Convert to DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize and train model\n",
    "file_path = \"mlp_model.pth\"\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, val_loader, epochs, save_path=file_path)\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_model(file_path)\n",
    "test_acc = model.evaluate(val_loader)\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "X_test = torch.randn(5, input_size)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predicted classes:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the MLP using SSA data, we need to first standardise the data. If we don't, the loss will be showing as nan, which is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Train MLP model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " ...\n",
      " [ 0.          1.00514142 -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.          2.44105774 -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]\n",
      " [ 0.         -0.4307749  -0.30161953 ... -0.05598925 -0.09728167\n",
      "  -0.07930516]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data \n",
    "# If your input features are too large (e.g., >1000) or too small (<0.0001), it can cause unstable training, so it's better to standardize the data.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 10.1923, Train Acc: 0.6500\n",
      "Epoch [2/100], Loss: 7.7781, Train Acc: 0.7250\n",
      "Epoch [3/100], Loss: 6.6361, Train Acc: 0.7656\n",
      "Epoch [4/100], Loss: 7.7896, Train Acc: 0.7375\n",
      "Epoch [5/100], Loss: 6.0724, Train Acc: 0.7656\n",
      "Epoch [6/100], Loss: 5.8631, Train Acc: 0.7781\n",
      "Epoch [7/100], Loss: 6.3598, Train Acc: 0.7500\n",
      "Epoch [8/100], Loss: 5.6975, Train Acc: 0.7750\n",
      "Epoch [9/100], Loss: 4.5606, Train Acc: 0.7969\n",
      "Epoch [10/100], Loss: 4.6146, Train Acc: 0.7781\n",
      "Epoch [11/100], Loss: 5.5498, Train Acc: 0.7594\n",
      "Epoch [12/100], Loss: 5.0303, Train Acc: 0.7937\n",
      "Epoch [13/100], Loss: 5.3236, Train Acc: 0.7750\n",
      "Epoch [14/100], Loss: 5.3151, Train Acc: 0.7844\n",
      "Epoch [15/100], Loss: 5.2147, Train Acc: 0.7875\n",
      "Epoch [16/100], Loss: 4.6183, Train Acc: 0.8063\n",
      "Epoch [17/100], Loss: 4.9205, Train Acc: 0.7781\n",
      "Epoch [18/100], Loss: 4.5531, Train Acc: 0.7969\n",
      "Epoch [19/100], Loss: 5.3765, Train Acc: 0.7812\n",
      "Epoch [20/100], Loss: 4.4642, Train Acc: 0.7875\n",
      "Epoch [21/100], Loss: 4.6854, Train Acc: 0.7875\n",
      "Epoch [22/100], Loss: 4.5870, Train Acc: 0.7750\n",
      "Epoch [23/100], Loss: 5.0190, Train Acc: 0.7781\n",
      "Epoch [24/100], Loss: 5.0426, Train Acc: 0.7750\n",
      "Epoch [25/100], Loss: 4.3805, Train Acc: 0.7937\n",
      "Epoch [26/100], Loss: 4.6825, Train Acc: 0.7969\n",
      "Epoch [27/100], Loss: 4.2755, Train Acc: 0.7937\n",
      "Epoch [28/100], Loss: 4.7869, Train Acc: 0.8000\n",
      "Epoch [29/100], Loss: 4.2953, Train Acc: 0.8156\n",
      "Epoch [30/100], Loss: 4.2488, Train Acc: 0.8063\n",
      "Epoch [31/100], Loss: 4.1984, Train Acc: 0.8063\n",
      "Epoch [32/100], Loss: 4.0858, Train Acc: 0.7937\n",
      "Epoch [33/100], Loss: 4.3555, Train Acc: 0.8219\n",
      "Epoch [34/100], Loss: 4.3212, Train Acc: 0.7937\n",
      "Epoch [35/100], Loss: 4.2879, Train Acc: 0.7969\n",
      "Epoch [36/100], Loss: 4.3916, Train Acc: 0.8156\n",
      "Epoch [37/100], Loss: 4.1942, Train Acc: 0.8031\n",
      "Epoch [38/100], Loss: 4.5088, Train Acc: 0.7844\n",
      "Epoch [39/100], Loss: 4.0805, Train Acc: 0.8281\n",
      "Epoch [40/100], Loss: 4.5596, Train Acc: 0.7937\n",
      "Epoch [41/100], Loss: 4.4430, Train Acc: 0.7844\n",
      "Epoch [42/100], Loss: 4.4258, Train Acc: 0.8094\n",
      "Epoch [43/100], Loss: 4.2859, Train Acc: 0.7906\n",
      "Epoch [44/100], Loss: 4.5973, Train Acc: 0.8125\n",
      "Epoch [45/100], Loss: 4.2807, Train Acc: 0.8063\n",
      "Epoch [46/100], Loss: 4.2460, Train Acc: 0.8156\n",
      "Epoch [47/100], Loss: 4.1073, Train Acc: 0.8125\n",
      "Epoch [48/100], Loss: 4.1277, Train Acc: 0.8031\n",
      "Epoch [49/100], Loss: 4.1727, Train Acc: 0.8187\n",
      "Epoch [50/100], Loss: 4.0336, Train Acc: 0.8313\n",
      "Epoch [51/100], Loss: 4.1872, Train Acc: 0.8094\n",
      "Epoch [52/100], Loss: 4.0777, Train Acc: 0.8125\n",
      "Epoch [53/100], Loss: 3.9647, Train Acc: 0.8156\n",
      "Epoch [54/100], Loss: 4.2056, Train Acc: 0.8063\n",
      "Epoch [55/100], Loss: 4.2509, Train Acc: 0.8156\n",
      "Epoch [56/100], Loss: 3.9823, Train Acc: 0.8219\n",
      "Epoch [57/100], Loss: 3.7125, Train Acc: 0.8250\n",
      "Epoch [58/100], Loss: 4.1631, Train Acc: 0.8187\n",
      "Epoch [59/100], Loss: 4.0687, Train Acc: 0.8125\n",
      "Epoch [60/100], Loss: 3.6781, Train Acc: 0.8375\n",
      "Epoch [61/100], Loss: 4.3926, Train Acc: 0.8000\n",
      "Epoch [62/100], Loss: 3.9729, Train Acc: 0.8156\n",
      "Epoch [63/100], Loss: 4.2785, Train Acc: 0.8125\n",
      "Epoch [64/100], Loss: 4.2463, Train Acc: 0.8063\n",
      "Epoch [65/100], Loss: 4.0465, Train Acc: 0.8156\n",
      "Epoch [66/100], Loss: 4.1421, Train Acc: 0.8156\n",
      "Epoch [67/100], Loss: 3.8435, Train Acc: 0.8281\n",
      "Epoch [68/100], Loss: 4.1224, Train Acc: 0.8000\n",
      "Epoch [69/100], Loss: 3.9326, Train Acc: 0.8125\n",
      "Epoch [70/100], Loss: 3.7884, Train Acc: 0.8219\n",
      "Epoch [71/100], Loss: 4.0025, Train Acc: 0.8156\n",
      "Epoch [72/100], Loss: 4.0565, Train Acc: 0.8125\n",
      "Epoch [73/100], Loss: 4.0597, Train Acc: 0.8187\n",
      "Epoch [74/100], Loss: 3.9993, Train Acc: 0.8094\n",
      "Epoch [75/100], Loss: 4.2728, Train Acc: 0.8063\n",
      "Epoch [76/100], Loss: 3.8537, Train Acc: 0.8156\n",
      "Epoch [77/100], Loss: 4.1045, Train Acc: 0.8063\n",
      "Epoch [78/100], Loss: 3.8306, Train Acc: 0.8063\n",
      "Epoch [79/100], Loss: 3.9511, Train Acc: 0.8063\n",
      "Epoch [80/100], Loss: 3.9208, Train Acc: 0.8156\n",
      "Epoch [81/100], Loss: 3.9126, Train Acc: 0.8187\n",
      "Epoch [82/100], Loss: 3.7935, Train Acc: 0.8219\n",
      "Epoch [83/100], Loss: 3.8628, Train Acc: 0.8219\n",
      "Epoch [84/100], Loss: 3.7238, Train Acc: 0.8250\n",
      "Epoch [85/100], Loss: 3.8184, Train Acc: 0.8250\n",
      "Epoch [86/100], Loss: 4.1577, Train Acc: 0.7969\n",
      "Epoch [87/100], Loss: 3.8260, Train Acc: 0.8313\n",
      "Epoch [88/100], Loss: 3.9471, Train Acc: 0.8250\n",
      "Epoch [89/100], Loss: 3.7491, Train Acc: 0.8313\n",
      "Epoch [90/100], Loss: 3.8005, Train Acc: 0.8219\n",
      "Epoch [91/100], Loss: 4.0605, Train Acc: 0.8125\n",
      "Epoch [92/100], Loss: 3.8358, Train Acc: 0.8219\n",
      "Epoch [93/100], Loss: 3.7377, Train Acc: 0.8438\n",
      "Epoch [94/100], Loss: 3.7239, Train Acc: 0.8313\n",
      "Epoch [95/100], Loss: 3.8789, Train Acc: 0.8094\n",
      "Epoch [96/100], Loss: 3.5113, Train Acc: 0.8344\n",
      "Epoch [97/100], Loss: 3.7416, Train Acc: 0.8187\n",
      "Epoch [98/100], Loss: 4.0322, Train Acc: 0.8125\n",
      "Epoch [99/100], Loss: 3.7898, Train Acc: 0.8313\n",
      "Epoch [100/100], Loss: 3.7816, Train Acc: 0.8281\n",
      "Training complete!\n",
      "MLP Test Accuracy: 0.7375\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(set(y_train))  # Number of classes\n",
    "hidden_size = [300, 200]\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.long)),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size, dropout_rate, learning_rate)\n",
    "model.train_model(train_loader, epochs=epochs)\n",
    "\n",
    "# Evaluate MLP model\n",
    "mlp_accuracy = model.evaluate(test_loader)\n",
    "print(f\"MLP Test Accuracy: {mlp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above, but getting the accuracy in a one-liner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Using device: cuda (1 GPUs available)\n",
      "âœ… Running on CUDA!\n",
      "Epoch [1/100], Loss: 10.1319, Train Acc: 0.6250\n",
      "Epoch [2/100], Loss: 6.4514, Train Acc: 0.7656\n",
      "Epoch [3/100], Loss: 5.5379, Train Acc: 0.7844\n",
      "Epoch [4/100], Loss: 5.3843, Train Acc: 0.7719\n",
      "Epoch [5/100], Loss: 5.2114, Train Acc: 0.7531\n",
      "Epoch [6/100], Loss: 4.4822, Train Acc: 0.7906\n",
      "Epoch [7/100], Loss: 4.1581, Train Acc: 0.8281\n",
      "Epoch [8/100], Loss: 4.5614, Train Acc: 0.8063\n",
      "Epoch [9/100], Loss: 4.3205, Train Acc: 0.8219\n",
      "Epoch [10/100], Loss: 4.1015, Train Acc: 0.8031\n",
      "Epoch [11/100], Loss: 4.3846, Train Acc: 0.8063\n",
      "Epoch [12/100], Loss: 4.1383, Train Acc: 0.8156\n",
      "Epoch [13/100], Loss: 3.8201, Train Acc: 0.8281\n",
      "Epoch [14/100], Loss: 3.9183, Train Acc: 0.8125\n",
      "Epoch [15/100], Loss: 4.0951, Train Acc: 0.7969\n",
      "Epoch [16/100], Loss: 4.1384, Train Acc: 0.8094\n",
      "Epoch [17/100], Loss: 3.9946, Train Acc: 0.8094\n",
      "Epoch [18/100], Loss: 4.2162, Train Acc: 0.7906\n",
      "Epoch [19/100], Loss: 3.8835, Train Acc: 0.8187\n",
      "Epoch [20/100], Loss: 4.0471, Train Acc: 0.8156\n",
      "Epoch [21/100], Loss: 3.8301, Train Acc: 0.8344\n",
      "Epoch [22/100], Loss: 4.0972, Train Acc: 0.8000\n",
      "Epoch [23/100], Loss: 3.9923, Train Acc: 0.8156\n",
      "Epoch [24/100], Loss: 3.8621, Train Acc: 0.8156\n",
      "Epoch [25/100], Loss: 4.0934, Train Acc: 0.7937\n",
      "Epoch [26/100], Loss: 4.0106, Train Acc: 0.8031\n",
      "Epoch [27/100], Loss: 3.8866, Train Acc: 0.8281\n",
      "Epoch [28/100], Loss: 4.0223, Train Acc: 0.7937\n",
      "Epoch [29/100], Loss: 3.7737, Train Acc: 0.8250\n",
      "Epoch [30/100], Loss: 3.9745, Train Acc: 0.8187\n",
      "Epoch [31/100], Loss: 4.1357, Train Acc: 0.8250\n",
      "Epoch [32/100], Loss: 3.9426, Train Acc: 0.8281\n",
      "Epoch [33/100], Loss: 3.6589, Train Acc: 0.8313\n",
      "Epoch [34/100], Loss: 4.0414, Train Acc: 0.8156\n",
      "Epoch [35/100], Loss: 3.9587, Train Acc: 0.8313\n",
      "Epoch [36/100], Loss: 3.8162, Train Acc: 0.8250\n",
      "Epoch [37/100], Loss: 3.5759, Train Acc: 0.8406\n",
      "Epoch [38/100], Loss: 3.8287, Train Acc: 0.8313\n",
      "Epoch [39/100], Loss: 4.0029, Train Acc: 0.8125\n",
      "Epoch [40/100], Loss: 4.1584, Train Acc: 0.8187\n",
      "Epoch [41/100], Loss: 3.8631, Train Acc: 0.8031\n",
      "Epoch [42/100], Loss: 3.8210, Train Acc: 0.8250\n",
      "Epoch [43/100], Loss: 3.7050, Train Acc: 0.8344\n",
      "Epoch [44/100], Loss: 3.8467, Train Acc: 0.8000\n",
      "Epoch [45/100], Loss: 3.7802, Train Acc: 0.8406\n",
      "Epoch [46/100], Loss: 3.8855, Train Acc: 0.8094\n",
      "Epoch [47/100], Loss: 3.8313, Train Acc: 0.8187\n",
      "Epoch [48/100], Loss: 4.0294, Train Acc: 0.8219\n",
      "Epoch [49/100], Loss: 3.9854, Train Acc: 0.8125\n",
      "Epoch [50/100], Loss: 3.5964, Train Acc: 0.8281\n",
      "Epoch [51/100], Loss: 4.1473, Train Acc: 0.8156\n",
      "Epoch [52/100], Loss: 3.8106, Train Acc: 0.8344\n",
      "Epoch [53/100], Loss: 3.7005, Train Acc: 0.8187\n",
      "Epoch [54/100], Loss: 3.6328, Train Acc: 0.8219\n",
      "Epoch [55/100], Loss: 3.7414, Train Acc: 0.8219\n",
      "Epoch [56/100], Loss: 3.8580, Train Acc: 0.8219\n",
      "Epoch [57/100], Loss: 3.5930, Train Acc: 0.8219\n",
      "Epoch [58/100], Loss: 3.9128, Train Acc: 0.8187\n",
      "Epoch [59/100], Loss: 3.9390, Train Acc: 0.8219\n",
      "Epoch [60/100], Loss: 3.7455, Train Acc: 0.8187\n",
      "Epoch [61/100], Loss: 3.8962, Train Acc: 0.8281\n",
      "Epoch [62/100], Loss: 3.8714, Train Acc: 0.8156\n",
      "Epoch [63/100], Loss: 3.7635, Train Acc: 0.8313\n",
      "Epoch [64/100], Loss: 3.6313, Train Acc: 0.8156\n",
      "Epoch [65/100], Loss: 3.5552, Train Acc: 0.8187\n",
      "Epoch [66/100], Loss: 3.7314, Train Acc: 0.8344\n",
      "Epoch [67/100], Loss: 4.0631, Train Acc: 0.8219\n",
      "Epoch [68/100], Loss: 3.8358, Train Acc: 0.8156\n",
      "Epoch [69/100], Loss: 3.7936, Train Acc: 0.8156\n",
      "Epoch [70/100], Loss: 3.9159, Train Acc: 0.8094\n",
      "Epoch [71/100], Loss: 3.8455, Train Acc: 0.8250\n",
      "Epoch [72/100], Loss: 3.6345, Train Acc: 0.8219\n",
      "Epoch [73/100], Loss: 3.8004, Train Acc: 0.8250\n",
      "Epoch [74/100], Loss: 3.8668, Train Acc: 0.8250\n",
      "Epoch [75/100], Loss: 3.6795, Train Acc: 0.8187\n",
      "Epoch [76/100], Loss: 3.7205, Train Acc: 0.8219\n",
      "Epoch [77/100], Loss: 3.8828, Train Acc: 0.8187\n",
      "Epoch [78/100], Loss: 3.6406, Train Acc: 0.8313\n",
      "Epoch [79/100], Loss: 3.7969, Train Acc: 0.8281\n",
      "Epoch [80/100], Loss: 3.7717, Train Acc: 0.8187\n",
      "Epoch [81/100], Loss: 3.5702, Train Acc: 0.8313\n",
      "Epoch [82/100], Loss: 3.8336, Train Acc: 0.8000\n",
      "Epoch [83/100], Loss: 3.7593, Train Acc: 0.8094\n",
      "Epoch [84/100], Loss: 3.7948, Train Acc: 0.8219\n",
      "Epoch [85/100], Loss: 3.5965, Train Acc: 0.8281\n",
      "Epoch [86/100], Loss: 3.6794, Train Acc: 0.8344\n",
      "Epoch [87/100], Loss: 3.5948, Train Acc: 0.8281\n",
      "Epoch [88/100], Loss: 3.8097, Train Acc: 0.8187\n",
      "Epoch [89/100], Loss: 3.8921, Train Acc: 0.8063\n",
      "Epoch [90/100], Loss: 3.7771, Train Acc: 0.8187\n",
      "Epoch [91/100], Loss: 3.6624, Train Acc: 0.8125\n",
      "Epoch [92/100], Loss: 3.6779, Train Acc: 0.8219\n",
      "Epoch [93/100], Loss: 3.7568, Train Acc: 0.8281\n",
      "Epoch [94/100], Loss: 3.5234, Train Acc: 0.8344\n",
      "Epoch [95/100], Loss: 3.7019, Train Acc: 0.8187\n",
      "Epoch [96/100], Loss: 3.7307, Train Acc: 0.8156\n",
      "Epoch [97/100], Loss: 3.5392, Train Acc: 0.8187\n",
      "Epoch [98/100], Loss: 3.5778, Train Acc: 0.8250\n",
      "Epoch [99/100], Loss: 3.7430, Train Acc: 0.8281\n",
      "Epoch [100/100], Loss: 3.6147, Train Acc: 0.8375\n",
      "Training complete!\n",
      "=== Multilayer Perceptron (MLP) Accuracy: 0.75 ===\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model using SSA data\n",
    "output_file = 'data/mRNA_trajectories_example.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(output_file)\n",
    "mlp_accuracy = mlp_classifier(X_train, X_test, y_train, y_test, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
